{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYLz/g3N9hQDXfv2OAtAyN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whoami-Lory271/thesis-project/blob/TiDE_SimTS/TiDE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TiDE"
      ],
      "metadata": {
        "id": "QlyKOGU4HiN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipdb --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIBscBszHyug",
        "outputId": "7772d9c4-b59e-4370-d162-b5e12eae5da9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.6 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.6 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fwYGIzsTHFC6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import ipdb\n",
        "\n",
        "\n",
        "args = {\n",
        "    \"dataset_name\" : \"ETTm1\",\n",
        "    \"path_data\" : \"\",\n",
        "    \"hidden_size\" : 128,\n",
        "    \"temporal_features\" : 4,\n",
        "    \"temporal_width\" : 4,\n",
        "    \"n_encoder_layers\" : 2,\n",
        "    \"n_decoder_layers\" : 2,\n",
        "    \"decoder_output_size\" : 32,\n",
        "    \"decoder_temporal_hidden_size\" : 128,\n",
        "    \"dropout\" : 0.1,\n",
        "    # Train arguments\n",
        "    \"batch_size\" : 4\n",
        "}\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, dropout=0.0):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, output_size),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.residual = nn.Linear(input_size, output_size)\n",
        "        self.layer_norm = nn.LayerNorm(output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.block(x) + self.residual(x)\n",
        "        output = self.layer_norm(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "class TemporalResidualBlock(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(TemporalResidualBlock, self).__init__()\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, 1)\n",
        "        )\n",
        "        self.residual = nn.Linear(input_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.block(x) + self.residual(x)\n",
        "        return output\n",
        "\n",
        "\n",
        "class FeatureProjectionBlock(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, temporal_width=4):\n",
        "        super(FeatureProjectionBlock, self).__init__()\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, temporal_width)\n",
        "        )\n",
        "        self.residual = nn.Linear(input_size, temporal_width)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.block(x) + self.residual(x)\n",
        "        return output\n",
        "\n",
        "\n",
        "class TiDE(nn.Module):\n",
        "    def __init__(self, args, input_steps, output_steps):\n",
        "        super(TiDE, self).__init__()\n",
        "        self.input_size = input_steps\n",
        "        self.output_size = output_steps\n",
        "        self.hidden_size = args[\"hidden_size\"]\n",
        "        self.temporal_features = args[\"temporal_features\"]\n",
        "        self.temporal_width = args[\"temporal_width\"]\n",
        "        self.n_encoder_layers = args[\"n_encoder_layers\"]\n",
        "        self.n_decoder_layers = args[\"n_decoder_layers\"]\n",
        "        self.decoder_output_size = args[\"decoder_output_size\"]\n",
        "        self.decoder_temporal_hidden_size = args[\"decoder_temporal_hidden_size\"]\n",
        "        self.dropout = args[\"dropout\"]\n",
        "\n",
        "        encoder_layers = []\n",
        "        for i in range(self.n_encoder_layers):\n",
        "            if i == 0:\n",
        "                residual_block = ResidualBlock(self.input_size+self.output_size*self.temporal_width, self.hidden_size, self.hidden_size, self.dropout)\n",
        "            else:\n",
        "                residual_block = ResidualBlock(self.hidden_size, self.hidden_size, self.hidden_size, self.dropout)\n",
        "            encoder_layers.append(residual_block)\n",
        "        self.dense_encoder = nn.Sequential(*encoder_layers)\n",
        "\n",
        "        decoder_layers = []\n",
        "        for i in range(self.n_decoder_layers):\n",
        "            if i == self.n_decoder_layers - 1:\n",
        "                residual_block = ResidualBlock(self.hidden_size, self.hidden_size, self.output_size*self.decoder_output_size, self.dropout)\n",
        "            else:\n",
        "                residual_block = ResidualBlock(self.hidden_size, self.hidden_size, self.hidden_size, self.dropout)\n",
        "            decoder_layers.append(residual_block)\n",
        "        self.dense_decoder = nn.Sequential(*decoder_layers)\n",
        "        self.temporal_decoder = TemporalResidualBlock(self.decoder_output_size+self.temporal_width, self.decoder_temporal_hidden_size)\n",
        "\n",
        "        self.feature_projection = FeatureProjectionBlock(self.temporal_features, self.hidden_size, self.temporal_width)\n",
        "\n",
        "        self.residual = nn.Linear(self.output_size, self.output_size)\n",
        "\n",
        "    def forward(self, x, feat):\n",
        "        assert x.dim() == 3 and x.size(2) == 1\n",
        "        ipdb.set_trace()\n",
        "        feat_embedding = self.feature_projection(feat)\n",
        "        feat_embedding = feat_embedding.reshape(feat_embedding.size(0), -1)\n",
        "        input = torch.cat([x.squeeze(2), feat_embedding], dim=1)\n",
        "        encoder_state = self.dense_encoder(input)\n",
        "        decoder_outputs = self.dense_decoder(encoder_state)\n",
        "        decoder_outputs = decoder_outputs.reshape(decoder_outputs.size(0), self.output_size, self.decoder_output_size)\n",
        "        decoder_outputs = torch.cat([decoder_outputs, feat_embedding.reshape(feat_embedding.size(0), self.output_size, self.temporal_width)], dim=2)\n",
        "        decoder_outputs = self.temporal_decoder(decoder_outputs)\n",
        "        decoder_outputs = decoder_outputs + self.residual(x[:,:self.output_size].squeeze(2)).unsqueeze(2)\n",
        "        return encoder_state, decoder_outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "PSXkblQ_Nhbn",
        "outputId": "a7b65c28-e07b-4f83-a565-8c28312e830f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2399877168bd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'hidden_size'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "L = 10\n",
        "H = 4\n",
        "D = 3\n",
        "R = 4\n",
        "y = torch.rand(4, L, D)\n",
        "x = torch.rand(4, L + H, R)\n",
        "tide = TiDE(args, D, 2)\n",
        "tide(y,x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        },
        "id": "rWrGyFjJMOa3",
        "outputId": "aba17004-89eb-4738-8bf2-ba3e6c781464"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> \u001b[0;32m<ipython-input-13-4a1d49a27cef>\u001b[0m(113)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    112 \u001b[0;31m        \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 113 \u001b[0;31m        \u001b[0mfeat_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    114 \u001b[0;31m        \u001b[0mfeat_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> x.dim()\n",
            "3\n",
            "ipdb> x.size(1)\n",
            "10\n",
            "ipdb> x.size(2)\n",
            "3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/debugger.py\", line 1075, in cmdloop\n",
            "    sys.settrace(None)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--KeyboardInterrupt--\n",
            "\n",
            "KeyboardInterrupt: Interrupted by user\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-7bf611001851>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtide\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTiDE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-4a1d49a27cef>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, feat)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mfeat_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mfeat_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_embedding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mencoder_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mdecoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 3 and 2"
          ]
        }
      ]
    }
  ]
}