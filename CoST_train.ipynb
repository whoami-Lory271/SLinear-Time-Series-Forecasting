{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whoami-Lory271/thesis-project/blob/main/CoST_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training CoST model"
      ],
      "metadata": {
        "id": "Gh2L5z66W2X6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1LWptcrfWeZG",
        "outputId": "c7f9a66d-8f69-4fcc-fe9a-f573568e9dcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CoST'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 74 (delta 30), reused 74 (delta 30), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (74/74), 368.15 KiB | 3.88 MiB/s, done.\n",
            "Resolving deltas: 100% (30/30), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/whoami-Lory271/CoST"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5EIFz57FW_Wh",
        "outputId": "67467dae-2be2-48e5-ac52-67a2eb8c5c11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/Tesi/code/datasets/electricity/LD2011_2014.txt\" \"/content/CoST/datasets/\""
      ],
      "metadata": {
        "id": "0hTJksSZXPcX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/CoST/requirements.txt\n",
        "!pip install einops==0.6.1 --quiet"
      ],
      "metadata": {
        "id": "x5qeqzGyXkx9",
        "outputId": "dc784e1e-4b0e-41c5-8f1d-430c350a3950",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scipy==1.6.1 (from -r /content/CoST/requirements.txt (line 1))\n",
            "  Downloading scipy-1.6.1.tar.gz (27.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.9.0 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.9.0\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/CoST/datasets; python electricity.py"
      ],
      "metadata": {
        "id": "A_zO0vylX_fF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cd /content/CoST; sh scripts/Electricity_CoST.sh"
      ],
      "metadata": {
        "id": "JDtXGWSiYvBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/CoST; python -u train.py electricity forecast_univar --alpha 0.0005 --kernels 1 2 4 8 16 32 64 128 --max-train-length 201 --batch-size 128 --archive forecast_csv_univar --repr-dims 320 --max-threads 8 --seed 1 --eval"
      ],
      "metadata": {
        "id": "cHGjomTozYI6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d2dedce-0843-4afe-ae00-0261496391db"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: electricity\n",
            "Arguments: Namespace(dataset='electricity', run_name='forecast_univar', archive='forecast_csv_univar', gpu=0, batch_size=128, lr=0.001, repr_dims=320, max_train_length=201, iters=None, epochs=None, save_every=None, seed=1, max_threads=8, eval=True, kernels=[1, 2, 4, 8, 16, 32, 64, 128], alpha=0.0005)\n",
            "/content/CoST/datautils.py:30: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series. To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
            "  dt.weekofyear.to_numpy(),\n",
            "Epoch #0: loss=0.06056727468967438\n",
            "Epoch #1: loss=4.238088607788086\n",
            "Epoch #2: loss=4.913817405700684\n",
            "Epoch #3: loss=4.793127536773682\n",
            "Epoch #4: loss=4.82541036605835\n",
            "Epoch #5: loss=4.691322326660156\n",
            "Epoch #6: loss=4.604249954223633\n",
            "Epoch #7: loss=4.510466575622559\n",
            "Epoch #8: loss=4.480866432189941\n",
            "Epoch #9: loss=4.4773383140563965\n",
            "Epoch #10: loss=4.712864875793457\n",
            "Epoch #11: loss=4.2335309982299805\n",
            "Epoch #12: loss=4.482583045959473\n",
            "Epoch #13: loss=4.21889591217041\n",
            "Epoch #14: loss=4.173023700714111\n",
            "Epoch #15: loss=4.290642738342285\n",
            "Epoch #16: loss=4.220555305480957\n",
            "Epoch #17: loss=4.329720973968506\n",
            "Epoch #18: loss=4.173304080963135\n",
            "Epoch #19: loss=4.1834635734558105\n",
            "Epoch #20: loss=4.0766777992248535\n",
            "Epoch #21: loss=4.121201515197754\n",
            "Epoch #22: loss=3.8155159950256348\n",
            "Epoch #23: loss=4.286764621734619\n",
            "Epoch #24: loss=3.762913465499878\n",
            "Epoch #25: loss=3.8010008335113525\n",
            "Epoch #26: loss=3.8465499877929688\n",
            "Epoch #27: loss=3.8176937103271484\n",
            "Epoch #28: loss=3.888279914855957\n",
            "Epoch #29: loss=3.737086296081543\n",
            "Epoch #30: loss=3.8818166255950928\n",
            "Epoch #31: loss=3.984726667404175\n",
            "Epoch #32: loss=3.4307353496551514\n",
            "Epoch #33: loss=3.679837226867676\n",
            "Epoch #34: loss=3.732297420501709\n",
            "Epoch #35: loss=3.6973140239715576\n",
            "Epoch #36: loss=3.56587553024292\n",
            "Epoch #37: loss=3.6116998195648193\n",
            "Epoch #38: loss=3.650682210922241\n",
            "Epoch #39: loss=3.678236484527588\n",
            "Epoch #40: loss=3.635967254638672\n",
            "Epoch #41: loss=3.526146173477173\n",
            "Epoch #42: loss=3.6506385803222656\n",
            "Epoch #43: loss=3.5889484882354736\n",
            "Epoch #44: loss=3.644615650177002\n",
            "Epoch #45: loss=3.385877847671509\n",
            "Epoch #46: loss=3.843648672103882\n",
            "Epoch #47: loss=3.3961310386657715\n",
            "Epoch #48: loss=3.5463030338287354\n",
            "Epoch #49: loss=3.4220523834228516\n",
            "Epoch #50: loss=3.441378593444824\n",
            "Epoch #51: loss=3.4038445949554443\n",
            "Epoch #52: loss=3.441533327102661\n",
            "Epoch #53: loss=3.2280852794647217\n",
            "Epoch #54: loss=3.296710968017578\n",
            "Epoch #55: loss=3.5579450130462646\n",
            "Epoch #56: loss=3.288037061691284\n",
            "Epoch #57: loss=3.073209285736084\n",
            "Epoch #58: loss=3.473250150680542\n",
            "Epoch #59: loss=3.3535900115966797\n",
            "Epoch #60: loss=3.4109206199645996\n",
            "Epoch #61: loss=3.170517921447754\n",
            "Epoch #62: loss=3.2483932971954346\n",
            "Epoch #63: loss=3.4042372703552246\n",
            "Epoch #64: loss=3.3931784629821777\n",
            "Epoch #65: loss=3.2451701164245605\n",
            "Epoch #66: loss=3.2709367275238037\n",
            "Epoch #67: loss=3.1620264053344727\n",
            "Epoch #68: loss=3.2694547176361084\n",
            "Epoch #69: loss=3.261725664138794\n",
            "Epoch #70: loss=3.452157497406006\n",
            "Epoch #71: loss=3.2045705318450928\n",
            "Epoch #72: loss=3.1546823978424072\n",
            "Epoch #73: loss=3.3950390815734863\n",
            "Epoch #74: loss=3.091808319091797\n",
            "Epoch #75: loss=3.091352701187134\n",
            "Epoch #76: loss=3.398503065109253\n",
            "Epoch #77: loss=3.2405617237091064\n",
            "Epoch #78: loss=3.1921703815460205\n",
            "Epoch #79: loss=3.2372705936431885\n",
            "Epoch #80: loss=3.255570411682129\n",
            "Epoch #81: loss=3.230170965194702\n",
            "Epoch #82: loss=3.3450088500976562\n",
            "Epoch #83: loss=3.580639123916626\n",
            "Epoch #84: loss=3.4741103649139404\n",
            "Epoch #85: loss=3.471057653427124\n",
            "Epoch #86: loss=2.9138190746307373\n",
            "Epoch #87: loss=2.9685585498809814\n",
            "Epoch #88: loss=3.10050368309021\n",
            "Epoch #89: loss=3.0821239948272705\n",
            "Epoch #90: loss=3.198289394378662\n",
            "Epoch #91: loss=2.986232042312622\n",
            "Epoch #92: loss=3.1627912521362305\n",
            "Epoch #93: loss=3.291952610015869\n",
            "Epoch #94: loss=3.299647331237793\n",
            "Epoch #95: loss=2.7567331790924072\n",
            "Epoch #96: loss=2.9235951900482178\n",
            "Epoch #97: loss=3.1604905128479004\n",
            "Epoch #98: loss=3.073915958404541\n",
            "Epoch #99: loss=3.1222386360168457\n",
            "Epoch #100: loss=3.0881073474884033\n",
            "Epoch #101: loss=3.2689781188964844\n",
            "Epoch #102: loss=3.0205633640289307\n",
            "Epoch #103: loss=3.082014560699463\n",
            "Epoch #104: loss=2.9616847038269043\n",
            "Epoch #105: loss=3.12196946144104\n",
            "Epoch #106: loss=3.412243127822876\n",
            "Epoch #107: loss=2.886969566345215\n",
            "Epoch #108: loss=3.043483257293701\n",
            "Epoch #109: loss=3.1276915073394775\n",
            "Epoch #110: loss=3.166306734085083\n",
            "Epoch #111: loss=3.118166446685791\n",
            "Epoch #112: loss=3.2077536582946777\n",
            "Epoch #113: loss=2.9105048179626465\n",
            "Epoch #114: loss=3.1179234981536865\n",
            "Epoch #115: loss=3.1878671646118164\n",
            "Epoch #116: loss=2.8576254844665527\n",
            "Epoch #117: loss=2.972775936126709\n",
            "Epoch #118: loss=3.1815297603607178\n",
            "Epoch #119: loss=3.0386176109313965\n",
            "Epoch #120: loss=3.0291173458099365\n",
            "Epoch #121: loss=2.8905906677246094\n",
            "Epoch #122: loss=3.3069570064544678\n",
            "Epoch #123: loss=2.645480155944824\n",
            "Epoch #124: loss=2.8221476078033447\n",
            "Epoch #125: loss=2.9591383934020996\n",
            "Epoch #126: loss=3.026418447494507\n",
            "Epoch #127: loss=2.7841782569885254\n",
            "Epoch #128: loss=3.1257123947143555\n",
            "Epoch #129: loss=3.025682210922241\n",
            "Epoch #130: loss=2.9399311542510986\n",
            "Epoch #131: loss=2.891812324523926\n",
            "Epoch #132: loss=2.938351631164551\n",
            "Epoch #133: loss=3.2823314666748047\n",
            "Epoch #134: loss=2.4553189277648926\n",
            "Epoch #135: loss=2.8086016178131104\n",
            "Epoch #136: loss=2.914900302886963\n",
            "Epoch #137: loss=3.089912176132202\n",
            "Epoch #138: loss=3.070462703704834\n",
            "Epoch #139: loss=2.9532158374786377\n",
            "Epoch #140: loss=2.6034810543060303\n",
            "Epoch #141: loss=2.707578420639038\n",
            "Epoch #142: loss=3.230461359024048\n",
            "Epoch #143: loss=2.9540112018585205\n",
            "Epoch #144: loss=2.798032522201538\n",
            "Epoch #145: loss=3.038327932357788\n",
            "Epoch #146: loss=2.8440985679626465\n",
            "Epoch #147: loss=2.648907423019409\n",
            "Epoch #148: loss=3.191148519515991\n",
            "Epoch #149: loss=2.7310516834259033\n",
            "Epoch #150: loss=3.22628116607666\n",
            "Epoch #151: loss=2.5731911659240723\n",
            "Epoch #152: loss=2.887467384338379\n",
            "Epoch #153: loss=3.075908660888672\n",
            "Epoch #154: loss=2.9645144939422607\n",
            "Epoch #155: loss=3.005096912384033\n",
            "Epoch #156: loss=2.6130008697509766\n",
            "Epoch #157: loss=2.8110077381134033\n",
            "Epoch #158: loss=2.8856825828552246\n",
            "Epoch #159: loss=2.771029472351074\n",
            "Epoch #160: loss=2.9067115783691406\n",
            "Epoch #161: loss=2.857421636581421\n",
            "Epoch #162: loss=2.9789531230926514\n",
            "Epoch #163: loss=2.8092262744903564\n",
            "Epoch #164: loss=2.6214938163757324\n",
            "Epoch #165: loss=2.842345952987671\n",
            "Epoch #166: loss=2.833942174911499\n",
            "Epoch #167: loss=2.752281427383423\n",
            "Epoch #168: loss=2.9403297901153564\n",
            "Epoch #169: loss=2.627089023590088\n",
            "Epoch #170: loss=2.6788361072540283\n",
            "Epoch #171: loss=2.7694883346557617\n",
            "Epoch #172: loss=2.5991296768188477\n",
            "Epoch #173: loss=2.4999406337738037\n",
            "Epoch #174: loss=2.9437859058380127\n",
            "Epoch #175: loss=2.814293622970581\n",
            "Epoch #176: loss=2.7212963104248047\n",
            "Epoch #177: loss=3.063577651977539\n",
            "Epoch #178: loss=2.8035075664520264\n",
            "Epoch #179: loss=2.863253355026245\n",
            "Epoch #180: loss=3.2747416496276855\n",
            "Epoch #181: loss=2.44023060798645\n",
            "Epoch #182: loss=2.3985960483551025\n",
            "Epoch #183: loss=2.8663480281829834\n",
            "Epoch #184: loss=2.634976625442505\n",
            "Epoch #185: loss=2.6569111347198486\n",
            "Epoch #186: loss=2.850911855697632\n",
            "Epoch #187: loss=3.057692527770996\n",
            "Epoch #188: loss=2.9238016605377197\n",
            "Epoch #189: loss=2.805406332015991\n",
            "Epoch #190: loss=2.890533685684204\n",
            "Epoch #191: loss=2.9965858459472656\n",
            "Epoch #192: loss=2.7779006958007812\n",
            "Epoch #193: loss=2.637105703353882\n",
            "Epoch #194: loss=2.598609447479248\n",
            "Epoch #195: loss=2.831234931945801\n",
            "Epoch #196: loss=2.9434165954589844\n",
            "Epoch #197: loss=2.7469594478607178\n",
            "Epoch #198: loss=2.7396719455718994\n",
            "Epoch #199: loss=2.6541037559509277\n",
            "Epoch #200: loss=2.9520044326782227\n",
            "Epoch #201: loss=3.2181830406188965\n",
            "Epoch #202: loss=2.5444223880767822\n",
            "Epoch #203: loss=2.6762852668762207\n",
            "Epoch #204: loss=2.7795515060424805\n",
            "Epoch #205: loss=2.8128278255462646\n",
            "Epoch #206: loss=2.77148699760437\n",
            "Epoch #207: loss=2.6354517936706543\n",
            "Epoch #208: loss=2.7560036182403564\n",
            "Epoch #209: loss=3.049530506134033\n",
            "Epoch #210: loss=2.532770872116089\n",
            "Epoch #211: loss=3.3622262477874756\n",
            "Epoch #212: loss=2.7570626735687256\n",
            "Epoch #213: loss=2.5238027572631836\n",
            "Epoch #214: loss=2.433972120285034\n",
            "Epoch #215: loss=2.6758370399475098\n",
            "Epoch #216: loss=2.6752893924713135\n",
            "Epoch #217: loss=2.4590609073638916\n",
            "Epoch #218: loss=2.860200881958008\n",
            "Epoch #219: loss=2.327989101409912\n",
            "Epoch #220: loss=3.292782783508301\n",
            "Epoch #221: loss=3.214827299118042\n",
            "Epoch #222: loss=3.4278323650360107\n",
            "Epoch #223: loss=2.055309295654297\n",
            "Epoch #224: loss=2.4716312885284424\n",
            "Epoch #225: loss=2.4811182022094727\n",
            "Epoch #226: loss=2.8244986534118652\n",
            "Epoch #227: loss=2.756619930267334\n",
            "Epoch #228: loss=2.8587911128997803\n",
            "Epoch #229: loss=2.620572566986084\n",
            "Epoch #230: loss=2.5462822914123535\n",
            "Epoch #231: loss=2.487274408340454\n",
            "Epoch #232: loss=2.230567216873169\n",
            "Epoch #233: loss=2.642019033432007\n",
            "Epoch #234: loss=2.6103968620300293\n",
            "Epoch #235: loss=2.4553864002227783\n",
            "Epoch #236: loss=2.4051241874694824\n",
            "Epoch #237: loss=2.55942964553833\n",
            "Epoch #238: loss=2.4043867588043213\n",
            "Epoch #239: loss=2.3567559719085693\n",
            "Epoch #240: loss=2.8453097343444824\n",
            "Epoch #241: loss=2.3075461387634277\n",
            "Epoch #242: loss=2.521538734436035\n",
            "Epoch #243: loss=2.697383165359497\n",
            "Epoch #244: loss=2.633676767349243\n",
            "Epoch #245: loss=2.4260382652282715\n",
            "Epoch #246: loss=2.307513952255249\n",
            "Epoch #247: loss=2.1173338890075684\n",
            "Epoch #248: loss=2.689318895339966\n",
            "Epoch #249: loss=2.5407450199127197\n",
            "Epoch #250: loss=2.5913009643554688\n",
            "Epoch #251: loss=2.7115554809570312\n",
            "Epoch #252: loss=2.3446342945098877\n",
            "Epoch #253: loss=2.225994110107422\n",
            "Epoch #254: loss=3.0154597759246826\n",
            "Epoch #255: loss=2.7466626167297363\n",
            "Epoch #256: loss=1.9255989789962769\n",
            "Epoch #257: loss=2.6584603786468506\n",
            "Epoch #258: loss=2.365936756134033\n",
            "Epoch #259: loss=2.443049669265747\n",
            "Epoch #260: loss=2.585421085357666\n",
            "Epoch #261: loss=2.730562210083008\n",
            "Epoch #262: loss=2.3801448345184326\n",
            "Epoch #263: loss=2.3508236408233643\n",
            "Epoch #264: loss=2.1517441272735596\n",
            "Epoch #265: loss=2.5027849674224854\n",
            "Epoch #266: loss=2.2719531059265137\n",
            "Epoch #267: loss=2.580279588699341\n",
            "Epoch #268: loss=2.2251174449920654\n",
            "Epoch #269: loss=2.2655720710754395\n",
            "Epoch #270: loss=2.483293056488037\n",
            "Epoch #271: loss=2.6762447357177734\n",
            "Epoch #272: loss=1.9159272909164429\n",
            "Epoch #273: loss=2.591515302658081\n",
            "Epoch #274: loss=2.409343957901001\n",
            "Epoch #275: loss=2.6722121238708496\n",
            "Epoch #276: loss=2.356252431869507\n",
            "Epoch #277: loss=2.196577548980713\n",
            "Epoch #278: loss=2.526937484741211\n",
            "Epoch #279: loss=2.3189945220947266\n",
            "Epoch #280: loss=2.3369834423065186\n",
            "Epoch #281: loss=2.3563742637634277\n",
            "Epoch #282: loss=2.3988826274871826\n",
            "Epoch #283: loss=2.2516469955444336\n",
            "Epoch #284: loss=2.120652675628662\n",
            "Epoch #285: loss=2.294203758239746\n",
            "Epoch #286: loss=2.4363796710968018\n",
            "Epoch #287: loss=2.448833465576172\n",
            "Epoch #288: loss=2.400310754776001\n",
            "Epoch #289: loss=2.183145761489868\n",
            "Epoch #290: loss=2.616896390914917\n",
            "Epoch #291: loss=2.239969253540039\n",
            "Epoch #292: loss=2.3668227195739746\n",
            "Epoch #293: loss=2.407555103302002\n",
            "Epoch #294: loss=2.074000358581543\n",
            "Epoch #295: loss=2.247235059738159\n",
            "Epoch #296: loss=2.2927498817443848\n",
            "Epoch #297: loss=2.40203595161438\n",
            "Epoch #298: loss=2.8364479541778564\n",
            "Epoch #299: loss=2.3656158447265625\n",
            "Epoch #300: loss=2.642115354537964\n",
            "Epoch #301: loss=2.5370140075683594\n",
            "Epoch #302: loss=1.8444894552230835\n",
            "Epoch #303: loss=2.2887985706329346\n",
            "Epoch #304: loss=2.4874143600463867\n",
            "Epoch #305: loss=2.5670294761657715\n",
            "Epoch #306: loss=2.2113840579986572\n",
            "Epoch #307: loss=2.9490609169006348\n",
            "Epoch #308: loss=1.452791690826416\n",
            "Epoch #309: loss=2.3583984375\n",
            "Epoch #310: loss=2.2439539432525635\n",
            "Epoch #311: loss=2.2625601291656494\n",
            "Epoch #312: loss=2.6765899658203125\n",
            "Epoch #313: loss=2.5537681579589844\n",
            "Epoch #314: loss=2.373602867126465\n",
            "Epoch #315: loss=2.0899477005004883\n",
            "Epoch #316: loss=2.0533297061920166\n",
            "Epoch #317: loss=1.822308897972107\n",
            "Epoch #318: loss=2.3109068870544434\n",
            "Epoch #319: loss=1.94673490524292\n",
            "Epoch #320: loss=2.2207159996032715\n",
            "Epoch #321: loss=2.949733018875122\n",
            "Epoch #322: loss=2.321781873703003\n",
            "Epoch #323: loss=2.4182000160217285\n",
            "Epoch #324: loss=2.823316812515259\n",
            "Epoch #325: loss=1.769891619682312\n",
            "Epoch #326: loss=2.1945607662200928\n",
            "Epoch #327: loss=2.2620885372161865\n",
            "Epoch #328: loss=2.3173367977142334\n",
            "Epoch #329: loss=2.5129470825195312\n",
            "Epoch #330: loss=1.7564564943313599\n",
            "Epoch #331: loss=2.463249921798706\n",
            "Epoch #332: loss=2.1731326580047607\n",
            "Epoch #333: loss=1.7747600078582764\n",
            "Epoch #334: loss=2.341855049133301\n",
            "Epoch #335: loss=2.2501187324523926\n",
            "Epoch #336: loss=2.2000420093536377\n",
            "Epoch #337: loss=1.771813988685608\n",
            "Epoch #338: loss=2.0705642700195312\n",
            "Epoch #339: loss=2.311983585357666\n",
            "Epoch #340: loss=2.332371711730957\n",
            "Epoch #341: loss=2.085280179977417\n",
            "Epoch #342: loss=2.4654834270477295\n",
            "Epoch #343: loss=1.5404642820358276\n",
            "Epoch #344: loss=2.410722017288208\n",
            "Epoch #345: loss=2.541943311691284\n",
            "Epoch #346: loss=2.6672191619873047\n",
            "Epoch #347: loss=2.79148006439209\n",
            "Epoch #348: loss=1.699859380722046\n",
            "Epoch #349: loss=1.8871756792068481\n",
            "Epoch #350: loss=2.457608461380005\n",
            "Epoch #351: loss=2.306427001953125\n",
            "Epoch #352: loss=2.029400110244751\n",
            "Epoch #353: loss=2.422257900238037\n",
            "Epoch #354: loss=1.8814878463745117\n",
            "Epoch #355: loss=2.221677541732788\n",
            "Epoch #356: loss=2.373898983001709\n",
            "Epoch #357: loss=2.0421383380889893\n",
            "Epoch #358: loss=3.485867738723755\n",
            "Epoch #359: loss=2.7251453399658203\n",
            "Epoch #360: loss=1.267168402671814\n",
            "Epoch #361: loss=2.329667329788208\n",
            "Epoch #362: loss=2.046747922897339\n",
            "Epoch #363: loss=1.974780797958374\n",
            "Epoch #364: loss=2.1093454360961914\n",
            "Epoch #365: loss=2.104660987854004\n",
            "Epoch #366: loss=2.2276158332824707\n",
            "Epoch #367: loss=2.194190502166748\n",
            "Epoch #368: loss=2.203733444213867\n",
            "Epoch #369: loss=2.0807340145111084\n",
            "Epoch #370: loss=2.12068510055542\n",
            "Epoch #371: loss=2.1699187755584717\n",
            "Epoch #372: loss=2.9747726917266846\n",
            "Epoch #373: loss=1.4077723026275635\n",
            "Epoch #374: loss=2.103583574295044\n",
            "Epoch #375: loss=2.0260891914367676\n",
            "Epoch #376: loss=1.5123437643051147\n",
            "Epoch #377: loss=2.7319037914276123\n",
            "Epoch #378: loss=2.0273940563201904\n",
            "Epoch #379: loss=2.3344249725341797\n",
            "Epoch #380: loss=1.7129892110824585\n",
            "Epoch #381: loss=2.032499074935913\n",
            "Epoch #382: loss=2.007826566696167\n",
            "Epoch #383: loss=1.8240060806274414\n",
            "Epoch #384: loss=1.9125961065292358\n",
            "Epoch #385: loss=1.6585513353347778\n",
            "Epoch #386: loss=2.221548080444336\n",
            "Epoch #387: loss=2.288349151611328\n",
            "Epoch #388: loss=1.997571349143982\n",
            "Epoch #389: loss=1.4731543064117432\n",
            "Epoch #390: loss=2.0338733196258545\n",
            "Epoch #391: loss=2.006335735321045\n",
            "Epoch #392: loss=1.9275802373886108\n",
            "Epoch #393: loss=1.8643978834152222\n",
            "Epoch #394: loss=2.007310390472412\n",
            "Epoch #395: loss=1.917372465133667\n",
            "Epoch #396: loss=1.68466055393219\n",
            "Epoch #397: loss=1.8319774866104126\n",
            "Epoch #398: loss=1.5530872344970703\n",
            "Epoch #399: loss=2.297663927078247\n",
            "Epoch #400: loss=1.8343238830566406\n",
            "Epoch #401: loss=2.182748556137085\n",
            "Epoch #402: loss=2.36051869392395\n",
            "Epoch #403: loss=2.669179916381836\n",
            "Epoch #404: loss=2.670959711074829\n",
            "Epoch #405: loss=1.8370800018310547\n",
            "Epoch #406: loss=2.070493698120117\n",
            "Epoch #407: loss=1.9719667434692383\n",
            "Epoch #408: loss=2.5278656482696533\n",
            "Epoch #409: loss=1.1827433109283447\n",
            "Epoch #410: loss=2.131274461746216\n",
            "Epoch #411: loss=2.0245847702026367\n",
            "Epoch #412: loss=1.817016363143921\n",
            "Epoch #413: loss=1.781150460243225\n",
            "Epoch #414: loss=1.9488604068756104\n",
            "Epoch #415: loss=2.321950912475586\n",
            "Epoch #416: loss=1.9193105697631836\n",
            "Epoch #417: loss=1.9816404581069946\n",
            "Epoch #418: loss=2.379289388656616\n",
            "Epoch #419: loss=2.258253812789917\n",
            "Epoch #420: loss=1.7117624282836914\n",
            "Epoch #421: loss=1.3480678796768188\n",
            "Epoch #422: loss=2.7362124919891357\n",
            "Epoch #423: loss=1.7039538621902466\n",
            "Epoch #424: loss=1.7245476245880127\n",
            "Epoch #425: loss=1.7288405895233154\n",
            "Epoch #426: loss=1.7203150987625122\n",
            "Epoch #427: loss=1.8890774250030518\n",
            "Epoch #428: loss=2.125683069229126\n",
            "Epoch #429: loss=1.785038709640503\n",
            "Epoch #430: loss=1.7677961587905884\n",
            "Epoch #431: loss=1.768401026725769\n",
            "Epoch #432: loss=1.5972490310668945\n",
            "Epoch #433: loss=1.7394416332244873\n",
            "Epoch #434: loss=1.1097966432571411\n",
            "Epoch #435: loss=1.9091777801513672\n",
            "Epoch #436: loss=1.869279146194458\n",
            "Epoch #437: loss=1.6485055685043335\n",
            "Epoch #438: loss=2.9154422283172607\n",
            "Epoch #439: loss=3.211987257003784\n",
            "Epoch #440: loss=0.9616790413856506\n",
            "Epoch #441: loss=1.665747046470642\n",
            "Epoch #442: loss=2.0303750038146973\n",
            "Epoch #443: loss=2.3667306900024414\n",
            "Epoch #444: loss=1.7434115409851074\n",
            "Epoch #445: loss=1.773971438407898\n",
            "Epoch #446: loss=1.7228913307189941\n",
            "Epoch #447: loss=1.7791318893432617\n",
            "Epoch #448: loss=1.4489234685897827\n",
            "Epoch #449: loss=2.319524049758911\n",
            "Epoch #450: loss=1.5112559795379639\n",
            "Epoch #451: loss=1.4201679229736328\n",
            "Epoch #452: loss=1.8003002405166626\n",
            "Epoch #453: loss=2.00394868850708\n",
            "Epoch #454: loss=2.0250244140625\n",
            "Epoch #455: loss=1.2901076078414917\n",
            "Epoch #456: loss=1.7388337850570679\n",
            "Epoch #457: loss=1.2265676259994507\n",
            "Epoch #458: loss=1.9898862838745117\n",
            "Epoch #459: loss=2.0323801040649414\n",
            "Epoch #460: loss=2.007936716079712\n",
            "Epoch #461: loss=1.8717291355133057\n",
            "Epoch #462: loss=1.8971331119537354\n",
            "Epoch #463: loss=2.0150034427642822\n",
            "Epoch #464: loss=1.741131067276001\n",
            "Epoch #465: loss=2.025552988052368\n",
            "Epoch #466: loss=2.098862886428833\n",
            "Epoch #467: loss=1.7778552770614624\n",
            "Epoch #468: loss=1.687592625617981\n",
            "Epoch #469: loss=1.6123950481414795\n",
            "Epoch #470: loss=1.5551837682724\n",
            "Epoch #471: loss=1.8136969804763794\n",
            "Epoch #472: loss=1.7161293029785156\n",
            "Epoch #473: loss=1.5750279426574707\n",
            "Epoch #474: loss=2.214705467224121\n",
            "Epoch #475: loss=1.5556710958480835\n",
            "Epoch #476: loss=1.9004672765731812\n",
            "Epoch #477: loss=1.5763121843338013\n",
            "Epoch #478: loss=1.4081213474273682\n",
            "Epoch #479: loss=1.8914661407470703\n",
            "Epoch #480: loss=1.1645203828811646\n",
            "Epoch #481: loss=1.7029900550842285\n",
            "Epoch #482: loss=1.5283863544464111\n",
            "Epoch #483: loss=1.6215872764587402\n",
            "Epoch #484: loss=2.0060572624206543\n",
            "Epoch #485: loss=1.5411943197250366\n",
            "Epoch #486: loss=1.3979668617248535\n",
            "Epoch #487: loss=1.952510952949524\n",
            "Epoch #488: loss=1.3280504941940308\n",
            "Epoch #489: loss=1.3107713460922241\n",
            "Epoch #490: loss=1.9752215147018433\n",
            "Epoch #491: loss=1.882320523262024\n",
            "Epoch #492: loss=1.6863961219787598\n",
            "Epoch #493: loss=1.733560562133789\n",
            "Epoch #494: loss=1.5873079299926758\n",
            "Epoch #495: loss=2.1273741722106934\n",
            "Epoch #496: loss=1.3249481916427612\n",
            "Epoch #497: loss=1.6248223781585693\n",
            "Epoch #498: loss=1.5210399627685547\n",
            "Epoch #499: loss=1.7819008827209473\n",
            "Epoch #500: loss=1.4141764640808105\n",
            "Epoch #501: loss=1.8783141374588013\n",
            "Epoch #502: loss=1.8516448736190796\n",
            "Epoch #503: loss=1.736716628074646\n",
            "Epoch #504: loss=1.687612533569336\n",
            "Epoch #505: loss=1.7386736869812012\n",
            "Epoch #506: loss=1.0794553756713867\n",
            "Epoch #507: loss=2.6974334716796875\n",
            "Epoch #508: loss=0.8079079389572144\n",
            "Epoch #509: loss=1.4172557592391968\n",
            "Epoch #510: loss=1.647341251373291\n",
            "Epoch #511: loss=1.7845160961151123\n",
            "Epoch #512: loss=1.7636277675628662\n",
            "Epoch #513: loss=1.3345352411270142\n",
            "Epoch #514: loss=1.6378378868103027\n",
            "Epoch #515: loss=2.665966510772705\n",
            "Epoch #516: loss=2.365220785140991\n",
            "Epoch #517: loss=1.3902747631072998\n",
            "Epoch #518: loss=1.0496519804000854\n",
            "Epoch #519: loss=1.7184420824050903\n",
            "Epoch #520: loss=1.8227031230926514\n",
            "Epoch #521: loss=1.9939631223678589\n",
            "Epoch #522: loss=1.8711663484573364\n",
            "Epoch #523: loss=1.7210767269134521\n",
            "Epoch #524: loss=1.3441041707992554\n",
            "Epoch #525: loss=1.3066197633743286\n",
            "Epoch #526: loss=1.976948857307434\n",
            "Epoch #527: loss=1.0876084566116333\n",
            "Epoch #528: loss=1.5731158256530762\n",
            "Epoch #529: loss=2.049959659576416\n",
            "Epoch #530: loss=1.6895370483398438\n",
            "Epoch #531: loss=1.6153329610824585\n",
            "Epoch #532: loss=2.3363394737243652\n",
            "Epoch #533: loss=1.829740285873413\n",
            "Epoch #534: loss=2.0954372882843018\n",
            "Epoch #535: loss=1.9534395933151245\n",
            "Epoch #536: loss=2.076481580734253\n",
            "Epoch #537: loss=2.3910722732543945\n",
            "Epoch #538: loss=2.648386001586914\n",
            "Epoch #539: loss=2.064194440841675\n",
            "Epoch #540: loss=0.7857750058174133\n",
            "Epoch #541: loss=1.3050835132598877\n",
            "Epoch #542: loss=1.838186502456665\n",
            "Epoch #543: loss=1.860611081123352\n",
            "Epoch #544: loss=1.1414756774902344\n",
            "Epoch #545: loss=2.4135916233062744\n",
            "Epoch #546: loss=1.3984273672103882\n",
            "Epoch #547: loss=0.9051446914672852\n",
            "Epoch #548: loss=1.6610170602798462\n",
            "Epoch #549: loss=1.8879331350326538\n",
            "Epoch #550: loss=1.438978910446167\n",
            "Epoch #551: loss=1.7918319702148438\n",
            "Epoch #552: loss=1.687609314918518\n",
            "Epoch #553: loss=1.571592926979065\n",
            "Epoch #554: loss=1.9575142860412598\n",
            "Epoch #555: loss=1.3474239110946655\n",
            "Epoch #556: loss=1.1540549993515015\n",
            "Epoch #557: loss=1.2401666641235352\n",
            "Epoch #558: loss=1.423603892326355\n",
            "Epoch #559: loss=1.4276691675186157\n",
            "Epoch #560: loss=1.0481096506118774\n",
            "Epoch #561: loss=1.2716161012649536\n",
            "Epoch #562: loss=1.4411404132843018\n",
            "Epoch #563: loss=1.8440767526626587\n",
            "Epoch #564: loss=1.9073901176452637\n",
            "Epoch #565: loss=0.7648788690567017\n",
            "Epoch #566: loss=1.4422402381896973\n",
            "Epoch #567: loss=1.7219734191894531\n",
            "Epoch #568: loss=1.3268401622772217\n",
            "Epoch #569: loss=1.1295678615570068\n",
            "Epoch #570: loss=1.4558547735214233\n",
            "Epoch #571: loss=1.8276267051696777\n",
            "Epoch #572: loss=1.6685866117477417\n",
            "Epoch #573: loss=1.7369942665100098\n",
            "Epoch #574: loss=1.9337286949157715\n",
            "Epoch #575: loss=1.7584701776504517\n",
            "Epoch #576: loss=1.3236050605773926\n",
            "Epoch #577: loss=1.9718327522277832\n",
            "Epoch #578: loss=0.918705940246582\n",
            "Epoch #579: loss=1.3038771152496338\n",
            "Epoch #580: loss=1.4285321235656738\n",
            "Epoch #581: loss=2.401050329208374\n",
            "Epoch #582: loss=1.0403865575790405\n",
            "Epoch #583: loss=1.4014211893081665\n",
            "Epoch #584: loss=2.097780466079712\n",
            "Epoch #585: loss=2.074509859085083\n",
            "Epoch #586: loss=1.7744927406311035\n",
            "Epoch #587: loss=0.8291884064674377\n",
            "Epoch #588: loss=1.4499658346176147\n",
            "Epoch #589: loss=0.899704098701477\n",
            "Epoch #590: loss=1.135859489440918\n",
            "Epoch #591: loss=1.5591638088226318\n",
            "Epoch #592: loss=0.786857008934021\n",
            "Epoch #593: loss=1.4404563903808594\n",
            "Epoch #594: loss=1.4076554775238037\n",
            "Epoch #595: loss=1.0754523277282715\n",
            "Epoch #596: loss=1.4141795635223389\n",
            "Epoch #597: loss=1.236918330192566\n",
            "Epoch #598: loss=1.403405785560608\n",
            "Epoch #599: loss=1.5986812114715576\n",
            "\n",
            "Training time: 0:15:30.112719\n",
            "\n",
            "Evaluation result: {'ours': {24: {'norm': {'MSE': 0.2442109960466285, 'MAE': 0.2622140591737076}, 'raw': {'MSE': 143.19646766231705, 'MAE': 6.349499909490429}}, 48: {'norm': {'MSE': 0.2918767186193153, 'MAE': 0.29563815394280424}, 'raw': {'MSE': 171.14591836360128, 'MAE': 7.158862650524269}}, 168: {'norm': {'MSE': 0.40428740633817445, 'MAE': 0.372492333449994}, 'raw': {'MSE': 237.05946826514707, 'MAE': 9.019882694423565}}, 336: {'norm': {'MSE': 0.5636826141202899, 'MAE': 0.4636978448599709}, 'raw': {'MSE': 330.52303509047715, 'MAE': 11.228419463063172}}, 720: {'norm': {'MSE': 0.8936854490330902, 'MAE': 0.6443403760773699}, 'raw': {'MSE': 524.0247216220362, 'MAE': 15.60266899319614}}}, 'encoder_infer_time': 12.43719744682312, 'lr_train_time': {24: 2.2251675128936768, 48: 1.557065725326538, 168: 1.9134879112243652, 336: 2.654899835586548, 720: 4.803322792053223}, 'lr_infer_time': {24: 0.007628917694091797, 48: 0.009168863296508789, 168: 0.014529705047607422, 336: 0.024467945098876953, 720: 0.09717726707458496}}\n",
            "Finished.\n"
          ]
        }
      ]
    }
  ]
}