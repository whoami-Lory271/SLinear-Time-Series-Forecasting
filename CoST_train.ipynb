{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whoami-Lory271/thesis-project/blob/main/CoST_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training CoST model"
      ],
      "metadata": {
        "id": "Gh2L5z66W2X6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1LWptcrfWeZG",
        "outputId": "da941c4e-7390-465e-ddc9-21f7e858eda6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CoST'...\n",
            "remote: Enumerating objects: 70, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 70 (delta 14), reused 14 (delta 14), pack-reused 43\u001b[K\n",
            "Receiving objects: 100% (70/70), 368.19 KiB | 3.57 MiB/s, done.\n",
            "Resolving deltas: 100% (27/27), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/salesforce/CoST.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5EIFz57FW_Wh",
        "outputId": "82f4f3a5-2a30-4aa6-b7ab-033569fa5104",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/Tesi/code/datasets/electricity/LD2011_2014.txt\" \"/content/CoST/datasets/\""
      ],
      "metadata": {
        "id": "0hTJksSZXPcX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/CoST/requirements.txt\n",
        "!pip install einops==0.6.1 --quiet"
      ],
      "metadata": {
        "id": "x5qeqzGyXkx9",
        "outputId": "3e073513-ce32-4f8d-d81d-bcc53a1d505a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scipy==1.6.1 (from -r /content/CoST/requirements.txt (line 1))\n",
            "  Downloading scipy-1.6.1.tar.gz (27.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.9.0 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.9.0\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/CoST/datasets; python electricity.py"
      ],
      "metadata": {
        "id": "A_zO0vylX_fF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cd /content/CoST; sh scripts/Electricity_CoST.sh"
      ],
      "metadata": {
        "id": "JDtXGWSiYvBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/CoST; python -u train.py electricity forecast_univar --alpha 0.0005 --kernels 1 2 4 8 16 32 64 128 --max-train-length 201 --batch-size 128 --archive forecast_csv_univar --repr-dims 320 --max-threads 8 --seed 1 --eval"
      ],
      "metadata": {
        "id": "cHGjomTozYI6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b27ee5f0-ccd8-4d92-ff26-e189ef736d03"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: electricity\n",
            "Arguments: Namespace(dataset='electricity', run_name='forecast_univar', archive='forecast_csv_univar', gpu=0, batch_size=128, lr=0.001, repr_dims=320, max_train_length=201, iters=None, epochs=None, save_every=None, seed=1, max_threads=8, eval=True, kernels=[1, 2, 4, 8, 16, 32, 64, 128], alpha=0.0005)\n",
            "/content/CoST/datautils.py:30: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series. To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
            "  dt.weekofyear.to_numpy(),\n",
            "Epoch #0: loss=0.06056727468967438\n",
            "Epoch #1: loss=4.238088130950928\n",
            "Epoch #2: loss=4.913817405700684\n",
            "Epoch #3: loss=4.793126583099365\n",
            "Epoch #4: loss=4.825410842895508\n",
            "Epoch #5: loss=4.691321849822998\n",
            "Epoch #6: loss=4.604249954223633\n",
            "Epoch #7: loss=4.510466575622559\n",
            "Epoch #8: loss=4.4808669090271\n",
            "Epoch #9: loss=4.477336883544922\n",
            "Epoch #10: loss=4.712864398956299\n",
            "Epoch #11: loss=4.233528137207031\n",
            "Epoch #12: loss=4.482581615447998\n",
            "Epoch #13: loss=4.218894958496094\n",
            "Epoch #14: loss=4.173020362854004\n",
            "Epoch #15: loss=4.2906413078308105\n",
            "Epoch #16: loss=4.220554351806641\n",
            "Epoch #17: loss=4.329725742340088\n",
            "Epoch #18: loss=4.173303604125977\n",
            "Epoch #19: loss=4.1834611892700195\n",
            "Epoch #20: loss=4.076681137084961\n",
            "Epoch #21: loss=4.121207237243652\n",
            "Epoch #22: loss=3.8155171871185303\n",
            "Epoch #23: loss=4.286764621734619\n",
            "Epoch #24: loss=3.7629055976867676\n",
            "Epoch #25: loss=3.8010072708129883\n",
            "Epoch #26: loss=3.846543550491333\n",
            "Epoch #27: loss=3.817701578140259\n",
            "Epoch #28: loss=3.8882782459259033\n",
            "Epoch #29: loss=3.7370948791503906\n",
            "Epoch #30: loss=3.881833076477051\n",
            "Epoch #31: loss=3.984734535217285\n",
            "Epoch #32: loss=3.430729627609253\n",
            "Epoch #33: loss=3.6798524856567383\n",
            "Epoch #34: loss=3.7322893142700195\n",
            "Epoch #35: loss=3.6973190307617188\n",
            "Epoch #36: loss=3.565889358520508\n",
            "Epoch #37: loss=3.6116912364959717\n",
            "Epoch #38: loss=3.650665044784546\n",
            "Epoch #39: loss=3.678234100341797\n",
            "Epoch #40: loss=3.6359798908233643\n",
            "Epoch #41: loss=3.526157855987549\n",
            "Epoch #42: loss=3.650627851486206\n",
            "Epoch #43: loss=3.5889625549316406\n",
            "Epoch #44: loss=3.6445982456207275\n",
            "Epoch #45: loss=3.3858962059020996\n",
            "Epoch #46: loss=3.843672037124634\n",
            "Epoch #47: loss=3.396152973175049\n",
            "Epoch #48: loss=3.5463035106658936\n",
            "Epoch #49: loss=3.422044038772583\n",
            "Epoch #50: loss=3.441359519958496\n",
            "Epoch #51: loss=3.4038937091827393\n",
            "Epoch #52: loss=3.4415547847747803\n",
            "Epoch #53: loss=3.2281248569488525\n",
            "Epoch #54: loss=3.296738862991333\n",
            "Epoch #55: loss=3.5579264163970947\n",
            "Epoch #56: loss=3.2880332469940186\n",
            "Epoch #57: loss=3.0732498168945312\n",
            "Epoch #58: loss=3.4732534885406494\n",
            "Epoch #59: loss=3.353590488433838\n",
            "Epoch #60: loss=3.4110686779022217\n",
            "Epoch #61: loss=3.1703152656555176\n",
            "Epoch #62: loss=3.248199224472046\n",
            "Epoch #63: loss=3.404440402984619\n",
            "Epoch #64: loss=3.3933420181274414\n",
            "Epoch #65: loss=3.245311737060547\n",
            "Epoch #66: loss=3.2709245681762695\n",
            "Epoch #67: loss=3.1620805263519287\n",
            "Epoch #68: loss=3.2693803310394287\n",
            "Epoch #69: loss=3.261732339859009\n",
            "Epoch #70: loss=3.452171564102173\n",
            "Epoch #71: loss=3.2046430110931396\n",
            "Epoch #72: loss=3.1546428203582764\n",
            "Epoch #73: loss=3.3951210975646973\n",
            "Epoch #74: loss=3.0919578075408936\n",
            "Epoch #75: loss=3.091606616973877\n",
            "Epoch #76: loss=3.3986988067626953\n",
            "Epoch #77: loss=3.2406373023986816\n",
            "Epoch #78: loss=3.192359447479248\n",
            "Epoch #79: loss=3.23750638961792\n",
            "Epoch #80: loss=3.2556381225585938\n",
            "Epoch #81: loss=3.2302091121673584\n",
            "Epoch #82: loss=3.345012664794922\n",
            "Epoch #83: loss=3.5807371139526367\n",
            "Epoch #84: loss=3.4742844104766846\n",
            "Epoch #85: loss=3.471270799636841\n",
            "Epoch #86: loss=2.9139533042907715\n",
            "Epoch #87: loss=2.9685914516448975\n",
            "Epoch #88: loss=3.100710391998291\n",
            "Epoch #89: loss=3.082386016845703\n",
            "Epoch #90: loss=3.198115587234497\n",
            "Epoch #91: loss=2.9861185550689697\n",
            "Epoch #92: loss=3.1624512672424316\n",
            "Epoch #93: loss=3.291667938232422\n",
            "Epoch #94: loss=3.299746513366699\n",
            "Epoch #95: loss=2.756819725036621\n",
            "Epoch #96: loss=2.923226833343506\n",
            "Epoch #97: loss=3.1606411933898926\n",
            "Epoch #98: loss=3.0737991333007812\n",
            "Epoch #99: loss=3.121908664703369\n",
            "Epoch #100: loss=3.088226556777954\n",
            "Epoch #101: loss=3.2685978412628174\n",
            "Epoch #102: loss=3.0209286212921143\n",
            "Epoch #103: loss=3.0825319290161133\n",
            "Epoch #104: loss=2.961691379547119\n",
            "Epoch #105: loss=3.1219639778137207\n",
            "Epoch #106: loss=3.412111520767212\n",
            "Epoch #107: loss=2.8870043754577637\n",
            "Epoch #108: loss=3.0436806678771973\n",
            "Epoch #109: loss=3.1277904510498047\n",
            "Epoch #110: loss=3.1665334701538086\n",
            "Epoch #111: loss=3.117771625518799\n",
            "Epoch #112: loss=3.2081568241119385\n",
            "Epoch #113: loss=2.910111427307129\n",
            "Epoch #114: loss=3.1177072525024414\n",
            "Epoch #115: loss=3.1877734661102295\n",
            "Epoch #116: loss=2.857302188873291\n",
            "Epoch #117: loss=2.9733152389526367\n",
            "Epoch #118: loss=3.1820900440216064\n",
            "Epoch #119: loss=3.0392327308654785\n",
            "Epoch #120: loss=3.028740406036377\n",
            "Epoch #121: loss=2.890146493911743\n",
            "Epoch #122: loss=3.306915044784546\n",
            "Epoch #123: loss=2.64514422416687\n",
            "Epoch #124: loss=2.822556734085083\n",
            "Epoch #125: loss=2.9597086906433105\n",
            "Epoch #126: loss=3.02614164352417\n",
            "Epoch #127: loss=2.7849302291870117\n",
            "Epoch #128: loss=3.1257872581481934\n",
            "Epoch #129: loss=3.025592803955078\n",
            "Epoch #130: loss=2.940042734146118\n",
            "Epoch #131: loss=2.891571283340454\n",
            "Epoch #132: loss=2.9383597373962402\n",
            "Epoch #133: loss=3.282639741897583\n",
            "Epoch #134: loss=2.455173969268799\n",
            "Epoch #135: loss=2.808419942855835\n",
            "Epoch #136: loss=2.9153318405151367\n",
            "Epoch #137: loss=3.0897467136383057\n",
            "Epoch #138: loss=3.0706355571746826\n",
            "Epoch #139: loss=2.9531843662261963\n",
            "Epoch #140: loss=2.603034257888794\n",
            "Epoch #141: loss=2.7079334259033203\n",
            "Epoch #142: loss=3.2309300899505615\n",
            "Epoch #143: loss=2.9538414478302\n",
            "Epoch #144: loss=2.7979342937469482\n",
            "Epoch #145: loss=3.0380806922912598\n",
            "Epoch #146: loss=2.8438100814819336\n",
            "Epoch #147: loss=2.6483116149902344\n",
            "Epoch #148: loss=3.191054582595825\n",
            "Epoch #149: loss=2.730748176574707\n",
            "Epoch #150: loss=3.226318836212158\n",
            "Epoch #151: loss=2.573220729827881\n",
            "Epoch #152: loss=2.88722825050354\n",
            "Epoch #153: loss=3.0754165649414062\n",
            "Epoch #154: loss=2.964479446411133\n",
            "Epoch #155: loss=3.0059292316436768\n",
            "Epoch #156: loss=2.6127195358276367\n",
            "Epoch #157: loss=2.8114664554595947\n",
            "Epoch #158: loss=2.8856282234191895\n",
            "Epoch #159: loss=2.771026134490967\n",
            "Epoch #160: loss=2.9066123962402344\n",
            "Epoch #161: loss=2.857999563217163\n",
            "Epoch #162: loss=2.979236125946045\n",
            "Epoch #163: loss=2.8089561462402344\n",
            "Epoch #164: loss=2.6207547187805176\n",
            "Epoch #165: loss=2.8416519165039062\n",
            "Epoch #166: loss=2.8336129188537598\n",
            "Epoch #167: loss=2.752117395401001\n",
            "Epoch #168: loss=2.940396547317505\n",
            "Epoch #169: loss=2.627070426940918\n",
            "Epoch #170: loss=2.678245782852173\n",
            "Epoch #171: loss=2.7692086696624756\n",
            "Epoch #172: loss=2.5994179248809814\n",
            "Epoch #173: loss=2.500420331954956\n",
            "Epoch #174: loss=2.9441750049591064\n",
            "Epoch #175: loss=2.81400728225708\n",
            "Epoch #176: loss=2.721388578414917\n",
            "Epoch #177: loss=3.0637190341949463\n",
            "Epoch #178: loss=2.803337335586548\n",
            "Epoch #179: loss=2.8636744022369385\n",
            "Epoch #180: loss=3.274735927581787\n",
            "Epoch #181: loss=2.4401392936706543\n",
            "Epoch #182: loss=2.3982150554656982\n",
            "Epoch #183: loss=2.866255521774292\n",
            "Epoch #184: loss=2.63602352142334\n",
            "Epoch #185: loss=2.6569936275482178\n",
            "Epoch #186: loss=2.850306510925293\n",
            "Epoch #187: loss=3.0566320419311523\n",
            "Epoch #188: loss=2.9239277839660645\n",
            "Epoch #189: loss=2.8049769401550293\n",
            "Epoch #190: loss=2.8901989459991455\n",
            "Epoch #191: loss=2.9965529441833496\n",
            "Epoch #192: loss=2.777334213256836\n",
            "Epoch #193: loss=2.637024402618408\n",
            "Epoch #194: loss=2.5987184047698975\n",
            "Epoch #195: loss=2.831465482711792\n",
            "Epoch #196: loss=2.943406581878662\n",
            "Epoch #197: loss=2.746729850769043\n",
            "Epoch #198: loss=2.7396934032440186\n",
            "Epoch #199: loss=2.6545352935791016\n",
            "Epoch #200: loss=2.9518990516662598\n",
            "Epoch #201: loss=3.217884063720703\n",
            "Epoch #202: loss=2.543682336807251\n",
            "Epoch #203: loss=2.6761085987091064\n",
            "Epoch #204: loss=2.7797253131866455\n",
            "Epoch #205: loss=2.81290864944458\n",
            "Epoch #206: loss=2.7713558673858643\n",
            "Epoch #207: loss=2.6352691650390625\n",
            "Epoch #208: loss=2.7564985752105713\n",
            "Epoch #209: loss=3.0505728721618652\n",
            "Epoch #210: loss=2.532904624938965\n",
            "Epoch #211: loss=3.362330198287964\n",
            "Epoch #212: loss=2.7563745975494385\n",
            "Epoch #213: loss=2.5234787464141846\n",
            "Epoch #214: loss=2.433448076248169\n",
            "Epoch #215: loss=2.6750335693359375\n",
            "Epoch #216: loss=2.6753897666931152\n",
            "Epoch #217: loss=2.459289789199829\n",
            "Epoch #218: loss=2.860114812850952\n",
            "Epoch #219: loss=2.3281471729278564\n",
            "Epoch #220: loss=3.292647361755371\n",
            "Epoch #221: loss=3.2146339416503906\n",
            "Epoch #222: loss=3.4273970127105713\n",
            "Epoch #223: loss=2.05502986907959\n",
            "Epoch #224: loss=2.471679210662842\n",
            "Epoch #225: loss=2.481706142425537\n",
            "Epoch #226: loss=2.824625015258789\n",
            "Epoch #227: loss=2.7567496299743652\n",
            "Epoch #228: loss=2.859361171722412\n",
            "Epoch #229: loss=2.6206209659576416\n",
            "Epoch #230: loss=2.545846462249756\n",
            "Epoch #231: loss=2.4876503944396973\n",
            "Epoch #232: loss=2.230807304382324\n",
            "Epoch #233: loss=2.642162799835205\n",
            "Epoch #234: loss=2.6092641353607178\n",
            "Epoch #235: loss=2.4549081325531006\n",
            "Epoch #236: loss=2.4044740200042725\n",
            "Epoch #237: loss=2.560084342956543\n",
            "Epoch #238: loss=2.4040143489837646\n",
            "Epoch #239: loss=2.3553671836853027\n",
            "Epoch #240: loss=2.845672130584717\n",
            "Epoch #241: loss=2.3064632415771484\n",
            "Epoch #242: loss=2.521652936935425\n",
            "Epoch #243: loss=2.697056531906128\n",
            "Epoch #244: loss=2.6330409049987793\n",
            "Epoch #245: loss=2.4265174865722656\n",
            "Epoch #246: loss=2.3065059185028076\n",
            "Epoch #247: loss=2.1179444789886475\n",
            "Epoch #248: loss=2.689263105392456\n",
            "Epoch #249: loss=2.5408153533935547\n",
            "Epoch #250: loss=2.591951847076416\n",
            "Epoch #251: loss=2.711277723312378\n",
            "Epoch #252: loss=2.344949960708618\n",
            "Epoch #253: loss=2.226846694946289\n",
            "Epoch #254: loss=3.0152900218963623\n",
            "Epoch #255: loss=2.746391773223877\n",
            "Epoch #256: loss=1.9261844158172607\n",
            "Epoch #257: loss=2.6587626934051514\n",
            "Epoch #258: loss=2.3661575317382812\n",
            "Epoch #259: loss=2.4430418014526367\n",
            "Epoch #260: loss=2.5861780643463135\n",
            "Epoch #261: loss=2.730168581008911\n",
            "Epoch #262: loss=2.3794753551483154\n",
            "Epoch #263: loss=2.3514585494995117\n",
            "Epoch #264: loss=2.1522724628448486\n",
            "Epoch #265: loss=2.502882480621338\n",
            "Epoch #266: loss=2.2722651958465576\n",
            "Epoch #267: loss=2.58001708984375\n",
            "Epoch #268: loss=2.225578546524048\n",
            "Epoch #269: loss=2.2654805183410645\n",
            "Epoch #270: loss=2.4830901622772217\n",
            "Epoch #271: loss=2.676504135131836\n",
            "Epoch #272: loss=1.9165847301483154\n",
            "Epoch #273: loss=2.5909531116485596\n",
            "Epoch #274: loss=2.408816337585449\n",
            "Epoch #275: loss=2.672417163848877\n",
            "Epoch #276: loss=2.3566925525665283\n",
            "Epoch #277: loss=2.1966919898986816\n",
            "Epoch #278: loss=2.5266799926757812\n",
            "Epoch #279: loss=2.318711280822754\n",
            "Epoch #280: loss=2.3369345664978027\n",
            "Epoch #281: loss=2.3568902015686035\n",
            "Epoch #282: loss=2.39872407913208\n",
            "Epoch #283: loss=2.251859426498413\n",
            "Epoch #284: loss=2.1211605072021484\n",
            "Epoch #285: loss=2.2937734127044678\n",
            "Epoch #286: loss=2.436051368713379\n",
            "Epoch #287: loss=2.448638677597046\n",
            "Epoch #288: loss=2.399960994720459\n",
            "Epoch #289: loss=2.183298349380493\n",
            "Epoch #290: loss=2.61635684967041\n",
            "Epoch #291: loss=2.239422082901001\n",
            "Epoch #292: loss=2.3667547702789307\n",
            "Epoch #293: loss=2.407719373703003\n",
            "Epoch #294: loss=2.074467897415161\n",
            "Epoch #295: loss=2.2474896907806396\n",
            "Epoch #296: loss=2.2927918434143066\n",
            "Epoch #297: loss=2.4013333320617676\n",
            "Epoch #298: loss=2.8364853858947754\n",
            "Epoch #299: loss=2.3667635917663574\n",
            "Epoch #300: loss=2.6425840854644775\n",
            "Epoch #301: loss=2.537139415740967\n",
            "Epoch #302: loss=1.8436094522476196\n",
            "Epoch #303: loss=2.2889199256896973\n",
            "Epoch #304: loss=2.487942934036255\n",
            "Epoch #305: loss=2.5674684047698975\n",
            "Epoch #306: loss=2.2113077640533447\n",
            "Epoch #307: loss=2.948827028274536\n",
            "Epoch #308: loss=1.4525080919265747\n",
            "Epoch #309: loss=2.358558177947998\n",
            "Epoch #310: loss=2.244839668273926\n",
            "Epoch #311: loss=2.2631735801696777\n",
            "Epoch #312: loss=2.6767871379852295\n",
            "Epoch #313: loss=2.553881883621216\n",
            "Epoch #314: loss=2.373744487762451\n",
            "Epoch #315: loss=2.0897858142852783\n",
            "Epoch #316: loss=2.054009437561035\n",
            "Epoch #317: loss=1.8217558860778809\n",
            "Epoch #318: loss=2.3102664947509766\n",
            "Epoch #319: loss=1.9470480680465698\n",
            "Epoch #320: loss=2.2205846309661865\n",
            "Epoch #321: loss=2.949779748916626\n",
            "Epoch #322: loss=2.3217709064483643\n",
            "Epoch #323: loss=2.418663263320923\n",
            "Epoch #324: loss=2.8232648372650146\n",
            "Epoch #325: loss=1.769987940788269\n",
            "Epoch #326: loss=2.1947200298309326\n",
            "Epoch #327: loss=2.263005495071411\n",
            "Epoch #328: loss=2.3172245025634766\n",
            "Epoch #329: loss=2.5126547813415527\n",
            "Epoch #330: loss=1.7566101551055908\n",
            "Epoch #331: loss=2.4631171226501465\n",
            "Epoch #332: loss=2.1730763912200928\n",
            "Epoch #333: loss=1.7742382287979126\n",
            "Epoch #334: loss=2.341657876968384\n",
            "Epoch #335: loss=2.251328706741333\n",
            "Epoch #336: loss=2.200079917907715\n",
            "Epoch #337: loss=1.7712762355804443\n",
            "Epoch #338: loss=2.0705552101135254\n",
            "Epoch #339: loss=2.3118221759796143\n",
            "Epoch #340: loss=2.332075595855713\n",
            "Epoch #341: loss=2.085531234741211\n",
            "Epoch #342: loss=2.465672731399536\n",
            "Epoch #343: loss=1.5394964218139648\n",
            "Epoch #344: loss=2.4103798866271973\n",
            "Epoch #345: loss=2.5415902137756348\n",
            "Epoch #346: loss=2.6673758029937744\n",
            "Epoch #347: loss=2.7918055057525635\n",
            "Epoch #348: loss=1.6990936994552612\n",
            "Epoch #349: loss=1.8872185945510864\n",
            "Epoch #350: loss=2.458439350128174\n",
            "Epoch #351: loss=2.306452751159668\n",
            "Epoch #352: loss=2.030107021331787\n",
            "Epoch #353: loss=2.423091173171997\n",
            "Epoch #354: loss=1.8816373348236084\n",
            "Epoch #355: loss=2.221522808074951\n",
            "Epoch #356: loss=2.3743958473205566\n",
            "Epoch #357: loss=2.042062520980835\n",
            "Epoch #358: loss=3.4859414100646973\n",
            "Epoch #359: loss=2.723900556564331\n",
            "Epoch #360: loss=1.2675602436065674\n",
            "Epoch #361: loss=2.329437494277954\n",
            "Epoch #362: loss=2.046818256378174\n",
            "Epoch #363: loss=1.9750988483428955\n",
            "Epoch #364: loss=2.1093437671661377\n",
            "Epoch #365: loss=2.104748249053955\n",
            "Epoch #366: loss=2.227078914642334\n",
            "Epoch #367: loss=2.194314479827881\n",
            "Epoch #368: loss=2.2040457725524902\n",
            "Epoch #369: loss=2.080712080001831\n",
            "Epoch #370: loss=2.1199729442596436\n",
            "Epoch #371: loss=2.1701135635375977\n",
            "Epoch #372: loss=2.9752228260040283\n",
            "Epoch #373: loss=1.4081624746322632\n",
            "Epoch #374: loss=2.103452444076538\n",
            "Epoch #375: loss=2.026594638824463\n",
            "Epoch #376: loss=1.5129547119140625\n",
            "Epoch #377: loss=2.7319610118865967\n",
            "Epoch #378: loss=2.027745485305786\n",
            "Epoch #379: loss=2.3338990211486816\n",
            "Epoch #380: loss=1.712702751159668\n",
            "Epoch #381: loss=2.0322253704071045\n",
            "Epoch #382: loss=2.0082483291625977\n",
            "Epoch #383: loss=1.8241599798202515\n",
            "Epoch #384: loss=1.912255883216858\n",
            "Epoch #385: loss=1.6582996845245361\n",
            "Epoch #386: loss=2.221632719039917\n",
            "Epoch #387: loss=2.2885851860046387\n",
            "Epoch #388: loss=1.9978009462356567\n",
            "Epoch #389: loss=1.4725180864334106\n",
            "Epoch #390: loss=2.034870147705078\n",
            "Epoch #391: loss=2.006603956222534\n",
            "Epoch #392: loss=1.9271502494812012\n",
            "Epoch #393: loss=1.8648699522018433\n",
            "Epoch #394: loss=2.007861375808716\n",
            "Epoch #395: loss=1.9179887771606445\n",
            "Epoch #396: loss=1.6842803955078125\n",
            "Epoch #397: loss=1.8322374820709229\n",
            "Epoch #398: loss=1.553320288658142\n",
            "Epoch #399: loss=2.297678232192993\n",
            "Epoch #400: loss=1.8343878984451294\n",
            "Epoch #401: loss=2.183194875717163\n",
            "Epoch #402: loss=2.360294818878174\n",
            "Epoch #403: loss=2.669492483139038\n",
            "Epoch #404: loss=2.6711325645446777\n",
            "Epoch #405: loss=1.8367573022842407\n",
            "Epoch #406: loss=2.0700693130493164\n",
            "Epoch #407: loss=1.9706239700317383\n",
            "Epoch #408: loss=2.5277864933013916\n",
            "Epoch #409: loss=1.182706356048584\n",
            "Epoch #410: loss=2.131359100341797\n",
            "Epoch #411: loss=2.0244481563568115\n",
            "Epoch #412: loss=1.8166905641555786\n",
            "Epoch #413: loss=1.7810777425765991\n",
            "Epoch #414: loss=1.9485020637512207\n",
            "Epoch #415: loss=2.3225059509277344\n",
            "Epoch #416: loss=1.919599175453186\n",
            "Epoch #417: loss=1.9814239740371704\n",
            "Epoch #418: loss=2.3797483444213867\n",
            "Epoch #419: loss=2.258786678314209\n",
            "Epoch #420: loss=1.7119442224502563\n",
            "Epoch #421: loss=1.3475149869918823\n",
            "Epoch #422: loss=2.7366747856140137\n",
            "Epoch #423: loss=1.703930377960205\n",
            "Epoch #424: loss=1.7242355346679688\n",
            "Epoch #425: loss=1.7289737462997437\n",
            "Epoch #426: loss=1.7198156118392944\n",
            "Epoch #427: loss=1.889063835144043\n",
            "Epoch #428: loss=2.1261885166168213\n",
            "Epoch #429: loss=1.7847014665603638\n",
            "Epoch #430: loss=1.767327904701233\n",
            "Epoch #431: loss=1.7683919668197632\n",
            "Epoch #432: loss=1.597412109375\n",
            "Epoch #433: loss=1.7396769523620605\n",
            "Epoch #434: loss=1.1098281145095825\n",
            "Epoch #435: loss=1.9094889163970947\n",
            "Epoch #436: loss=1.86946439743042\n",
            "Epoch #437: loss=1.6483334302902222\n",
            "Epoch #438: loss=2.915546417236328\n",
            "Epoch #439: loss=3.211632251739502\n",
            "Epoch #440: loss=0.9618380665779114\n",
            "Epoch #441: loss=1.665786862373352\n",
            "Epoch #442: loss=2.030444622039795\n",
            "Epoch #443: loss=2.3669071197509766\n",
            "Epoch #444: loss=1.7432700395584106\n",
            "Epoch #445: loss=1.7740498781204224\n",
            "Epoch #446: loss=1.7228350639343262\n",
            "Epoch #447: loss=1.778935432434082\n",
            "Epoch #448: loss=1.4483494758605957\n",
            "Epoch #449: loss=2.319169282913208\n",
            "Epoch #450: loss=1.5113261938095093\n",
            "Epoch #451: loss=1.420378565788269\n",
            "Epoch #452: loss=1.8005967140197754\n",
            "Epoch #453: loss=2.0039303302764893\n",
            "Epoch #454: loss=2.0244555473327637\n",
            "Epoch #455: loss=1.2898908853530884\n",
            "Epoch #456: loss=1.7387815713882446\n",
            "Epoch #457: loss=1.2263909578323364\n",
            "Epoch #458: loss=1.9899630546569824\n",
            "Epoch #459: loss=2.0326874256134033\n",
            "Epoch #460: loss=2.0084547996520996\n",
            "Epoch #461: loss=1.8715484142303467\n",
            "Epoch #462: loss=1.897043228149414\n",
            "Epoch #463: loss=2.0154483318328857\n",
            "Epoch #464: loss=1.7412654161453247\n",
            "Epoch #465: loss=2.0256874561309814\n",
            "Epoch #466: loss=2.0987439155578613\n",
            "Epoch #467: loss=1.7774921655654907\n",
            "Epoch #468: loss=1.6875053644180298\n",
            "Epoch #469: loss=1.6123747825622559\n",
            "Epoch #470: loss=1.554925799369812\n",
            "Epoch #471: loss=1.8139370679855347\n",
            "Epoch #472: loss=1.7157678604125977\n",
            "Epoch #473: loss=1.574872374534607\n",
            "Epoch #474: loss=2.2147340774536133\n",
            "Epoch #475: loss=1.5558363199234009\n",
            "Epoch #476: loss=1.9009069204330444\n",
            "Epoch #477: loss=1.576446771621704\n",
            "Epoch #478: loss=1.4082664251327515\n",
            "Epoch #479: loss=1.8911902904510498\n",
            "Epoch #480: loss=1.164477825164795\n",
            "Epoch #481: loss=1.702700138092041\n",
            "Epoch #482: loss=1.527776837348938\n",
            "Epoch #483: loss=1.622022271156311\n",
            "Epoch #484: loss=2.006334066390991\n",
            "Epoch #485: loss=1.5405594110488892\n",
            "Epoch #486: loss=1.397698163986206\n",
            "Epoch #487: loss=1.953088402748108\n",
            "Epoch #488: loss=1.3284797668457031\n",
            "Epoch #489: loss=1.310657262802124\n",
            "Epoch #490: loss=1.9759002923965454\n",
            "Epoch #491: loss=1.8826106786727905\n",
            "Epoch #492: loss=1.686118245124817\n",
            "Epoch #493: loss=1.733750343322754\n",
            "Epoch #494: loss=1.5875089168548584\n",
            "Epoch #495: loss=2.1272194385528564\n",
            "Epoch #496: loss=1.3243975639343262\n",
            "Epoch #497: loss=1.6247485876083374\n",
            "Epoch #498: loss=1.5217660665512085\n",
            "Epoch #499: loss=1.7823069095611572\n",
            "Epoch #500: loss=1.4143327474594116\n",
            "Epoch #501: loss=1.8785523176193237\n",
            "Epoch #502: loss=1.851426124572754\n",
            "Epoch #503: loss=1.7371892929077148\n",
            "Epoch #504: loss=1.6870759725570679\n",
            "Epoch #505: loss=1.7386527061462402\n",
            "Epoch #506: loss=1.0794426202774048\n",
            "Epoch #507: loss=2.697404623031616\n",
            "Epoch #508: loss=0.807887613773346\n",
            "Epoch #509: loss=1.4174742698669434\n",
            "Epoch #510: loss=1.6470506191253662\n",
            "Epoch #511: loss=1.7844749689102173\n",
            "Epoch #512: loss=1.7639472484588623\n",
            "Epoch #513: loss=1.3342766761779785\n",
            "Epoch #514: loss=1.6378815174102783\n",
            "Epoch #515: loss=2.665573835372925\n",
            "Epoch #516: loss=2.365229845046997\n",
            "Epoch #517: loss=1.3903528451919556\n",
            "Epoch #518: loss=1.0497533082962036\n",
            "Epoch #519: loss=1.7179282903671265\n",
            "Epoch #520: loss=1.822914719581604\n",
            "Epoch #521: loss=1.994327187538147\n",
            "Epoch #522: loss=1.870819330215454\n",
            "Epoch #523: loss=1.7214158773422241\n",
            "Epoch #524: loss=1.3440659046173096\n",
            "Epoch #525: loss=1.3070039749145508\n",
            "Epoch #526: loss=1.976646065711975\n",
            "Epoch #527: loss=1.0870627164840698\n",
            "Epoch #528: loss=1.5730812549591064\n",
            "Epoch #529: loss=2.0495193004608154\n",
            "Epoch #530: loss=1.689317226409912\n",
            "Epoch #531: loss=1.614654302597046\n",
            "Epoch #532: loss=2.3360800743103027\n",
            "Epoch #533: loss=1.830114722251892\n",
            "Epoch #534: loss=2.0954806804656982\n",
            "Epoch #535: loss=1.9531561136245728\n",
            "Epoch #536: loss=2.0766351222991943\n",
            "Epoch #537: loss=2.390662431716919\n",
            "Epoch #538: loss=2.649204730987549\n",
            "Epoch #539: loss=2.0638320446014404\n",
            "Epoch #540: loss=0.7854947447776794\n",
            "Epoch #541: loss=1.3047090768814087\n",
            "Epoch #542: loss=1.8383640050888062\n",
            "Epoch #543: loss=1.8604707717895508\n",
            "Epoch #544: loss=1.1410799026489258\n",
            "Epoch #545: loss=2.4137609004974365\n",
            "Epoch #546: loss=1.3987855911254883\n",
            "Epoch #547: loss=0.9053312540054321\n",
            "Epoch #548: loss=1.6611360311508179\n",
            "Epoch #549: loss=1.8879115581512451\n",
            "Epoch #550: loss=1.4392437934875488\n",
            "Epoch #551: loss=1.791943907737732\n",
            "Epoch #552: loss=1.6876486539840698\n",
            "Epoch #553: loss=1.5718486309051514\n",
            "Epoch #554: loss=1.9578787088394165\n",
            "Epoch #555: loss=1.3476028442382812\n",
            "Epoch #556: loss=1.1539840698242188\n",
            "Epoch #557: loss=1.2404276132583618\n",
            "Epoch #558: loss=1.4236737489700317\n",
            "Epoch #559: loss=1.427950143814087\n",
            "Epoch #560: loss=1.0483753681182861\n",
            "Epoch #561: loss=1.2717628479003906\n",
            "Epoch #562: loss=1.4417243003845215\n",
            "Epoch #563: loss=1.8438817262649536\n",
            "Epoch #564: loss=1.9076275825500488\n",
            "Epoch #565: loss=0.7647437453269958\n",
            "Epoch #566: loss=1.4423822164535522\n",
            "Epoch #567: loss=1.722220778465271\n",
            "Epoch #568: loss=1.3267852067947388\n",
            "Epoch #569: loss=1.1297314167022705\n",
            "Epoch #570: loss=1.4560414552688599\n",
            "Epoch #571: loss=1.8275846242904663\n",
            "Epoch #572: loss=1.6685445308685303\n",
            "Epoch #573: loss=1.7370240688323975\n",
            "Epoch #574: loss=1.933417558670044\n",
            "Epoch #575: loss=1.75819993019104\n",
            "Epoch #576: loss=1.3234330415725708\n",
            "Epoch #577: loss=1.971794843673706\n",
            "Epoch #578: loss=0.9190065860748291\n",
            "Epoch #579: loss=1.3038532733917236\n",
            "Epoch #580: loss=1.4285500049591064\n",
            "Epoch #581: loss=2.401371955871582\n",
            "Epoch #582: loss=1.0399960279464722\n",
            "Epoch #583: loss=1.4018361568450928\n",
            "Epoch #584: loss=2.097851514816284\n",
            "Epoch #585: loss=2.0745909214019775\n",
            "Epoch #586: loss=1.7744636535644531\n",
            "Epoch #587: loss=0.8291873931884766\n",
            "Epoch #588: loss=1.4504847526550293\n",
            "Epoch #589: loss=0.8994525074958801\n",
            "Epoch #590: loss=1.1361896991729736\n",
            "Epoch #591: loss=1.5595190525054932\n",
            "Epoch #592: loss=0.7865397334098816\n",
            "Epoch #593: loss=1.4407379627227783\n",
            "Epoch #594: loss=1.407684326171875\n",
            "Epoch #595: loss=1.0754644870758057\n",
            "Epoch #596: loss=1.4144221544265747\n",
            "Epoch #597: loss=1.237031102180481\n",
            "Epoch #598: loss=1.4036720991134644\n",
            "Epoch #599: loss=1.5982787609100342\n",
            "\n",
            "Training time: 0:15:23.385742\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/CoST/train.py\", line 109, in <module>\n",
            "    out, eval_res = tasks.eval_forecasting(model, data, train_slice, valid_slice, test_slice, scaler, pred_lens, n_covariate_cols, args.max_train_length-1)\n",
            "  File \"/content/CoST/tasks/forecasting.py\", line 70, in eval_forecasting\n",
            "    test_pred_inv = scaler.inverse_transform(test_pred)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\", line 1034, in inverse_transform\n",
            "    X = check_array(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 915, in check_array\n",
            "    raise ValueError(\n",
            "ValueError: Found array with dim 4. None expected <= 2.\n"
          ]
        }
      ]
    }
  ]
}