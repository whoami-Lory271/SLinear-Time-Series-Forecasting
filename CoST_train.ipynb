{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/whoami-Lory271/thesis-project/blob/main/CoST_train.ipynb",
      "authorship_tag": "ABX9TyNuPAPd0xwcPEykzEalPi6c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whoami-Lory271/thesis-project/blob/main/CoST_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training CoST model"
      ],
      "metadata": {
        "id": "Gh2L5z66W2X6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1LWptcrfWeZG",
        "outputId": "b5bae835-f3e1-4431-91c8-05ac13256591",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CoST'...\n",
            "remote: Enumerating objects: 70, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 70 (delta 14), reused 14 (delta 14), pack-reused 43\u001b[K\n",
            "Unpacking objects: 100% (70/70), 368.17 KiB | 8.18 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/salesforce/CoST.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5EIFz57FW_Wh",
        "outputId": "39188906-71e4-4e69-bdc7-5a575e1fdf44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/Tesi/code/datasets/electricity/LD2011_2014.txt\" \"/content/CoST/datasets/\""
      ],
      "metadata": {
        "id": "0hTJksSZXPcX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/CoST/requirements.txt\n",
        "!pip install einops==0.6.1 --quiet"
      ],
      "metadata": {
        "id": "x5qeqzGyXkx9",
        "outputId": "f372d6a2-8188-4985-b690-8930a9ec3809",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scipy==1.6.1\n",
            "  Downloading scipy-1.6.1.tar.gz (27.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.0rc1 Requires-Python >=3.7,<3.10; 1.7.0rc2 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.9.0 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.9.0\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/CoST/datasets; python electricity.py"
      ],
      "metadata": {
        "id": "A_zO0vylX_fF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/CoST; sh scripts/Electricity_CoST.sh"
      ],
      "metadata": {
        "id": "JDtXGWSiYvBz",
        "outputId": "2f5b0de0-92ca-48c7-8b63-055b105bc928",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: electricity\n",
            "Arguments: Namespace(dataset='electricity', run_name='forecast_univar', archive='forecast_csv_univar', gpu=0, batch_size=128, lr=0.001, repr_dims=320, max_train_length=201, iters=None, epochs=None, save_every=None, seed=0, max_threads=8, eval=True, kernels=[1, 2, 4, 8, 16, 32, 64, 128], alpha=0.0005)\n",
            "/content/CoST/datautils.py:30: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series. To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
            "  dt.weekofyear.to_numpy(),\n",
            "Epoch #0: loss=0.05992288514971733\n",
            "Epoch #1: loss=4.184701442718506\n",
            "Epoch #2: loss=4.828720569610596\n",
            "Epoch #3: loss=4.814533233642578\n",
            "Epoch #4: loss=4.712976932525635\n",
            "Epoch #5: loss=4.658689498901367\n",
            "Epoch #6: loss=4.627259254455566\n",
            "Epoch #7: loss=4.612172603607178\n",
            "Epoch #8: loss=4.5285139083862305\n",
            "Epoch #9: loss=4.577086925506592\n",
            "Epoch #10: loss=4.470342636108398\n",
            "Epoch #11: loss=4.492817401885986\n",
            "Epoch #12: loss=4.426695823669434\n",
            "Epoch #13: loss=4.396483421325684\n",
            "Epoch #14: loss=4.310788154602051\n",
            "Epoch #15: loss=4.522311687469482\n",
            "Epoch #16: loss=4.729259490966797\n",
            "Epoch #17: loss=4.133897304534912\n",
            "Epoch #18: loss=4.661288261413574\n",
            "Epoch #19: loss=4.054878234863281\n",
            "Epoch #20: loss=4.083245754241943\n",
            "Epoch #21: loss=4.263055324554443\n",
            "Epoch #22: loss=4.046158790588379\n",
            "Epoch #23: loss=4.100539207458496\n",
            "Epoch #24: loss=4.221828460693359\n",
            "Epoch #25: loss=4.025940418243408\n",
            "Epoch #26: loss=4.221146106719971\n",
            "Epoch #27: loss=3.961214303970337\n",
            "Epoch #28: loss=3.9247419834136963\n",
            "Epoch #29: loss=4.1995744705200195\n",
            "Epoch #30: loss=3.825178861618042\n",
            "Epoch #31: loss=3.7223243713378906\n",
            "Epoch #32: loss=3.9026074409484863\n",
            "Epoch #33: loss=3.9355742931365967\n",
            "Epoch #34: loss=3.9834163188934326\n",
            "Epoch #35: loss=3.7486019134521484\n",
            "Epoch #36: loss=3.9741640090942383\n",
            "Epoch #37: loss=3.703665018081665\n",
            "Epoch #38: loss=3.690448045730591\n",
            "Epoch #39: loss=3.7711777687072754\n",
            "Epoch #40: loss=3.744788646697998\n",
            "Epoch #41: loss=3.7093441486358643\n",
            "Epoch #42: loss=3.6098668575286865\n",
            "Epoch #43: loss=3.524548053741455\n",
            "Epoch #44: loss=3.828150510787964\n",
            "Epoch #45: loss=3.625054359436035\n",
            "Epoch #46: loss=3.586026906967163\n",
            "Epoch #47: loss=3.7430684566497803\n",
            "Epoch #48: loss=3.9944546222686768\n",
            "Epoch #49: loss=2.990635395050049\n",
            "Epoch #50: loss=3.5109000205993652\n",
            "Epoch #51: loss=3.629549980163574\n",
            "Epoch #52: loss=3.377031087875366\n",
            "Epoch #53: loss=3.403095006942749\n",
            "Epoch #54: loss=3.7049286365509033\n",
            "Epoch #55: loss=3.355769157409668\n",
            "Epoch #56: loss=3.3845059871673584\n",
            "Epoch #57: loss=3.6395490169525146\n",
            "Epoch #58: loss=3.418313980102539\n",
            "Epoch #59: loss=3.2707438468933105\n",
            "Epoch #60: loss=3.1878795623779297\n",
            "Epoch #61: loss=3.4977736473083496\n",
            "Epoch #62: loss=3.620068073272705\n",
            "Epoch #63: loss=3.6292977333068848\n",
            "Epoch #64: loss=3.5970985889434814\n",
            "Epoch #65: loss=3.577350378036499\n",
            "Epoch #66: loss=3.3789010047912598\n",
            "Epoch #67: loss=3.4597840309143066\n",
            "Epoch #68: loss=3.2603695392608643\n",
            "Epoch #69: loss=3.3862788677215576\n",
            "Epoch #70: loss=3.475834608078003\n",
            "Epoch #71: loss=3.4682419300079346\n",
            "Epoch #72: loss=3.6069273948669434\n",
            "Epoch #73: loss=3.3323843479156494\n",
            "Epoch #74: loss=3.2701518535614014\n",
            "Epoch #75: loss=3.411175012588501\n",
            "Epoch #76: loss=3.2714695930480957\n",
            "Epoch #77: loss=3.218574047088623\n",
            "Epoch #78: loss=3.421868085861206\n",
            "Epoch #79: loss=3.4885098934173584\n",
            "Epoch #80: loss=3.085331678390503\n",
            "Epoch #81: loss=3.2046234607696533\n",
            "Epoch #82: loss=3.252696990966797\n",
            "Epoch #83: loss=3.2381339073181152\n",
            "Epoch #84: loss=3.354783773422241\n",
            "Epoch #85: loss=3.0700438022613525\n",
            "Epoch #86: loss=3.182138204574585\n",
            "Epoch #87: loss=3.452788829803467\n",
            "Epoch #88: loss=3.3321690559387207\n",
            "Epoch #89: loss=3.5169060230255127\n",
            "Epoch #90: loss=3.248915195465088\n",
            "Epoch #91: loss=3.272637128829956\n",
            "Epoch #92: loss=3.2347419261932373\n",
            "Epoch #93: loss=3.3537938594818115\n",
            "Epoch #94: loss=3.13417387008667\n",
            "Epoch #95: loss=3.268833637237549\n",
            "Epoch #96: loss=3.2860493659973145\n",
            "Epoch #97: loss=3.1794025897979736\n",
            "Epoch #98: loss=3.3881826400756836\n",
            "Epoch #99: loss=3.377243757247925\n",
            "Epoch #100: loss=3.5662550926208496\n",
            "Epoch #101: loss=2.941640853881836\n",
            "Epoch #102: loss=3.1972086429595947\n",
            "Epoch #103: loss=3.246725559234619\n",
            "Epoch #104: loss=3.4020190238952637\n",
            "Epoch #105: loss=3.029637575149536\n",
            "Epoch #106: loss=3.234816789627075\n",
            "Epoch #107: loss=3.1450469493865967\n",
            "Epoch #108: loss=3.088496446609497\n",
            "Epoch #109: loss=3.0112197399139404\n",
            "Epoch #110: loss=3.115581512451172\n",
            "Epoch #111: loss=2.9152743816375732\n",
            "Epoch #112: loss=3.281567096710205\n",
            "Epoch #113: loss=3.5720901489257812\n",
            "Epoch #114: loss=3.8559603691101074\n",
            "Epoch #115: loss=2.3933749198913574\n",
            "Epoch #116: loss=2.994666337966919\n",
            "Epoch #117: loss=3.3526084423065186\n",
            "Epoch #118: loss=3.2620089054107666\n",
            "Epoch #119: loss=3.3752875328063965\n",
            "Epoch #120: loss=3.2386434078216553\n",
            "Epoch #121: loss=3.0409491062164307\n",
            "Epoch #122: loss=2.929046154022217\n",
            "Epoch #123: loss=3.346912384033203\n",
            "Epoch #124: loss=3.1264266967773438\n",
            "Epoch #125: loss=3.244410514831543\n",
            "Epoch #126: loss=2.9840164184570312\n",
            "Epoch #127: loss=3.0978894233703613\n",
            "Epoch #128: loss=3.1661508083343506\n",
            "Epoch #129: loss=3.047736167907715\n",
            "Epoch #130: loss=3.1194400787353516\n",
            "Epoch #131: loss=3.1820805072784424\n",
            "Epoch #132: loss=2.9175117015838623\n",
            "Epoch #133: loss=3.150146245956421\n",
            "Epoch #134: loss=3.3961939811706543\n",
            "Epoch #135: loss=2.962614059448242\n",
            "Epoch #136: loss=3.1045751571655273\n",
            "Epoch #137: loss=2.8948347568511963\n",
            "Epoch #138: loss=3.384829044342041\n",
            "Epoch #139: loss=2.348965883255005\n",
            "Epoch #140: loss=3.1426539421081543\n",
            "Epoch #141: loss=2.9616925716400146\n",
            "Epoch #142: loss=3.1177773475646973\n",
            "Epoch #143: loss=3.243462324142456\n",
            "Epoch #144: loss=3.341388702392578\n",
            "Epoch #145: loss=3.3173398971557617\n",
            "Epoch #146: loss=3.2452638149261475\n",
            "Epoch #147: loss=3.0498909950256348\n",
            "Epoch #148: loss=3.1402645111083984\n",
            "Epoch #149: loss=2.8525888919830322\n",
            "Epoch #150: loss=2.6117520332336426\n",
            "Epoch #151: loss=3.017977476119995\n",
            "Epoch #152: loss=2.9408488273620605\n",
            "Epoch #153: loss=3.0758957862854004\n",
            "Epoch #154: loss=3.0731301307678223\n",
            "Epoch #155: loss=2.885615825653076\n",
            "Epoch #156: loss=2.882014751434326\n",
            "Epoch #157: loss=3.0665178298950195\n",
            "Epoch #158: loss=2.840548038482666\n",
            "Epoch #159: loss=2.63816499710083\n",
            "Epoch #160: loss=3.0451438426971436\n",
            "Epoch #161: loss=2.9809184074401855\n",
            "Epoch #162: loss=2.9701945781707764\n",
            "Epoch #163: loss=3.1461408138275146\n",
            "Epoch #164: loss=2.8031728267669678\n",
            "Epoch #165: loss=3.0209786891937256\n",
            "Epoch #166: loss=3.0464274883270264\n",
            "Epoch #167: loss=3.0626754760742188\n",
            "Epoch #168: loss=3.058178424835205\n",
            "Epoch #169: loss=2.9296631813049316\n",
            "Epoch #170: loss=2.7551798820495605\n",
            "Epoch #171: loss=2.8238844871520996\n",
            "Epoch #172: loss=2.9829189777374268\n",
            "Epoch #173: loss=2.8023693561553955\n",
            "Epoch #174: loss=3.0991220474243164\n",
            "Epoch #175: loss=2.948253631591797\n",
            "Epoch #176: loss=2.7287914752960205\n",
            "Epoch #177: loss=3.408010721206665\n",
            "Epoch #178: loss=2.133448839187622\n",
            "Epoch #179: loss=2.6958389282226562\n",
            "Epoch #180: loss=2.897885322570801\n",
            "Epoch #181: loss=2.839831590652466\n",
            "Epoch #182: loss=3.1141481399536133\n",
            "Epoch #183: loss=3.080782413482666\n",
            "Epoch #184: loss=2.7764499187469482\n",
            "Epoch #185: loss=2.929645538330078\n",
            "Epoch #186: loss=2.6517791748046875\n",
            "Epoch #187: loss=2.8684372901916504\n",
            "Epoch #188: loss=2.7735140323638916\n",
            "Epoch #189: loss=2.7258718013763428\n",
            "Epoch #190: loss=3.0444536209106445\n",
            "Epoch #191: loss=2.8491392135620117\n",
            "Epoch #192: loss=2.8546323776245117\n",
            "Epoch #193: loss=2.6584887504577637\n",
            "Epoch #194: loss=2.6878578662872314\n",
            "Epoch #195: loss=2.6244614124298096\n",
            "Epoch #196: loss=2.8367207050323486\n",
            "Epoch #197: loss=3.0141396522521973\n",
            "Epoch #198: loss=2.8081958293914795\n",
            "Epoch #199: loss=2.8813533782958984\n",
            "Epoch #200: loss=2.5020101070404053\n",
            "Epoch #201: loss=2.671525239944458\n",
            "Epoch #202: loss=1.9893254041671753\n",
            "Epoch #203: loss=3.0427920818328857\n",
            "Epoch #204: loss=2.4723284244537354\n",
            "Epoch #205: loss=2.5584890842437744\n",
            "Epoch #206: loss=2.6037826538085938\n",
            "Epoch #207: loss=2.8882205486297607\n",
            "Epoch #208: loss=3.5052027702331543\n",
            "Epoch #209: loss=1.6858783960342407\n",
            "Epoch #210: loss=2.5202229022979736\n",
            "Epoch #211: loss=2.8748724460601807\n",
            "Epoch #212: loss=2.8881077766418457\n",
            "Epoch #213: loss=2.8063371181488037\n",
            "Epoch #214: loss=3.0134060382843018\n",
            "Epoch #215: loss=2.8538997173309326\n",
            "Epoch #216: loss=2.610421657562256\n",
            "Epoch #217: loss=2.6252975463867188\n",
            "Epoch #218: loss=3.052854061126709\n",
            "Epoch #219: loss=2.7471699714660645\n",
            "Epoch #220: loss=2.3690476417541504\n",
            "Epoch #221: loss=3.3646621704101562\n",
            "Epoch #222: loss=2.958966016769409\n",
            "Epoch #223: loss=2.0828328132629395\n",
            "Epoch #224: loss=2.6760752201080322\n",
            "Epoch #225: loss=2.7568764686584473\n",
            "Epoch #226: loss=2.927414894104004\n",
            "Epoch #227: loss=2.7784295082092285\n",
            "Epoch #228: loss=2.320349931716919\n",
            "Epoch #229: loss=2.4863409996032715\n",
            "Epoch #230: loss=2.4985368251800537\n",
            "Epoch #231: loss=2.5428411960601807\n",
            "Epoch #232: loss=2.582573890686035\n",
            "Epoch #233: loss=2.8249430656433105\n",
            "Epoch #234: loss=2.7924599647521973\n",
            "Epoch #235: loss=2.5835280418395996\n",
            "Epoch #236: loss=2.53804874420166\n",
            "Epoch #237: loss=2.471146583557129\n",
            "Epoch #238: loss=2.5911355018615723\n",
            "Epoch #239: loss=1.912197232246399\n",
            "Epoch #240: loss=3.2166943550109863\n",
            "Epoch #241: loss=2.6550052165985107\n",
            "Epoch #242: loss=2.587736129760742\n",
            "Epoch #243: loss=2.2717599868774414\n",
            "Epoch #244: loss=2.62129807472229\n",
            "Epoch #245: loss=2.5472140312194824\n",
            "Epoch #246: loss=2.4472904205322266\n",
            "Epoch #247: loss=2.6984729766845703\n",
            "Epoch #248: loss=2.678999900817871\n",
            "Epoch #249: loss=2.747899293899536\n",
            "Epoch #250: loss=2.8123152256011963\n",
            "Epoch #251: loss=2.8534951210021973\n",
            "Epoch #252: loss=2.2374584674835205\n",
            "Epoch #253: loss=2.8783254623413086\n",
            "Epoch #254: loss=2.6136715412139893\n",
            "Epoch #255: loss=2.187241792678833\n",
            "Epoch #256: loss=2.3417863845825195\n",
            "Epoch #257: loss=2.8394501209259033\n",
            "Epoch #258: loss=2.732804298400879\n",
            "Epoch #259: loss=1.981391429901123\n",
            "Epoch #260: loss=2.799039840698242\n",
            "Epoch #261: loss=2.6824710369110107\n",
            "Epoch #262: loss=2.4146265983581543\n",
            "Epoch #263: loss=2.751831293106079\n",
            "Epoch #264: loss=2.1564700603485107\n",
            "Epoch #265: loss=2.182992458343506\n",
            "Epoch #266: loss=2.4622836112976074\n",
            "Epoch #267: loss=2.1177194118499756\n",
            "Epoch #268: loss=2.595586061477661\n",
            "Epoch #269: loss=2.3605380058288574\n",
            "Epoch #270: loss=2.8657474517822266\n",
            "Epoch #271: loss=3.058941602706909\n",
            "Epoch #272: loss=3.1051013469696045\n",
            "Epoch #273: loss=2.021115779876709\n",
            "Epoch #274: loss=2.730611562728882\n",
            "Epoch #275: loss=2.227283477783203\n",
            "Epoch #276: loss=2.2962117195129395\n",
            "Epoch #277: loss=2.6348087787628174\n",
            "Epoch #278: loss=2.598093271255493\n",
            "Epoch #279: loss=2.170469284057617\n",
            "Epoch #280: loss=2.818311929702759\n",
            "Epoch #281: loss=2.4548840522766113\n",
            "Epoch #282: loss=2.5005435943603516\n",
            "Epoch #283: loss=2.2646608352661133\n",
            "Epoch #284: loss=2.6522884368896484\n",
            "Epoch #285: loss=1.8731602430343628\n",
            "Epoch #286: loss=2.4085350036621094\n",
            "Epoch #287: loss=2.47235369682312\n",
            "Epoch #288: loss=2.493892192840576\n",
            "Epoch #289: loss=2.5517795085906982\n",
            "Epoch #290: loss=2.326467990875244\n",
            "Epoch #291: loss=2.3859400749206543\n",
            "Epoch #292: loss=2.221463441848755\n",
            "Epoch #293: loss=2.6175403594970703\n",
            "Epoch #294: loss=1.7715522050857544\n",
            "Epoch #295: loss=2.378812789916992\n",
            "Epoch #296: loss=1.8863805532455444\n",
            "Epoch #297: loss=2.0865886211395264\n",
            "Epoch #298: loss=2.8419411182403564\n",
            "Epoch #299: loss=2.528661012649536\n",
            "Epoch #300: loss=3.1568126678466797\n",
            "Epoch #301: loss=1.828402042388916\n",
            "Epoch #302: loss=2.11639142036438\n",
            "Epoch #303: loss=1.9228265285491943\n",
            "Epoch #304: loss=2.2662134170532227\n",
            "Epoch #305: loss=2.278425931930542\n",
            "Epoch #306: loss=2.517643690109253\n",
            "Epoch #307: loss=2.3073103427886963\n",
            "Epoch #308: loss=1.8184829950332642\n",
            "Epoch #309: loss=2.9342024326324463\n",
            "Epoch #310: loss=2.25120210647583\n",
            "Epoch #311: loss=1.975007176399231\n",
            "Epoch #312: loss=2.431403875350952\n",
            "Epoch #313: loss=2.764343738555908\n",
            "Epoch #314: loss=2.3989992141723633\n",
            "Epoch #315: loss=2.3468940258026123\n",
            "Epoch #316: loss=2.621516466140747\n",
            "Epoch #317: loss=2.3365931510925293\n",
            "Epoch #318: loss=2.581836223602295\n",
            "Epoch #319: loss=2.48484468460083\n",
            "Epoch #320: loss=1.829412817955017\n",
            "Epoch #321: loss=2.702894926071167\n",
            "Epoch #322: loss=1.5049188137054443\n",
            "Epoch #323: loss=2.3445708751678467\n",
            "Epoch #324: loss=1.8395649194717407\n",
            "Epoch #325: loss=2.455556869506836\n",
            "Epoch #326: loss=1.9329103231430054\n",
            "Epoch #327: loss=2.3743162155151367\n",
            "Epoch #328: loss=2.566540241241455\n",
            "Epoch #329: loss=2.308323860168457\n",
            "Epoch #330: loss=2.4374678134918213\n",
            "Epoch #331: loss=2.255093812942505\n",
            "Epoch #332: loss=2.0847856998443604\n",
            "Epoch #333: loss=2.7336950302124023\n",
            "Epoch #334: loss=2.657243490219116\n",
            "Epoch #335: loss=1.3202059268951416\n",
            "Epoch #336: loss=2.107722520828247\n",
            "Epoch #337: loss=2.4413669109344482\n",
            "Epoch #338: loss=2.4204649925231934\n",
            "Epoch #339: loss=2.6343014240264893\n",
            "Epoch #340: loss=2.2321441173553467\n",
            "Epoch #341: loss=2.508563280105591\n",
            "Epoch #342: loss=2.2212729454040527\n",
            "Epoch #343: loss=2.469592809677124\n",
            "Epoch #344: loss=1.5947540998458862\n",
            "Epoch #345: loss=2.4653971195220947\n",
            "Epoch #346: loss=1.4023317098617554\n",
            "Epoch #347: loss=2.1124119758605957\n",
            "Epoch #348: loss=2.410292863845825\n",
            "Epoch #349: loss=2.5180397033691406\n",
            "Epoch #350: loss=1.7952542304992676\n",
            "Epoch #351: loss=2.3202171325683594\n",
            "Epoch #352: loss=2.398942708969116\n",
            "Epoch #353: loss=2.5063910484313965\n",
            "Epoch #354: loss=1.8175584077835083\n",
            "Epoch #355: loss=1.5732964277267456\n",
            "Epoch #356: loss=1.9274581670761108\n",
            "Epoch #357: loss=1.865071415901184\n",
            "Epoch #358: loss=1.584643840789795\n",
            "Epoch #359: loss=2.323716402053833\n",
            "Epoch #360: loss=2.09108567237854\n",
            "Epoch #361: loss=1.0689319372177124\n",
            "Epoch #362: loss=2.663181781768799\n",
            "Epoch #363: loss=2.3069217205047607\n",
            "Epoch #364: loss=1.5228252410888672\n",
            "Epoch #365: loss=2.3345394134521484\n",
            "Epoch #366: loss=2.3497798442840576\n",
            "Epoch #367: loss=2.467801332473755\n",
            "Epoch #368: loss=2.2924017906188965\n",
            "Epoch #369: loss=2.7440178394317627\n",
            "Epoch #370: loss=0.9949640035629272\n",
            "Epoch #371: loss=2.3712430000305176\n",
            "Epoch #372: loss=2.1584365367889404\n",
            "Epoch #373: loss=2.0627119541168213\n",
            "Epoch #374: loss=2.3895740509033203\n",
            "Epoch #375: loss=2.2507128715515137\n",
            "Epoch #376: loss=1.8781030178070068\n",
            "Epoch #377: loss=2.328336477279663\n",
            "Epoch #378: loss=2.419826030731201\n",
            "Epoch #379: loss=1.7523444890975952\n",
            "Epoch #380: loss=2.0122995376586914\n",
            "Epoch #381: loss=2.794238805770874\n",
            "Epoch #382: loss=1.6351652145385742\n",
            "Epoch #383: loss=1.7275457382202148\n",
            "Epoch #384: loss=2.1445138454437256\n",
            "Epoch #385: loss=2.3153226375579834\n",
            "Epoch #386: loss=2.409878969192505\n",
            "Epoch #387: loss=2.2236673831939697\n",
            "Epoch #388: loss=1.4581514596939087\n",
            "Epoch #389: loss=2.074845552444458\n",
            "Epoch #390: loss=1.7007559537887573\n",
            "Epoch #391: loss=2.357733964920044\n",
            "Epoch #392: loss=2.2782037258148193\n",
            "Epoch #393: loss=1.5587913990020752\n",
            "Epoch #394: loss=2.297849655151367\n",
            "Epoch #395: loss=1.3913288116455078\n",
            "Epoch #396: loss=1.3192349672317505\n",
            "Epoch #397: loss=1.8812532424926758\n",
            "Epoch #398: loss=2.449233293533325\n",
            "Epoch #399: loss=1.7795324325561523\n",
            "Epoch #400: loss=1.7175153493881226\n",
            "Epoch #401: loss=2.2439138889312744\n",
            "Epoch #402: loss=1.718138575553894\n",
            "Epoch #403: loss=2.044679880142212\n",
            "Epoch #404: loss=1.6767596006393433\n",
            "Epoch #405: loss=2.046520709991455\n",
            "Epoch #406: loss=1.9516663551330566\n",
            "Epoch #407: loss=2.125594139099121\n",
            "Epoch #408: loss=1.552244782447815\n",
            "Epoch #409: loss=2.1139719486236572\n",
            "Epoch #410: loss=2.1875810623168945\n",
            "Epoch #411: loss=1.4471476078033447\n",
            "Epoch #412: loss=1.4037915468215942\n",
            "Epoch #413: loss=2.5048303604125977\n",
            "Epoch #414: loss=1.6976432800292969\n",
            "Epoch #415: loss=2.0907700061798096\n",
            "Epoch #416: loss=2.2497010231018066\n",
            "Epoch #417: loss=2.097658634185791\n",
            "Epoch #418: loss=2.0912604331970215\n",
            "Epoch #419: loss=1.4440884590148926\n",
            "Epoch #420: loss=2.2098915576934814\n",
            "Epoch #421: loss=1.5008985996246338\n",
            "Epoch #422: loss=1.449526071548462\n",
            "Epoch #423: loss=2.3929758071899414\n",
            "Epoch #424: loss=0.9192665219306946\n",
            "Epoch #425: loss=1.971671462059021\n",
            "Epoch #426: loss=2.0693371295928955\n",
            "Epoch #427: loss=2.0869174003601074\n",
            "Epoch #428: loss=2.1771838665008545\n",
            "Epoch #429: loss=2.108769178390503\n",
            "Epoch #430: loss=1.717069387435913\n",
            "Epoch #431: loss=1.3311398029327393\n",
            "Epoch #432: loss=2.0543394088745117\n",
            "Epoch #433: loss=0.936922013759613\n",
            "Epoch #434: loss=1.86105215549469\n",
            "Epoch #435: loss=2.338697910308838\n",
            "Epoch #436: loss=1.2725708484649658\n",
            "Epoch #437: loss=1.7554585933685303\n",
            "Epoch #438: loss=2.7708680629730225\n",
            "Epoch #439: loss=1.6651164293289185\n",
            "Epoch #440: loss=0.7973003387451172\n",
            "Epoch #441: loss=2.071916103363037\n",
            "Epoch #442: loss=2.3412106037139893\n",
            "Epoch #443: loss=1.9885081052780151\n",
            "Epoch #444: loss=2.149578809738159\n",
            "Epoch #445: loss=2.2474312782287598\n",
            "Epoch #446: loss=1.5113297700881958\n",
            "Epoch #447: loss=1.905322551727295\n",
            "Epoch #448: loss=2.2589268684387207\n",
            "Epoch #449: loss=2.140596866607666\n",
            "Epoch #450: loss=1.8939646482467651\n",
            "Epoch #451: loss=1.8853116035461426\n",
            "Epoch #452: loss=1.965133786201477\n",
            "Epoch #453: loss=1.9061174392700195\n",
            "Epoch #454: loss=2.003812074661255\n",
            "Epoch #455: loss=1.6678178310394287\n",
            "Epoch #456: loss=2.5479886531829834\n",
            "Epoch #457: loss=2.4899940490722656\n",
            "Epoch #458: loss=1.9742969274520874\n",
            "Epoch #459: loss=1.3777669668197632\n",
            "Epoch #460: loss=1.8551597595214844\n",
            "Epoch #461: loss=2.003114938735962\n",
            "Epoch #462: loss=0.9692755937576294\n",
            "Epoch #463: loss=1.5334588289260864\n",
            "Epoch #464: loss=1.0340754985809326\n",
            "Epoch #465: loss=2.1291215419769287\n",
            "Epoch #466: loss=1.8765541315078735\n",
            "Epoch #467: loss=1.9299020767211914\n",
            "Epoch #468: loss=2.006080389022827\n",
            "Epoch #469: loss=2.1008622646331787\n",
            "Epoch #470: loss=2.107703685760498\n",
            "Epoch #471: loss=2.034552574157715\n",
            "Epoch #472: loss=2.103834867477417\n",
            "Epoch #473: loss=1.8125550746917725\n",
            "Epoch #474: loss=1.3611257076263428\n",
            "Epoch #475: loss=2.496717691421509\n",
            "Epoch #476: loss=1.837502121925354\n",
            "Epoch #477: loss=2.011735677719116\n",
            "Epoch #478: loss=2.417607545852661\n",
            "Epoch #479: loss=2.3969156742095947\n",
            "Epoch #480: loss=2.696739435195923\n",
            "Epoch #481: loss=1.0218628644943237\n",
            "Epoch #482: loss=1.8784672021865845\n",
            "Epoch #483: loss=2.021618604660034\n",
            "Epoch #484: loss=2.2188878059387207\n",
            "Epoch #485: loss=1.4596521854400635\n",
            "Epoch #486: loss=1.1033202409744263\n",
            "Epoch #487: loss=1.9767829179763794\n",
            "Epoch #488: loss=1.5317295789718628\n",
            "Epoch #489: loss=1.7488526105880737\n",
            "Epoch #490: loss=2.051680326461792\n",
            "Epoch #491: loss=1.8483747243881226\n",
            "Epoch #492: loss=1.0254907608032227\n",
            "Epoch #493: loss=1.0937061309814453\n",
            "Epoch #494: loss=3.2472944259643555\n",
            "Epoch #495: loss=1.52708101272583\n",
            "Epoch #496: loss=1.4839667081832886\n",
            "Epoch #497: loss=2.0349464416503906\n",
            "Epoch #498: loss=1.3258330821990967\n",
            "Epoch #499: loss=1.9162530899047852\n",
            "Epoch #500: loss=1.8412237167358398\n",
            "Epoch #501: loss=1.0853124856948853\n",
            "Epoch #502: loss=1.7794804573059082\n",
            "Epoch #503: loss=1.7815430164337158\n",
            "Epoch #504: loss=0.6255849599838257\n",
            "Epoch #505: loss=1.567845344543457\n",
            "Epoch #506: loss=2.020399808883667\n",
            "Epoch #507: loss=1.9142343997955322\n",
            "Epoch #508: loss=1.9127012491226196\n",
            "Epoch #509: loss=1.151207447052002\n",
            "Epoch #510: loss=1.937658429145813\n",
            "Epoch #511: loss=1.5550707578659058\n",
            "Epoch #512: loss=1.0597809553146362\n",
            "Epoch #513: loss=1.5847845077514648\n",
            "Epoch #514: loss=1.6287542581558228\n",
            "Epoch #515: loss=2.0488109588623047\n",
            "Epoch #516: loss=1.489322304725647\n",
            "Epoch #517: loss=1.4430769681930542\n",
            "Epoch #518: loss=1.806309700012207\n",
            "Epoch #519: loss=0.9843310117721558\n",
            "Epoch #520: loss=1.8879764080047607\n",
            "Epoch #521: loss=2.009885549545288\n",
            "Epoch #522: loss=1.6550989151000977\n",
            "Epoch #523: loss=1.9893898963928223\n",
            "Epoch #524: loss=2.076066017150879\n",
            "Epoch #525: loss=1.8084471225738525\n",
            "Epoch #526: loss=2.1160178184509277\n",
            "Epoch #527: loss=1.199097752571106\n",
            "Epoch #528: loss=1.0175375938415527\n",
            "Epoch #529: loss=2.9492604732513428\n",
            "Epoch #530: loss=0.6161457300186157\n",
            "Epoch #531: loss=1.527186632156372\n",
            "Epoch #532: loss=1.5661430358886719\n",
            "Epoch #533: loss=1.6758884191513062\n",
            "Epoch #534: loss=1.0669020414352417\n",
            "Epoch #535: loss=1.7291743755340576\n",
            "Epoch #536: loss=2.108623743057251\n",
            "Epoch #537: loss=2.043687343597412\n",
            "Epoch #538: loss=2.0175576210021973\n",
            "Epoch #539: loss=1.5434976816177368\n",
            "Epoch #540: loss=1.0061205625534058\n",
            "Epoch #541: loss=0.9507358074188232\n",
            "Epoch #542: loss=2.580961227416992\n",
            "Epoch #543: loss=1.5372945070266724\n",
            "Epoch #544: loss=1.5550758838653564\n",
            "Epoch #545: loss=1.5521782636642456\n",
            "Epoch #546: loss=1.692887306213379\n",
            "Epoch #547: loss=1.851042628288269\n",
            "Epoch #548: loss=0.9818117022514343\n",
            "Epoch #549: loss=1.6644208431243896\n",
            "Epoch #550: loss=1.2437690496444702\n",
            "Epoch #551: loss=1.0969430208206177\n",
            "Epoch #552: loss=0.8207516670227051\n",
            "Epoch #553: loss=1.3901735544204712\n",
            "Epoch #554: loss=1.7462059259414673\n",
            "Epoch #555: loss=0.657354474067688\n",
            "Epoch #556: loss=1.592221736907959\n",
            "Epoch #557: loss=2.2766449451446533\n",
            "Epoch #558: loss=2.488762140274048\n",
            "Epoch #559: loss=0.6931004524230957\n",
            "Epoch #560: loss=1.9121177196502686\n",
            "Epoch #561: loss=1.6295340061187744\n",
            "Epoch #562: loss=1.791975736618042\n",
            "Epoch #563: loss=1.890220284461975\n",
            "Epoch #564: loss=1.56277334690094\n",
            "Epoch #565: loss=1.7578821182250977\n",
            "Epoch #566: loss=0.9404475092887878\n",
            "Epoch #567: loss=1.966194748878479\n",
            "Epoch #568: loss=0.8125876784324646\n",
            "Epoch #569: loss=1.592807650566101\n",
            "Epoch #570: loss=1.80559241771698\n",
            "Epoch #571: loss=1.0164649486541748\n",
            "Epoch #572: loss=1.796167016029358\n",
            "Epoch #573: loss=1.9698402881622314\n",
            "Epoch #574: loss=2.238996982574463\n",
            "Epoch #575: loss=1.3398511409759521\n",
            "Epoch #576: loss=1.6635499000549316\n",
            "Epoch #577: loss=1.148184895515442\n",
            "Epoch #578: loss=1.5682106018066406\n",
            "Epoch #579: loss=1.6579513549804688\n",
            "Epoch #580: loss=0.9682354927062988\n",
            "Epoch #581: loss=2.201382637023926\n",
            "Epoch #582: loss=1.3888936042785645\n",
            "Epoch #583: loss=1.0745002031326294\n",
            "Epoch #584: loss=1.8019882440567017\n",
            "Epoch #585: loss=1.6433689594268799\n",
            "Epoch #586: loss=1.4426088333129883\n",
            "Epoch #587: loss=1.4809291362762451\n",
            "Epoch #588: loss=1.5156126022338867\n",
            "Epoch #589: loss=1.8585028648376465\n",
            "Epoch #590: loss=1.7750126123428345\n",
            "Epoch #591: loss=0.5016469359397888\n",
            "Epoch #592: loss=2.2820937633514404\n",
            "Epoch #593: loss=0.9294716715812683\n",
            "Epoch #594: loss=2.2684333324432373\n",
            "Epoch #595: loss=1.6718369722366333\n",
            "Epoch #596: loss=1.0394688844680786\n",
            "Epoch #597: loss=1.321501612663269\n",
            "Epoch #598: loss=1.6564968824386597\n",
            "Epoch #599: loss=1.3249554634094238\n",
            "\n",
            "Training time: 0:14:55.985143\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/CoST/train.py\", line 109, in <module>\n",
            "    out, eval_res = tasks.eval_forecasting(model, data, train_slice, valid_slice, test_slice, scaler, pred_lens, n_covariate_cols, args.max_train_length-1)\n",
            "  File \"/content/CoST/tasks/forecasting.py\", line 70, in eval_forecasting\n",
            "    test_pred_inv = scaler.inverse_transform(test_pred)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\", line 1034, in inverse_transform\n",
            "    X = check_array(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 915, in check_array\n",
            "    raise ValueError(\n",
            "ValueError: Found array with dim 4. None expected <= 2.\n",
            "Dataset: electricity\n",
            "Arguments: Namespace(dataset='electricity', run_name='forecast_multivar', archive='forecast_csv', gpu=0, batch_size=128, lr=0.001, repr_dims=320, max_train_length=201, iters=None, epochs=None, save_every=None, seed=0, max_threads=8, eval=True, kernels=[1, 2, 4, 8, 16, 32, 64, 128], alpha=0.0005)\n",
            "/content/CoST/datautils.py:30: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series. To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
            "  dt.weekofyear.to_numpy(),\n",
            "Epoch #0: loss=3.337485514638516\n",
            "Epoch #1: loss=2.3725345449569897\n",
            "Epoch #2: loss=1.7161289606338892\n",
            "\n",
            "Training time: 0:14:49.889829\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/CoST/train.py\", line 109, in <module>\n",
            "    out, eval_res = tasks.eval_forecasting(model, data, train_slice, valid_slice, test_slice, scaler, pred_lens, n_covariate_cols, args.max_train_length-1)\n",
            "  File \"/content/CoST/tasks/forecasting.py\", line 26, in eval_forecasting\n",
            "    all_repr = model.encode(\n",
            "  File \"/content/CoST/cost.py\", line 387, in encode\n",
            "    out = self._eval_with_pooling(\n",
            "  File \"/content/CoST/cost.py\", line 335, in _eval_with_pooling\n",
            "    return rearrange(out.cpu(), 'b d -> b () d')\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -u train.py electricity forecast_multivar --alpha 0.0005 --kernels 1 2 4 8 16 32 64 128 --max-train-length 201 --batch-size 128 --archive forecast_csv --repr-dims 320 --max-threads 8 --seed 0 --eval"
      ],
      "metadata": {
        "id": "cHGjomTozYI6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}