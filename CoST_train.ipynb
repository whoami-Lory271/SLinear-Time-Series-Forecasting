{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whoami-Lory271/thesis-project/blob/main/CoST_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training CoST model"
      ],
      "metadata": {
        "id": "Gh2L5z66W2X6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1LWptcrfWeZG",
        "outputId": "e1febda0-841a-4c7d-dc36-6e7dad323a78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CoST'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 74 (delta 30), reused 74 (delta 30), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (74/74), 368.15 KiB | 4.09 MiB/s, done.\n",
            "Resolving deltas: 100% (30/30), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/whoami-Lory271/CoST"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5EIFz57FW_Wh",
        "outputId": "24c9a978-ff35-4b9f-8cc6-2a09f4fc8362",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/Tesi/code/datasets/electricity/LD2011_2014.txt\" \"/content/CoST/datasets/\"\n",
        "!cp \"/content/drive/MyDrive/Tesi/code/datasets/ETT/ETTh1.csv\" \"/content/CoST/datasets/\""
      ],
      "metadata": {
        "id": "0hTJksSZXPcX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/CoST/requirements.txt\n",
        "!pip install einops==0.6.1 --quiet"
      ],
      "metadata": {
        "id": "x5qeqzGyXkx9",
        "outputId": "cc7df40a-abb6-44c2-cc60-01fc60813784",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scipy==1.6.1 (from -r /content/CoST/requirements.txt (line 1))\n",
            "  Downloading scipy-1.6.1.tar.gz (27.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.9.0 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.9.0\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cd /content/CoST/datasets; python electricity.py"
      ],
      "metadata": {
        "id": "A_zO0vylX_fF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cd /content/CoST; sh scripts/Electricity_CoST.sh"
      ],
      "metadata": {
        "id": "JDtXGWSiYvBz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/CoST; python -u train.py ETTh1 forecast_univar --alpha 0.0005 --kernels 1 2 4 8 16 32 64 128 --max-train-length 201 --batch-size 16 --archive forecast_csv_univar --repr-dims 320 --max-threads 8 --seed 1 --eval"
      ],
      "metadata": {
        "id": "cHGjomTozYI6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fd12818-3f93-4a4d-d3f2-58d530f40d9a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: ETTh1\n",
            "Arguments: Namespace(dataset='ETTh1', run_name='forecast_univar', archive='forecast_csv_univar', gpu=0, batch_size=16, lr=0.001, repr_dims=320, max_train_length=201, iters=None, epochs=None, save_every=None, seed=1, max_threads=8, eval=True, kernels=[1, 2, 4, 8, 16, 32, 64, 128], alpha=0.0005)\n",
            "/content/CoST/datautils.py:30: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series. To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
            "  dt.weekofyear.to_numpy(),\n",
            "Epoch #0: loss=1.0828017983585596\n",
            "Epoch #1: loss=3.051060438156128\n",
            "Epoch #2: loss=3.330972671508789\n",
            "Epoch #3: loss=3.7567211389541626\n",
            "Epoch #4: loss=3.7681621313095093\n",
            "Epoch #5: loss=4.010585784912109\n",
            "Epoch #6: loss=4.031236052513123\n",
            "Epoch #7: loss=4.0523658990859985\n",
            "Epoch #8: loss=4.131662726402283\n",
            "Epoch #9: loss=4.033974885940552\n",
            "Epoch #10: loss=4.143225312232971\n",
            "Epoch #11: loss=4.154924631118774\n",
            "Epoch #12: loss=3.820319890975952\n",
            "Epoch #13: loss=3.917424201965332\n",
            "Epoch #14: loss=3.6855989694595337\n",
            "Epoch #15: loss=3.8487685918807983\n",
            "Epoch #16: loss=3.7928653955459595\n",
            "Epoch #17: loss=3.7378926277160645\n",
            "Epoch #18: loss=3.7010470628738403\n",
            "Epoch #19: loss=3.414722442626953\n",
            "Epoch #20: loss=3.5043435096740723\n",
            "Epoch #21: loss=3.7403753995895386\n",
            "Epoch #22: loss=4.054460048675537\n",
            "Epoch #23: loss=3.746024250984192\n",
            "Epoch #24: loss=3.4428772926330566\n",
            "Epoch #25: loss=3.856885313987732\n",
            "Epoch #26: loss=3.5366681814193726\n",
            "Epoch #27: loss=3.432640314102173\n",
            "Epoch #28: loss=3.517061471939087\n",
            "Epoch #29: loss=3.2835848331451416\n",
            "Epoch #30: loss=3.1996357440948486\n",
            "Epoch #31: loss=3.2833027839660645\n",
            "Epoch #32: loss=3.313676595687866\n",
            "Epoch #33: loss=3.3628896474838257\n",
            "Epoch #34: loss=3.484923005104065\n",
            "Epoch #35: loss=3.463008403778076\n",
            "Epoch #36: loss=3.345978260040283\n",
            "Epoch #37: loss=3.054487466812134\n",
            "Epoch #38: loss=3.593729615211487\n",
            "Epoch #39: loss=3.223556160926819\n",
            "Epoch #40: loss=3.1562693119049072\n",
            "Epoch #41: loss=3.329560875892639\n",
            "Epoch #42: loss=3.2944213151931763\n",
            "Epoch #43: loss=3.5483641624450684\n",
            "Epoch #44: loss=2.9160056114196777\n",
            "Epoch #45: loss=3.3768434524536133\n",
            "Epoch #46: loss=3.1311514377593994\n",
            "Epoch #47: loss=3.2537307739257812\n",
            "Epoch #48: loss=3.2124603986740112\n",
            "Epoch #49: loss=3.3741631507873535\n",
            "Epoch #50: loss=3.0597643852233887\n",
            "Epoch #51: loss=3.3749022483825684\n",
            "Epoch #52: loss=3.474954128265381\n",
            "Epoch #53: loss=3.153383731842041\n",
            "Epoch #54: loss=3.083828091621399\n",
            "Epoch #55: loss=3.262801170349121\n",
            "Epoch #56: loss=3.0116264820098877\n",
            "Epoch #57: loss=3.204848051071167\n",
            "Epoch #58: loss=2.8569315671920776\n",
            "Epoch #59: loss=3.1923705339431763\n",
            "Epoch #60: loss=3.1407841444015503\n",
            "Epoch #61: loss=2.753818988800049\n",
            "Epoch #62: loss=3.2491559982299805\n",
            "Epoch #63: loss=2.846066951751709\n",
            "Epoch #64: loss=3.636584758758545\n",
            "Epoch #65: loss=3.2820504903793335\n",
            "Epoch #66: loss=2.66302752494812\n",
            "Epoch #67: loss=3.1872315406799316\n",
            "Epoch #68: loss=2.9189053773880005\n",
            "Epoch #69: loss=2.524139165878296\n",
            "Epoch #70: loss=2.471502959728241\n",
            "Epoch #71: loss=3.0954779386520386\n",
            "Epoch #72: loss=2.6662757396698\n",
            "Epoch #73: loss=3.1181893348693848\n",
            "Epoch #74: loss=2.7356237173080444\n",
            "Epoch #75: loss=2.8557664155960083\n",
            "Epoch #76: loss=2.8044283390045166\n",
            "Epoch #77: loss=2.6706337928771973\n",
            "Epoch #78: loss=3.062590479850769\n",
            "Epoch #79: loss=3.1047844886779785\n",
            "Epoch #80: loss=2.977510094642639\n",
            "Epoch #81: loss=2.968890905380249\n",
            "Epoch #82: loss=2.8599518537521362\n",
            "Epoch #83: loss=3.000231981277466\n",
            "Epoch #84: loss=2.7749240398406982\n",
            "Epoch #85: loss=2.9004052877426147\n",
            "Epoch #86: loss=2.8051875829696655\n",
            "Epoch #87: loss=2.603992462158203\n",
            "Epoch #88: loss=2.676751971244812\n",
            "Epoch #89: loss=2.905965566635132\n",
            "Epoch #90: loss=2.657277464866638\n",
            "Epoch #91: loss=2.782030463218689\n",
            "Epoch #92: loss=2.9794983863830566\n",
            "Epoch #93: loss=3.075393319129944\n",
            "Epoch #94: loss=2.5410099029541016\n",
            "Epoch #95: loss=2.516387104988098\n",
            "Epoch #96: loss=2.8828593492507935\n",
            "Epoch #97: loss=3.0701109170913696\n",
            "Epoch #98: loss=2.5008955001831055\n",
            "Epoch #99: loss=2.4781826734542847\n",
            "\n",
            "Training time: 0:00:34.684269\n",
            "\n",
            "Evaluation result: {'ours': {24: {'norm': {'MSE': 0.03983480566904124, 'MAE': 0.15104417367164516}, 'raw': {'MSE': 3.3544087368628874, 'MAE': 1.3860554844661734}}, 48: {'norm': {'MSE': 0.06008489380718176, 'MAE': 0.18528087936525323}, 'raw': {'MSE': 5.059627882611466, 'MAE': 1.7002283042898247}}, 168: {'norm': {'MSE': 0.09330434614679103, 'MAE': 0.2312159837070167}, 'raw': {'MSE': 7.856971054223364, 'MAE': 2.121751371098062}}, 336: {'norm': {'MSE': 0.11025272116569412, 'MAE': 0.25584770894211323}, 'raw': {'MSE': 9.284159561124465, 'MAE': 2.3477841693454766}}, 720: {'norm': {'MSE': 0.13396286689757023, 'MAE': 0.28765127118483347}, 'raw': {'MSE': 11.28074316357996, 'MAE': 2.6396292670599872}}}, 'encoder_infer_time': 7.791670322418213, 'lr_train_time': {24: 0.7497093677520752, 48: 0.792330265045166, 168: 1.2703397274017334, 336: 1.665984869003296, 720: 2.773669481277466}, 'lr_infer_time': {24: 0.002210855484008789, 48: 0.0046918392181396484, 168: 0.010969400405883789, 336: 0.012656450271606445, 720: 0.044762372970581055}}\n",
            "Finished.\n"
          ]
        }
      ]
    }
  ]
}