{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "15ce7b3e10f544aa94cafe8a021f4b58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f1c178f76124a8787c10f8a997c8ccc",
              "IPY_MODEL_9273a1b2a30242f2beb82464239851bf"
            ],
            "layout": "IPY_MODEL_33b1b60ea0184260afb1d16cdb5e01a4"
          }
        },
        "0f1c178f76124a8787c10f8a997c8ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0500c97459c04dfbb53370218729f499",
            "placeholder": "​",
            "style": "IPY_MODEL_3d323b6f2b614b3cabb48451f5379a32",
            "value": "0.000 MB of 0.009 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "9273a1b2a30242f2beb82464239851bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fff7b6419bcc4031b5f9b29d8b5365b5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8052a99970a3454793a11db1d5b49f0f",
            "value": 0
          }
        },
        "33b1b60ea0184260afb1d16cdb5e01a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0500c97459c04dfbb53370218729f499": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d323b6f2b614b3cabb48451f5379a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fff7b6419bcc4031b5f9b29d8b5365b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8052a99970a3454793a11db1d5b49f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c501934c63d9462c972f78feb8dd2a9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5dc6b82929ce400db0331514d58b3faa",
              "IPY_MODEL_19887a44fcaf4045ad2dc38ce4b0699d",
              "IPY_MODEL_56d1995cabf04e2e850c05bbf5165f63"
            ],
            "layout": "IPY_MODEL_9e3948f2487c492d97fae67cc67ae45e"
          }
        },
        "5dc6b82929ce400db0331514d58b3faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a370524abefb412abb0e0b3faf926eda",
            "placeholder": "​",
            "style": "IPY_MODEL_38ae1136f9914256a72a3a4f759f8bf3",
            "value": "Predicting DataLoader 0: 100%"
          }
        },
        "19887a44fcaf4045ad2dc38ce4b0699d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca54361675a045638fbd23fdc18910a2",
            "max": 2857,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b823a084bfc54652a89cfb829c6cd715",
            "value": 2857
          }
        },
        "56d1995cabf04e2e850c05bbf5165f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe9b7d7057614f55becb7c1b971ab11b",
            "placeholder": "​",
            "style": "IPY_MODEL_72042f6936134b07ae08dd884c134877",
            "value": " 2857/2857 [00:13&lt;00:00, 208.25it/s]"
          }
        },
        "9e3948f2487c492d97fae67cc67ae45e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "a370524abefb412abb0e0b3faf926eda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38ae1136f9914256a72a3a4f759f8bf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca54361675a045638fbd23fdc18910a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b823a084bfc54652a89cfb829c6cd715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe9b7d7057614f55becb7c1b971ab11b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72042f6936134b07ae08dd884c134877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5528c1f2c664382b88baaf77397bebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c64379c5e04a4124b523f37c3460fff7",
              "IPY_MODEL_607783d4e2444487a2415706d870de1e",
              "IPY_MODEL_5b97d886decf48a4964aad020e17d6fd"
            ],
            "layout": "IPY_MODEL_b8db8b41e51d43a4b0d8c260a7d7b9d9"
          }
        },
        "c64379c5e04a4124b523f37c3460fff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71a096ae8c6a4698a7ac4f9397b1971d",
            "placeholder": "​",
            "style": "IPY_MODEL_5793a6b1c99c4efc82e3a3e28f57c18b",
            "value": "Predicting DataLoader 0: 100%"
          }
        },
        "607783d4e2444487a2415706d870de1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bfd0cae9dd84337a0a3c568caeb2eb9",
            "max": 2833,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d39f66e593094b469d4c00949ca3197f",
            "value": 2833
          }
        },
        "5b97d886decf48a4964aad020e17d6fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2f9db72d3dd40baad08d33c3c662838",
            "placeholder": "​",
            "style": "IPY_MODEL_1ebebb00058c49e39ac96b2912fa2569",
            "value": " 2833/2833 [00:14&lt;00:00, 198.71it/s]"
          }
        },
        "b8db8b41e51d43a4b0d8c260a7d7b9d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "71a096ae8c6a4698a7ac4f9397b1971d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5793a6b1c99c4efc82e3a3e28f57c18b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bfd0cae9dd84337a0a3c568caeb2eb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d39f66e593094b469d4c00949ca3197f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2f9db72d3dd40baad08d33c3c662838": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ebebb00058c49e39ac96b2912fa2569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92e98d9703214e94adda91a706f2cc9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b2f72b2072f4417b561bfc6ab38332f",
              "IPY_MODEL_b94abaa578e64e8d9fbb096ea12017a9",
              "IPY_MODEL_9be9daa0cfde4fc59271e708046c0b16"
            ],
            "layout": "IPY_MODEL_26a946135d3f4f358e49622ff225ba52"
          }
        },
        "5b2f72b2072f4417b561bfc6ab38332f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8326c40aa31477597401ac98680361e",
            "placeholder": "​",
            "style": "IPY_MODEL_33051e01180d43689129ee09c88f0efa",
            "value": "Predicting DataLoader 0: 100%"
          }
        },
        "b94abaa578e64e8d9fbb096ea12017a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba1070f2ca0145e492ef4f81300c151b",
            "max": 2713,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a806b6cbce80454f9b9f4c724c0a9ba9",
            "value": 2713
          }
        },
        "9be9daa0cfde4fc59271e708046c0b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22b577297b7a43bfb493e5ea1f2b9e90",
            "placeholder": "​",
            "style": "IPY_MODEL_8cd3636d30514b538b375778310d7236",
            "value": " 2713/2713 [00:12&lt;00:00, 214.76it/s]"
          }
        },
        "26a946135d3f4f358e49622ff225ba52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "f8326c40aa31477597401ac98680361e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33051e01180d43689129ee09c88f0efa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba1070f2ca0145e492ef4f81300c151b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a806b6cbce80454f9b9f4c724c0a9ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22b577297b7a43bfb493e5ea1f2b9e90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cd3636d30514b538b375778310d7236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "790b035423164684bb48e3a56e81a59e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a56bdae769949b9b556bc503dc0a61f",
              "IPY_MODEL_c85ad95f8ba14dc19e54b39a0dcfc2a9",
              "IPY_MODEL_2f8df22038974ef5ae817b087899fe57"
            ],
            "layout": "IPY_MODEL_29ea323550ac4ef783c1a9be0144b35e"
          }
        },
        "4a56bdae769949b9b556bc503dc0a61f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61b974291f974afeaa3e494c213645a7",
            "placeholder": "​",
            "style": "IPY_MODEL_eb296f9daf764c78961ef5ab3253b639",
            "value": "Predicting DataLoader 0: 100%"
          }
        },
        "c85ad95f8ba14dc19e54b39a0dcfc2a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f754e48dcfd4b1eb07b5a500167d699",
            "max": 2545,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15de2a3bdebb4d998a0721f366b33b77",
            "value": 2545
          }
        },
        "2f8df22038974ef5ae817b087899fe57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65644f835f8c4d5b81cfec680f9a54fd",
            "placeholder": "​",
            "style": "IPY_MODEL_e2d0e031ddf244ac8428f7fee507854f",
            "value": " 2545/2545 [00:10&lt;00:00, 231.72it/s]"
          }
        },
        "29ea323550ac4ef783c1a9be0144b35e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "61b974291f974afeaa3e494c213645a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb296f9daf764c78961ef5ab3253b639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f754e48dcfd4b1eb07b5a500167d699": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15de2a3bdebb4d998a0721f366b33b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65644f835f8c4d5b81cfec680f9a54fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2d0e031ddf244ac8428f7fee507854f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6457d829262d4fc0ae4d2d039d26d759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3e529219ba5487ead3ac755be77d4ee",
              "IPY_MODEL_831ee33c61cb4f2d9667fd25a1e7d412",
              "IPY_MODEL_cbc0178b215f4ff2a23ec6035d06106c"
            ],
            "layout": "IPY_MODEL_7ffa323061094a589bd6be52b1e71a74"
          }
        },
        "e3e529219ba5487ead3ac755be77d4ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea5b6fd591384b90baded0881f81a327",
            "placeholder": "​",
            "style": "IPY_MODEL_40e35c4807fa48528961060702b35cae",
            "value": "Predicting DataLoader 0: 100%"
          }
        },
        "831ee33c61cb4f2d9667fd25a1e7d412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6de860666be545788ce14e24eae1ba6a",
            "max": 2161,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e162ee0348d44c2fa83e3d74041636d7",
            "value": 2161
          }
        },
        "cbc0178b215f4ff2a23ec6035d06106c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd21f44e6cbf4763bea96d4562f0deb9",
            "placeholder": "​",
            "style": "IPY_MODEL_a93c2dc570be40fdb40fe10cc5ff89dd",
            "value": " 2161/2161 [00:09&lt;00:00, 220.66it/s]"
          }
        },
        "7ffa323061094a589bd6be52b1e71a74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "ea5b6fd591384b90baded0881f81a327": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40e35c4807fa48528961060702b35cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6de860666be545788ce14e24eae1ba6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e162ee0348d44c2fa83e3d74041636d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd21f44e6cbf4763bea96d4562f0deb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a93c2dc570be40fdb40fe10cc5ff89dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whoami-Lory271/thesis-project/blob/main/LSTM_Linear_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Symbol legend\n",
        "\n",
        "* B: batch size\n",
        "* L: lookback window (aka input_size)\n"
      ],
      "metadata": {
        "id": "7s9odzFFQWyj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations and imports\n"
      ],
      "metadata": {
        "id": "w7opc0NsjlNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning==2.0.1.post0 --quiet\n",
        "!pip install einops==0.6.1 --quiet\n",
        "!pip install ipdb --quiet\n",
        "!pip install wandb --quiet\n",
        "# !pip install objsize --quiet"
      ],
      "metadata": {
        "id": "ehQC2AKyci-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bd37872-67cb-4756-99b2-7a72ccd7b687"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.6/718.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pandas.tseries import offsets\n",
        "from pandas.tseries.frequencies import to_offset\n",
        "from typing import List\n",
        "import logging\n",
        "# https://github.com/gotcha/ipdb\n",
        "import ipdb\n",
        "import copy\n",
        "from google.colab import drive\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import functools\n",
        "# https://theaisummer.com/einsum-attention/\n",
        "import einops\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Ridge\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "from pytorch_lightning.profilers import PyTorchProfiler\n",
        "from pytorch_lightning.tuner import Tuner\n",
        "\n",
        "import wandb\n",
        "import sys\n",
        "import pickle\n",
        "import time\n",
        "import os\n",
        "import torch.fft as fft\n",
        "import argparse\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n"
      ],
      "metadata": {
        "id": "WuaX4Ts_jqmd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "!cp /content/drive/MyDrive/Tesi/code/.netrc /root/\n",
        "wandb.login()\n",
        "# 024a3906e525e6d2640af94c364128bb3d33e44b"
      ],
      "metadata": {
        "id": "4F86VEC4VtL8",
        "outputId": "d7c57826-afd2-469d-9d99-9ea16b838efa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdesantis-1849114\u001b[0m (\u001b[33mdesantis\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/dataset\n",
        "!cp \"/content/drive/MyDrive/Tesi/code/datasets/NLinear/ETTh1.csv\" \"/content/dataset/\"\n",
        "\n",
        "!cp \"/content/drive/MyDrive/Tesi/code/datasets/NLinear/ETTh2.csv\" \"/content/dataset/\"\n",
        "\n",
        "!cp \"/content/drive/MyDrive/Tesi/code/datasets/NLinear/ETTm1.csv\" \"/content/dataset/\"\n",
        "\n",
        "!cp \"/content/drive/MyDrive/Tesi/code/datasets/NLinear/ETTm2.csv\" \"/content/dataset/\"\n",
        "\n",
        "!cp \"/content/drive/MyDrive/Tesi/code/datasets/NLinear/electricity.csv\" \"/content/dataset/\""
      ],
      "metadata": {
        "id": "YKC7BhtXbkD9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions"
      ],
      "metadata": {
        "id": "J2UVU6VqgizJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup logger function\n",
        "def setup_log(self, level):\n",
        "    log = logging.getLogger(self.__class__.__name__)\n",
        "    log.setLevel(level)\n",
        "    return log"
      ],
      "metadata": {
        "id": "gkBTe3nko46m"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write log on a file\n",
        "def write_log(a):\n",
        "    with open(\"log.txt\", 'w') as file:\n",
        "        for row in a:\n",
        "            file.write(str(row))\n",
        "        log.debug(\"object logged\")"
      ],
      "metadata": {
        "id": "i8LE_3TogiZn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random seed functions\n",
        "def seed_everything(seed):\n",
        "    pl.seed_everything(seed, workers=True)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "mzBQAeoIi8l2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pickle helper\n",
        "def pkl_save(name, var):\n",
        "    os.makedirs(os.path.dirname(name), exist_ok=True)\n",
        "    with open(name, 'wb') as f:\n",
        "        pickle.dump(var, f)\n",
        "\n",
        "def pkl_load(name):\n",
        "    with open(name, 'rb') as f:\n",
        "        return pickle.load(f)"
      ],
      "metadata": {
        "id": "NxBH76S1gdKm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MAE(pred, true):\n",
        "    return np.mean(np.abs(pred - true))\n",
        "\n",
        "\n",
        "def MSE(pred, true):\n",
        "    return np.mean((pred - true) ** 2)\n",
        "\n",
        "\n",
        "def metric(pred, true):\n",
        "    mse = MSE(pred, true)\n",
        "    mae = MAE(pred, true)\n",
        "\n",
        "    return mse, mae"
      ],
      "metadata": {
        "id": "2YdeAger1_7N"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constants"
      ],
      "metadata": {
        "id": "94xSbfaKkOmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SLinear : fijs8ftw, [2373, 901, 1223, 657, 681]\n",
        "\n",
        "# Linear: hbuwmdyg"
      ],
      "metadata": {
        "id": "qIAuZ1UcF0hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# logger\n",
        "LOG_LEVEL = logging.DEBUG\n",
        "\n",
        "# datasets name\n",
        "ELECTRICITY = \"electricity\"\n",
        "M5 = \"M5\"\n",
        "ETTh1 = \"ETTh1\"\n",
        "ETTh2 = \"ETTh2\"\n",
        "ETTm1 = \"ETTm1\"\n",
        "ETTm2 = \"ETTm2\"\n",
        "WEATHER = \"WTH\"\n",
        "\n",
        "# models\n",
        "SLinear = \"SLinear\"\n",
        "NLinear = \"NLinear\"\n",
        "Linear = \"Linear\"\n",
        "\n",
        "MODEL = NLinear\n",
        "DATASET = ETTh1\n",
        "\n",
        "# device\n",
        "\n",
        "DEVICE = torch.device('cpu') if not torch.cuda.is_available() else torch.device('cuda')\n",
        "\n",
        "# hyperparameters\n",
        "\n",
        "NORMALIZATION = 'z-score' # z-score || DAIN\n",
        "\n",
        "# Train\n",
        "EPOCHS = 10\n",
        "UNIVARIATE = True\n",
        "SEQ_LEN = 336\n",
        "lr_datasets = {\n",
        "    ETTh1: 0.005,\n",
        "    ETTh2: 0.05,\n",
        "    ETTm1: 0.0001,\n",
        "    ETTm2: 0.001,\n",
        "    ELECTRICITY: 0.001\n",
        "}\n",
        "\n",
        "batch_size_datasets = {\n",
        "    ETTh1: 32,\n",
        "    ETTh2: 32,\n",
        "    ETTm1: 8,\n",
        "    ETTm2: 8,\n",
        "    ELECTRICITY: 16\n",
        "}\n",
        "\n",
        "LR = 0.005 if UNIVARIATE else lr_datasets[DATASET]\n",
        "BATCH_SIZE = 32 if UNIVARIATE else batch_size_datasets[DATASET]\n",
        "\n",
        "# Eval\n",
        "EVALUATE = True\n",
        "\n",
        "\n",
        "# training\n",
        "TRAIN = False\n",
        "TEST = False\n",
        "DETERMINISTIC = True\n",
        "LOAD_MODEL = True\n",
        "RESUME_TRAINING = False\n",
        "MEMORY_PROFILING = False\n",
        "LOAD_ENCODE = False\n",
        "\n",
        "# predict\n",
        "PREDICT = True\n",
        "BEST_BATCH_IDX = [2373, 901, 1223, 657, 681] #[-1, -1, -1, -1, -1] # set the predictions index\n",
        "\n",
        "# wandb\n",
        "\n",
        "SETTINGS_STRING = \"univariate\" if UNIVARIATE else \"multivariate\"\n",
        "RUN_ID = \"hbuwmdyg\"\n",
        "RESUME_RUN = True\n",
        "RUN_ID = wandb.util.generate_id() if not RESUME_RUN else RUN_ID\n",
        "if MODEL == SLinear:\n",
        "    if NORMALIZATION == 'DAIN':\n",
        "        MODEL_ID = MODEL+'_'+NORMALIZATION+'_'+DATASET+'_'+SETTINGS_STRING\n",
        "    else:\n",
        "        MODEL_ID = MODEL+'_'+DATASET+'_'+SETTINGS_STRING\n",
        "print(f\"current RUN_ID is {RUN_ID}\")\n",
        "\n",
        "\n",
        "#paths\n",
        "MODEL_SETTINGS_FOLDER = \"/univariate\" if UNIVARIATE else \"/multivariate\"\n",
        "ROOT_FOLDER = \"/content/drive/MyDrive/Tesi/code\"\n",
        "MODEL_FOLDER = ROOT_FOLDER + \"/models\"\n",
        "CHECKPOINT_FOLDER = ROOT_FOLDER + \"/checkpoints\" + \"/\" + MODEL + \"/\" + DATASET + MODEL_SETTINGS_FOLDER\n",
        "# LOGS_FOLDER = ROOT_FOLDER + \"/logs\"\n",
        "ENCODING_FOLDER = ROOT_FOLDER + \"/encoding/\" + MODEL + \"/\" + DATASET + MODEL_SETTINGS_FOLDER\n",
        "FORECASTING_RESULT = ROOT_FOLDER + \"/forecasting_result/\" + MODEL + \"/\" + DATASET + MODEL_SETTINGS_FOLDER\n",
        "\n",
        "datasets_name = {\n",
        "    ELECTRICITY: \"electricity.csv\",\n",
        "    ETTh1: \"ETTh1.csv\",\n",
        "    ETTh2: \"ETTh2.csv\",\n",
        "    ETTm1: \"ETTm1.csv\",\n",
        "    ETTm2: \"ETTm2.csv\"\n",
        "}\n",
        "\n",
        "datasets_pred_lens = {\n",
        "    ELECTRICITY: [336, 720], # [24, 48, 168, 336, 720]\n",
        "    ETTh1: [24, 48, 168, 336, 720],\n",
        "    ETTh2: [24, 48, 168, 336, 720],\n",
        "    WEATHER: [24, 48, 168, 336, 720],\n",
        "    M5: [28],\n",
        "    ETTm1: [24, 48, 96, 288, 672],\n",
        "    ETTm2: [24, 48, 96, 288, 672]\n",
        "}\n",
        "\n",
        "enc_in = {\n",
        "    ELECTRICITY: 321,\n",
        "    ETTh1: 7,\n",
        "    ETTh2: 7,\n",
        "    ETTm1: 7,\n",
        "    ETTm2: 7\n",
        "}\n",
        "\n",
        "config = dict(\n",
        "    model_id = MODEL_ID,\n",
        "    epochs = 0 if EPOCHS is None else EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    learning_rate = LR,\n",
        "    dataset=DATASET,\n",
        "    architecture=MODEL,\n",
        "    run_id = RUN_ID)"
      ],
      "metadata": {
        "id": "ySxfaOHQkQ_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c623f807-18b1-46f2-f6c5-604570ad25ab"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current RUN_ID is hbuwmdyg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WanDB"
      ],
      "metadata": {
        "id": "WXYPOAZ8O2zL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# start a new experiment\n",
        "run = wandb.init(project=config['model_id'], config = config, id = config[\"run_id\"], resume = 'allow')\n",
        "ENCODING_FOLDER += \"/\" + run.name\n",
        "FORECASTING_RESULT += \"/\" + run.name\n",
        "CHECKPOINT_FOLDER += \"/\" + run.name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "15ce7b3e10f544aa94cafe8a021f4b58",
            "0f1c178f76124a8787c10f8a997c8ccc",
            "9273a1b2a30242f2beb82464239851bf",
            "33b1b60ea0184260afb1d16cdb5e01a4",
            "0500c97459c04dfbb53370218729f499",
            "3d323b6f2b614b3cabb48451f5379a32",
            "fff7b6419bcc4031b5f9b29d8b5365b5",
            "8052a99970a3454793a11db1d5b49f0f"
          ]
        },
        "id": "sC_id8hdO5i_",
        "outputId": "5a07c0ba-9e7b-4a38-de3f-621f29e24eea"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:fijs8ftw) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.000 MB of 0.009 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15ce7b3e10f544aa94cafe8a021f4b58"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dainty-feather-6</strong> at: <a href='https://wandb.ai/desantis/SLinear_ETTh1_univariate/runs/fijs8ftw' target=\"_blank\">https://wandb.ai/desantis/SLinear_ETTh1_univariate/runs/fijs8ftw</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230927_142241-fijs8ftw/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:fijs8ftw). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230927_143311-hbuwmdyg</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/desantis/SLinear_ETTh1_univariate/runs/hbuwmdyg' target=\"_blank\">dauntless-thunder-7</a></strong> to <a href='https://wandb.ai/desantis/SLinear_ETTh1_univariate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/desantis/SLinear_ETTh1_univariate' target=\"_blank\">https://wandb.ai/desantis/SLinear_ETTh1_univariate</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/desantis/SLinear_ETTh1_univariate/runs/hbuwmdyg' target=\"_blank\">https://wandb.ai/desantis/SLinear_ETTh1_univariate/runs/hbuwmdyg</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Argument Parser"
      ],
      "metadata": {
        "id": "A7-lHvJRzOty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser(description='Autoformer & Transformer family for Time Series Forecasting')\n",
        "\n",
        "# basic config\n",
        "parser.add_argument('--is_training', type=int, required=True, default=1, help='status')\n",
        "parser.add_argument('--train_only', type=bool, required=False, default=False, help='perform training on full input dataset without validation and testing')\n",
        "parser.add_argument('--model_id', type=str, required=True, default='test', help='model id')\n",
        "parser.add_argument('--model', type=str, required=True, default='Autoformer',\n",
        "                    help='model name, options: [Autoformer, Informer, Transformer]')\n",
        "\n",
        "# data loader\n",
        "parser.add_argument('--data', type=str, required=True, default='ETTm1', help='dataset type')\n",
        "parser.add_argument('--root_path', type=str, default='./data/ETT/', help='root path of the data file')\n",
        "parser.add_argument('--data_path', type=str, default='ETTh1.csv', help='data file')\n",
        "parser.add_argument('--features', type=str, default='M',\n",
        "                    help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')\n",
        "parser.add_argument('--target', type=str, default='OT', help='target feature in S or MS task')\n",
        "parser.add_argument('--freq', type=str, default='h',\n",
        "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
        "parser.add_argument('--checkpoints', type=str, default='./checkpoints/', help='location of model checkpoints')\n",
        "\n",
        "# forecasting task\n",
        "parser.add_argument('--seq_len', type=int, default=96, help='input sequence length')\n",
        "parser.add_argument('--label_len', type=int, default=48, help='start token length')\n",
        "parser.add_argument('--pred_len', type=int, default=96, help='prediction sequence length')\n",
        "parser.add_argument('--seed', type=int, default=0, help='random seed')\n",
        "\n",
        "\n",
        "# DLinear\n",
        "parser.add_argument('--individual', action='store_true', default=False, help='DLinear: a linear layer for each variate(channel) individually')\n",
        "\n",
        "# SLinear\n",
        "parser.add_argument('--normalization', type=str, default='z-score', help='normalization')\n",
        "parser.add_argument('--pred_batch_index', nargs=\"+\", type=int, help = \"prediction index\", required = True)\n",
        "\n",
        "\n",
        "# Formers\n",
        "parser.add_argument('--embed_type', type=int, default=0, help='0: default 1: value embedding + temporal embedding + positional embedding 2: value embedding + temporal embedding 3: value embedding + positional embedding 4: value embedding')\n",
        "parser.add_argument('--enc_in', type=int, default=7, help='encoder input size') # DLinear with --individual, use this hyperparameter as the number of channels\n",
        "parser.add_argument('--dec_in', type=int, default=7, help='decoder input size')\n",
        "parser.add_argument('--c_out', type=int, default=7, help='output size')\n",
        "parser.add_argument('--d_model', type=int, default=512, help='dimension of model')\n",
        "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
        "parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')\n",
        "parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')\n",
        "parser.add_argument('--d_ff', type=int, default=2048, help='dimension of fcn')\n",
        "parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')\n",
        "parser.add_argument('--factor', type=int, default=1, help='attn factor')\n",
        "parser.add_argument('--distil', action='store_false',\n",
        "                    help='whether to use distilling in encoder, using this argument means not using distilling',\n",
        "                    default=True)\n",
        "parser.add_argument('--dropout', type=float, default=0.05, help='dropout')\n",
        "parser.add_argument('--embed', type=str, default='timeF',\n",
        "                    help='time features encoding, options:[timeF, fixed, learned]')\n",
        "parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
        "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in ecoder')\n",
        "parser.add_argument('--do_predict', action='store_true', help='whether to predict unseen future data')\n",
        "\n",
        "# optimization\n",
        "parser.add_argument('--num_workers', type=int, default=10, help='data loader num workers')\n",
        "parser.add_argument('--train_epochs', type=int, default=10, help='train epochs')\n",
        "parser.add_argument('--batch_size', type=int, default=32, help='batch size of train input data')\n",
        "parser.add_argument('--patience', type=int, default=3, help='early stopping patience')\n",
        "parser.add_argument('--learning_rate', type=float, default=0.0001, help='optimizer learning rate')\n",
        "parser.add_argument('--des', type=str, default='test', help='exp description')\n",
        "parser.add_argument('--loss', type=str, default='mse', help='loss function')\n",
        "parser.add_argument('--lradj', type=str, default='type1', help='adjust learning rate')\n",
        "parser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=False)\n",
        "\n",
        "# GPU\n",
        "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
        "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
        "parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
        "parser.add_argument('--devices', type=str, default='0,1,2,3', help='device ids of multile gpus')\n",
        "parser.add_argument('--test_flop', action='store_true', default=False, help='See utils/tools for usage')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7o0eClOzR6d",
        "outputId": "b104313c-17ea-477d-f714-b52bd30dc547"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreTrueAction(option_strings=['--test_flop'], dest='test_flop', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='See utils/tools for usage', metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logger"
      ],
      "metadata": {
        "id": "8j5-8dn5ppGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create logger\n",
        "log = logging.getLogger('APP')\n",
        "log.setLevel(LOG_LEVEL)\n",
        "logging.basicConfig(level=LOG_LEVEL)\n",
        "\n",
        "# # create console handler and set level to debug\n",
        "# ch = logging.StreamHandler()\n",
        "# ch.setLevel(logging.INFO)\n",
        "\n",
        "# # create formatter\n",
        "# formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# # add formatter to ch\n",
        "# ch.setFormatter(formatter)\n",
        "\n",
        "# # add ch to logger\n",
        "# logger.addHandler(ch)"
      ],
      "metadata": {
        "id": "iRLWiTu4mlx9"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset and Datamodule"
      ],
      "metadata": {
        "id": "ma655OWbiZ0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "XYSq_-WilrgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeFeature:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        pass\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + \"()\"\n",
        "\n",
        "\n",
        "class SecondOfMinute(TimeFeature):\n",
        "    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return index.second / 59.0 - 0.5\n",
        "\n",
        "\n",
        "class MinuteOfHour(TimeFeature):\n",
        "    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return index.minute / 59.0 - 0.5\n",
        "\n",
        "\n",
        "class HourOfDay(TimeFeature):\n",
        "    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return index.hour / 23.0 - 0.5\n",
        "\n",
        "\n",
        "class DayOfWeek(TimeFeature):\n",
        "    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return index.dayofweek / 6.0 - 0.5\n",
        "\n",
        "\n",
        "class DayOfMonth(TimeFeature):\n",
        "    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return (index.day - 1) / 30.0 - 0.5\n",
        "\n",
        "\n",
        "class DayOfYear(TimeFeature):\n",
        "    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return (index.dayofyear - 1) / 365.0 - 0.5\n",
        "\n",
        "\n",
        "class MonthOfYear(TimeFeature):\n",
        "    \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return (index.month - 1) / 11.0 - 0.5\n",
        "\n",
        "\n",
        "class WeekOfYear(TimeFeature):\n",
        "    \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return (index.isocalendar().week - 1) / 52.0 - 0.5\n",
        "\n",
        "\n",
        "def time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n",
        "    \"\"\"\n",
        "    Returns a list of time features that will be appropriate for the given frequency string.\n",
        "    Parameters\n",
        "    ----------\n",
        "    freq_str\n",
        "        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n",
        "    \"\"\"\n",
        "\n",
        "    features_by_offsets = {\n",
        "        offsets.YearEnd: [],\n",
        "        offsets.QuarterEnd: [MonthOfYear],\n",
        "        offsets.MonthEnd: [MonthOfYear],\n",
        "        offsets.Week: [DayOfMonth, WeekOfYear],\n",
        "        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n",
        "        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n",
        "        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
        "        offsets.Minute: [\n",
        "            MinuteOfHour,\n",
        "            HourOfDay,\n",
        "            DayOfWeek,\n",
        "            DayOfMonth,\n",
        "            DayOfYear,\n",
        "        ],\n",
        "        offsets.Second: [\n",
        "            SecondOfMinute,\n",
        "            MinuteOfHour,\n",
        "            HourOfDay,\n",
        "            DayOfWeek,\n",
        "            DayOfMonth,\n",
        "            DayOfYear,\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    offset = to_offset(freq_str)\n",
        "\n",
        "    for offset_type, feature_classes in features_by_offsets.items():\n",
        "        if isinstance(offset, offset_type):\n",
        "            return [cls() for cls in feature_classes]\n",
        "\n",
        "    supported_freq_msg = f\"\"\"\n",
        "    Unsupported frequency {freq_str}\n",
        "    The following frequencies are supported:\n",
        "        Y   - yearly\n",
        "            alias: A\n",
        "        M   - monthly\n",
        "        W   - weekly\n",
        "        D   - daily\n",
        "        B   - business days\n",
        "        H   - hourly\n",
        "        T   - minutely\n",
        "            alias: min\n",
        "        S   - secondly\n",
        "    \"\"\"\n",
        "    raise RuntimeError(supported_freq_msg)\n",
        "\n",
        "\n",
        "def time_features(dates, freq='h'):\n",
        "    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])"
      ],
      "metadata": {
        "id": "w_x8XS1Sltek"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets"
      ],
      "metadata": {
        "id": "0dOIrBBc1ewD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset_ETT_hour(Dataset):\n",
        "    def __init__(self, root_path, flag='train', size=None,\n",
        "                 features='S', data_path='ETTh1.csv',\n",
        "                 target='OT', scale=True, timeenc=0, freq='h', train_only=False):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['train', 'test', 'val']\n",
        "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
        "        self.set_type = type_map[flag]\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
        "                                          self.data_path))\n",
        "\n",
        "        border1s = [0, 12 * 30 * 24 - self.seq_len, 12 * 30 * 24 + 4 * 30 * 24 - self.seq_len]\n",
        "        border2s = [12 * 30 * 24, 12 * 30 * 24 + 4 * 30 * 24, 12 * 30 * 24 + 8 * 30 * 24]\n",
        "        border1 = border1s[self.set_type]\n",
        "        border2 = border2s[self.set_type]\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "        elif self.features == 'S':\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            train_data = df_data[border1s[0]:border2s[0]]\n",
        "            self.scaler.fit(train_data.values)\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "        df_stamp = df_raw[['date']][border1:border2]\n",
        "        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            data_stamp = df_stamp.drop(['date'], 1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = data[border1:border2]\n",
        "        self.data_y = data[border1:border2]\n",
        "        self.data_stamp = data_stamp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        seq_y = self.data_y[r_begin:r_end]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)\n",
        "\n",
        "\n",
        "class Dataset_ETT_minute(Dataset):\n",
        "    def __init__(self, root_path, flag='train', size=None,\n",
        "                 features='S', data_path='ETTm1.csv',\n",
        "                 target='OT', scale=True, timeenc=0, freq='t', train_only=False):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['train', 'test', 'val']\n",
        "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
        "        self.set_type = type_map[flag]\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
        "                                          self.data_path))\n",
        "\n",
        "        border1s = [0, 12 * 30 * 24 * 4 - self.seq_len, 12 * 30 * 24 * 4 + 4 * 30 * 24 * 4 - self.seq_len]\n",
        "        border2s = [12 * 30 * 24 * 4, 12 * 30 * 24 * 4 + 4 * 30 * 24 * 4, 12 * 30 * 24 * 4 + 8 * 30 * 24 * 4]\n",
        "        border1 = border1s[self.set_type]\n",
        "        border2 = border2s[self.set_type]\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "        elif self.features == 'S':\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            train_data = df_data[border1s[0]:border2s[0]]\n",
        "            self.scaler.fit(train_data.values)\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "        df_stamp = df_raw[['date']][border1:border2]\n",
        "        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            df_stamp['minute'] = df_stamp.date.apply(lambda row: row.minute, 1)\n",
        "            df_stamp['minute'] = df_stamp.minute.map(lambda x: x // 15)\n",
        "            data_stamp = df_stamp.drop(['date'], 1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = data[border1:border2]\n",
        "        self.data_y = data[border1:border2]\n",
        "        self.data_stamp = data_stamp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        seq_y = self.data_y[r_begin:r_end]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)\n",
        "\n",
        "\n",
        "class Dataset_Custom(Dataset):\n",
        "    def __init__(self, root_path, flag='train', size=None,\n",
        "                 features='S', data_path='ETTh1.csv',\n",
        "                 target='OT', scale=True, timeenc=0, freq='h', train_only=False):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['train', 'test', 'val']\n",
        "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
        "        self.set_type = type_map[flag]\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "        self.train_only = train_only\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
        "                                          self.data_path))\n",
        "\n",
        "        '''\n",
        "        df_raw.columns: ['date', ...(other features), target feature]\n",
        "        '''\n",
        "        cols = list(df_raw.columns)\n",
        "        if self.features == 'S':\n",
        "            cols.remove(self.target)\n",
        "        cols.remove('date')\n",
        "        # print(cols)\n",
        "        num_train = int(len(df_raw) * (0.7 if not self.train_only else 1))\n",
        "        num_test = int(len(df_raw) * 0.2)\n",
        "        num_vali = len(df_raw) - num_train - num_test\n",
        "        border1s = [0, num_train - self.seq_len, len(df_raw) - num_test - self.seq_len]\n",
        "        border2s = [num_train, num_train + num_vali, len(df_raw)]\n",
        "        border1 = border1s[self.set_type]\n",
        "        border2 = border2s[self.set_type]\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            df_raw = df_raw[['date'] + cols]\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "        elif self.features == 'S':\n",
        "            df_raw = df_raw[['date'] + cols + [self.target]]\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            train_data = df_data[border1s[0]:border2s[0]]\n",
        "            self.scaler.fit(train_data.values)\n",
        "            # print(self.scaler.mean_)\n",
        "            # exit()\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "        df_stamp = df_raw[['date']][border1:border2]\n",
        "        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            data_stamp = df_stamp.drop(['date'], 1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = data[border1:border2]\n",
        "        self.data_y = data[border1:border2]\n",
        "        self.data_stamp = data_stamp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        seq_y = self.data_y[r_begin:r_end]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)\n",
        "\n",
        "\n",
        "class Dataset_Pred(Dataset):\n",
        "    def __init__(self, root_path, flag='pred', size=None,\n",
        "                 features='S', data_path='ETTh1.csv',\n",
        "                 target='OT', scale=True, inverse=False, timeenc=0, freq='15min', cols=None, train_only=False):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['pred']\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.inverse = inverse\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "        self.cols = cols\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
        "                                          self.data_path))\n",
        "        '''\n",
        "        df_raw.columns: ['date', ...(other features), target feature]\n",
        "        '''\n",
        "        if self.cols:\n",
        "            cols = self.cols.copy()\n",
        "        else:\n",
        "            cols = list(df_raw.columns)\n",
        "            self.cols = cols.copy()\n",
        "            cols.remove('date')\n",
        "        if self.features == 'S':\n",
        "            cols.remove(self.target)\n",
        "        border1 = len(df_raw) - self.seq_len\n",
        "        border2 = len(df_raw)\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            df_raw = df_raw[['date'] + cols]\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "        elif self.features == 'S':\n",
        "            df_raw = df_raw[['date'] + cols + [self.target]]\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            self.scaler.fit(df_data.values)\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "        tmp_stamp = df_raw[['date']][border1:border2]\n",
        "        tmp_stamp['date'] = pd.to_datetime(tmp_stamp.date)\n",
        "        pred_dates = pd.date_range(tmp_stamp.date.values[-1], periods=self.pred_len + 1, freq=self.freq)\n",
        "\n",
        "        df_stamp = pd.DataFrame(columns=['date'])\n",
        "        df_stamp.date = list(tmp_stamp.date.values) + list(pred_dates[1:])\n",
        "        self.future_dates = list(pred_dates[1:])\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            df_stamp['minute'] = df_stamp.date.apply(lambda row: row.minute, 1)\n",
        "            df_stamp['minute'] = df_stamp.minute.map(lambda x: x // 15)\n",
        "            data_stamp = df_stamp.drop(['date'], 1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = data[border1:border2]\n",
        "        if self.inverse:\n",
        "            self.data_y = df_data.values[border1:border2]\n",
        "        else:\n",
        "            self.data_y = data[border1:border2]\n",
        "        self.data_stamp = data_stamp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        if self.inverse:\n",
        "            seq_y = self.data_x[r_begin:r_begin + self.label_len]\n",
        "        else:\n",
        "            seq_y = self.data_y[r_begin:r_begin + self.label_len]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)"
      ],
      "metadata": {
        "id": "qhF8zP_w1buC"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datamodule"
      ],
      "metadata": {
        "id": "5NTY0pc31jOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.args = args\n",
        "        self.data_dict = {\n",
        "            'ETTh1': Dataset_ETT_hour,\n",
        "            'ETTh2': Dataset_ETT_hour,\n",
        "            'ETTm1': Dataset_ETT_minute,\n",
        "            'ETTm2': Dataset_ETT_minute,\n",
        "            'electricity': Dataset_Custom,\n",
        "        }\n",
        "        self.Data = self.data_dict[args.data]\n",
        "        self.timeenc = 0 if args.embed != 'timeF' else 1\n",
        "        self.train_only = args.train_only\n",
        "\n",
        "    def setup(self, stage: str):\n",
        "        args = self.args\n",
        "        shuffle_flag = True\n",
        "        drop_last = True\n",
        "        batch_size = args.batch_size\n",
        "        freq = args.freq\n",
        "        Data = self.Data\n",
        "        timeenc = self.timeenc\n",
        "        train_only = self.train_only\n",
        "\n",
        "        if stage == \"fit\":\n",
        "            self.batch_size = batch_size\n",
        "            self.shuffle_flag = shuffle_flag\n",
        "            self.drop_last = drop_last\n",
        "            self.train = Data(\n",
        "                root_path=args.root_path,\n",
        "                data_path=args.data_path,\n",
        "                flag=\"train\",\n",
        "                size=[args.seq_len, args.label_len, args.pred_len],\n",
        "                features=args.features,\n",
        "                target=args.target,\n",
        "                timeenc=timeenc,\n",
        "                freq=freq,\n",
        "                train_only=train_only\n",
        "            )\n",
        "\n",
        "            self.val = Data(\n",
        "                root_path=args.root_path,\n",
        "                data_path=args.data_path,\n",
        "                flag=\"val\",\n",
        "                size=[args.seq_len, args.label_len, args.pred_len],\n",
        "                features=args.features,\n",
        "                target=args.target,\n",
        "                timeenc=timeenc,\n",
        "                freq=freq,\n",
        "                train_only=train_only\n",
        "            )\n",
        "\n",
        "        if stage == 'test':\n",
        "            shuffle_flag = False\n",
        "            drop_last = False\n",
        "            batch_size = args.batch_size\n",
        "            freq = args.freq\n",
        "\n",
        "            self.batch_size = batch_size\n",
        "            self.shuffle_flag = shuffle_flag\n",
        "            self.drop_last = drop_last\n",
        "\n",
        "            self.test = Data(\n",
        "                root_path=args.root_path,\n",
        "                data_path=args.data_path,\n",
        "                flag=\"test\",\n",
        "                size=[args.seq_len, args.label_len, args.pred_len],\n",
        "                features=args.features,\n",
        "                target=args.target,\n",
        "                timeenc=timeenc,\n",
        "                freq=freq,\n",
        "                train_only=train_only\n",
        "            )\n",
        "\n",
        "\n",
        "        if stage == 'predict':\n",
        "            shuffle_flag = False\n",
        "            drop_last = False\n",
        "            batch_size = 1\n",
        "            freq = args.freq\n",
        "            # Data = Dataset_Pred\n",
        "\n",
        "            self.batch_size = batch_size\n",
        "            self.shuffle_flag = shuffle_flag\n",
        "            self.drop_last = drop_last\n",
        "\n",
        "            self.predict = Data(\n",
        "                root_path=args.root_path,\n",
        "                data_path=args.data_path,\n",
        "                flag=\"test\",\n",
        "                size=[args.seq_len, args.label_len, args.pred_len],\n",
        "                features=args.features,\n",
        "                target=args.target,\n",
        "                timeenc=timeenc,\n",
        "                freq=freq,\n",
        "                train_only=train_only\n",
        "            )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train,\n",
        "                        batch_size=self.batch_size,\n",
        "                        shuffle=self.shuffle_flag,\n",
        "                        num_workers=self.args.num_workers,\n",
        "                        drop_last=self.drop_last)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val,\n",
        "                        batch_size=self.batch_size,\n",
        "                        shuffle=self.shuffle_flag,\n",
        "                        num_workers=self.args.num_workers,\n",
        "                        drop_last=self.drop_last)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test,\n",
        "                        batch_size=self.batch_size,\n",
        "                        shuffle=self.shuffle_flag,\n",
        "                        num_workers=self.args.num_workers,\n",
        "                        drop_last=self.drop_last)\n",
        "\n",
        "    def predict_dataloader(self):\n",
        "        return DataLoader(self.predict,\n",
        "                        batch_size=self.batch_size,\n",
        "                        shuffle=self.shuffle_flag,\n",
        "                        num_workers=self.args.num_workers,\n",
        "                        drop_last=self.drop_last)"
      ],
      "metadata": {
        "id": "37YF2vGhSYjl"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "S84zQ9UjigKj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "Oq9gmXnKGmVP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OFFCIAL IMPLEMENTATIONS 🔽"
      ],
      "metadata": {
        "id": "wriuLMemIEtl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear"
      ],
      "metadata": {
        "id": "nmtNYOkjVSvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear(pl.LightningModule):\n",
        "    \"\"\"\n",
        "    Just one Linear layer\n",
        "    \"\"\"\n",
        "    def __init__(self, configs):\n",
        "        super(Linear, self).__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.configs = configs\n",
        "        self.seq_len = configs.seq_len\n",
        "        self.pred_len = configs.pred_len\n",
        "        self.pred_batch_index = configs.pred_batch_index[0]\n",
        "\n",
        "        # Use this line if you want to visualize the weights\n",
        "        # self.NLinear.weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
        "        self.channels = configs.enc_in\n",
        "        self.individual = configs.individual\n",
        "\n",
        "        if self.individual:\n",
        "            self.Linear = nn.ModuleList()\n",
        "            for i in range(self.channels):\n",
        "                self.Linear.append(nn.Linear(self.seq_len,self.pred_len))\n",
        "        else:\n",
        "            self.Linear = nn.Linear(self.seq_len, self.pred_len)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        model_optim = optim.Adam(self.parameters(), lr=self.configs.learning_rate)\n",
        "        return model_optim\n",
        "\n",
        "    def _get_loss(self):\n",
        "        criterion = nn.MSELoss()\n",
        "        return criterion\n",
        "\n",
        "    def on_train_epoch_start(self):\n",
        "        self.train_loss = []\n",
        "\n",
        "    def on_validation_epoch_start(self):\n",
        "        self.val_loss = []\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        train_loss = np.average(self.train_loss)\n",
        "        self.log(\"train_loss\", train_loss, prog_bar=True)\n",
        "        wandb.log({\"train\": {\"epoch\": self.current_epoch ,\"train_loss\": train_loss}})\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        val_loss = np.average(self.val_loss)\n",
        "        self.log(\"val_loss\", val_loss, prog_bar=True)\n",
        "        wandb.log({\"val\": {\"epoch\": self.current_epoch ,\"val_loss\": val_loss}})\n",
        "        model_optim = self.optimizers(use_pl_optimizer=False)\n",
        "        adjust_learning_rate(model_optim, self.current_epoch + 1, self.configs)\n",
        "\n",
        "    def on_test_start(self):\n",
        "        # Testing\n",
        "        self.preds = []\n",
        "        self.trues = []\n",
        "        self.inputx = []\n",
        "\n",
        "    def on_test_end(self):\n",
        "        self.preds = np.concatenate(self.preds, axis=0)\n",
        "        self.trues = np.concatenate(self.trues, axis=0)\n",
        "        self.mse, self.mae = metric(self.preds, self.trues)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        batch_x, batch_y, batch_x_mark, batch_y_mark = batch\n",
        "        batch_x = batch_x.float()\n",
        "        batch_y = batch_y.float()\n",
        "        batch_x_mark = batch_x_mark.float()\n",
        "        batch_y_mark = batch_y_mark.float()\n",
        "        outputs = self(batch_x)\n",
        "        f_dim = -1 if self.configs.features == 'MS' else 0\n",
        "        outputs = outputs[:, -self.pred_len:, f_dim:]\n",
        "        batch_y = batch_y[:, -self.pred_len:, f_dim:]\n",
        "        criterion = self._get_loss()\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        self.train_loss.append(loss.item())\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        batch_x, batch_y, batch_x_mark, batch_y_mark = batch\n",
        "        batch_x = batch_x.float()\n",
        "        batch_y = batch_y.float()\n",
        "        batch_x_mark = batch_x_mark.float()\n",
        "        batch_y_mark = batch_y_mark.float()\n",
        "        outputs = self(batch_x)\n",
        "        f_dim = -1 if self.configs.features == 'MS' else 0\n",
        "        outputs = outputs[:, -self.pred_len:, f_dim:]\n",
        "        batch_y = batch_y[:, -self.pred_len:, f_dim:]\n",
        "        criterion = self._get_loss()\n",
        "        pred = outputs.detach().cpu()\n",
        "        true = batch_y.detach().cpu()\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        self.val_loss.append(loss.item())\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        batch_x, batch_y, batch_x_mark, batch_y_mark = batch\n",
        "        batch_x = batch_x.float()\n",
        "        batch_y = batch_y.float()\n",
        "        batch_x_mark = batch_x_mark.float()\n",
        "        batch_y_mark = batch_y_mark.float()\n",
        "        outputs = self(batch_x)\n",
        "        f_dim = -1 if self.configs.features == 'MS' else 0\n",
        "        outputs = outputs[:, -self.pred_len:, f_dim:]\n",
        "        batch_y = batch_y[:, -self.pred_len:, f_dim:]\n",
        "        outputs = outputs.detach().cpu().numpy()\n",
        "        batch_y = batch_y.detach().cpu().numpy()\n",
        "\n",
        "        pred = outputs  # outputs.detach().cpu().numpy()  # .squeeze()\n",
        "        true = batch_y  # batch_y.detach().cpu().numpy()  # .squeeze()\n",
        "\n",
        "        self.preds.append(pred)\n",
        "        self.trues.append(true)\n",
        "        # self.inputx.append(batch_x.detach().numpy())\n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        batch_x, batch_y, batch_x_mark, batch_y_mark = batch\n",
        "        batch_x = batch_x.float()\n",
        "        batch_y = batch_y.float()\n",
        "        batch_x_mark = batch_x_mark.float()\n",
        "        batch_y_mark = batch_y_mark.float()\n",
        "        outputs = self(batch_x)\n",
        "        f_dim = -1 if self.configs.features == 'MS' else 0\n",
        "        outputs = outputs[:, -self.pred_len:, f_dim:]\n",
        "        batch_y = batch_y[:, -self.pred_len:, f_dim:]\n",
        "        criterion = self._get_loss()\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        if self.pred_batch_index > -1 and batch_idx > self.pred_batch_index:\n",
        "            return\n",
        "        if batch_idx == 0 or (self.pred_batch_index > -1 and batch_idx == self.pred_batch_index):\n",
        "            self.best_prediction = (outputs.detach().cpu(), batch_y.detach().cpu(), loss.item(), batch_idx)\n",
        "            return\n",
        "        if loss < self.best_prediction[2]:\n",
        "            self.best_prediction = (outputs.detach().cpu(), batch_y.detach().cpu(), loss.item(), batch_idx)\n",
        "        return\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [Batch, Input length, Channel]\n",
        "        if self.individual:\n",
        "            output = torch.zeros([x.size(0),self.pred_len,x.size(2)],dtype=x.dtype).to(x.device)\n",
        "            for i in range(self.channels):\n",
        "                output[:,:,i] = self.Linear[i](x[:,:,i])\n",
        "            x = output\n",
        "        else:\n",
        "            x = self.Linear(x.permute(0,2,1)).permute(0,2,1)\n",
        "        return x # [Batch, Output length, Channel]"
      ],
      "metadata": {
        "id": "h1bh4J5OVXD0"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NLinear"
      ],
      "metadata": {
        "id": "9VKcjh66BBAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NLinear(pl.LightningModule):\n",
        "    \"\"\"\n",
        "    Just one Linear layer\n",
        "    \"\"\"\n",
        "    def __init__(self, configs):\n",
        "        super(NLinear, self).__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.configs = configs\n",
        "        self.seq_len = configs.seq_len\n",
        "        self.pred_len = configs.pred_len\n",
        "        self.pred_batch_index = configs.pred_batch_index[0]\n",
        "\n",
        "        # Use this line if you want to visualize the weights\n",
        "        # self.NLinear.weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
        "        self.channels = configs.enc_in\n",
        "        self.individual = configs.individual\n",
        "\n",
        "        if self.individual:\n",
        "            self.Linear = nn.ModuleList()\n",
        "            for i in range(self.channels):\n",
        "                self.Linear.append(nn.Linear(self.seq_len,self.pred_len))\n",
        "        else:\n",
        "            self.Linear = nn.Linear(self.seq_len, self.pred_len)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        model_optim = optim.Adam(self.parameters(), lr=self.configs.learning_rate)\n",
        "        return model_optim\n",
        "\n",
        "    def _get_loss(self):\n",
        "        criterion = nn.MSELoss()\n",
        "        return criterion\n",
        "\n",
        "    def on_train_epoch_start(self):\n",
        "        self.train_loss = []\n",
        "\n",
        "    def on_validation_epoch_start(self):\n",
        "        self.val_loss = []\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        train_loss = np.average(self.train_loss)\n",
        "        self.log(\"train_loss\", train_loss, prog_bar=True)\n",
        "        wandb.log({\"train\": {\"epoch\": self.current_epoch ,\"train_loss\": train_loss}})\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        val_loss = np.average(self.val_loss)\n",
        "        self.log(\"val_loss\", val_loss, prog_bar=True)\n",
        "        wandb.log({\"val\": {\"epoch\": self.current_epoch ,\"val_loss\": val_loss}})\n",
        "        model_optim = self.optimizers(use_pl_optimizer=False)\n",
        "        adjust_learning_rate(model_optim, self.current_epoch + 1, self.configs)\n",
        "\n",
        "    def on_test_start(self):\n",
        "        # Testing\n",
        "        self.preds = []\n",
        "        self.trues = []\n",
        "        self.inputx = []\n",
        "\n",
        "    def on_test_end(self):\n",
        "        self.preds = np.concatenate(self.preds, axis=0)\n",
        "        self.trues = np.concatenate(self.trues, axis=0)\n",
        "        self.mse, self.mae = metric(self.preds, self.trues)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        batch_x, batch_y, batch_x_mark, batch_y_mark = batch\n",
        "        batch_x = batch_x.float()\n",
        "        batch_y = batch_y.float()\n",
        "        batch_x_mark = batch_x_mark.float()\n",
        "        batch_y_mark = batch_y_mark.float()\n",
        "        outputs = self(batch_x)\n",
        "        f_dim = -1 if self.configs.features == 'MS' else 0\n",
        "        outputs = outputs[:, -self.pred_len:, f_dim:]\n",
        "        batch_y = batch_y[:, -self.pred_len:, f_dim:]\n",
        "        criterion = self._get_loss()\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        self.train_loss.append(loss.item())\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        batch_x, batch_y, batch_x_mark, batch_y_mark = batch\n",
        "        batch_x = batch_x.float()\n",
        "        batch_y = batch_y.float()\n",
        "        batch_x_mark = batch_x_mark.float()\n",
        "        batch_y_mark = batch_y_mark.float()\n",
        "        outputs = self(batch_x)\n",
        "        f_dim = -1 if self.configs.features == 'MS' else 0\n",
        "        outputs = outputs[:, -self.pred_len:, f_dim:]\n",
        "        batch_y = batch_y[:, -self.pred_len:, f_dim:]\n",
        "        criterion = self._get_loss()\n",
        "        pred = outputs.detach().cpu()\n",
        "        true = batch_y.detach().cpu()\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        self.val_loss.append(loss.item())\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        batch_x, batch_y, batch_x_mark, batch_y_mark = batch\n",
        "        batch_x = batch_x.float()\n",
        "        batch_y = batch_y.float()\n",
        "        batch_x_mark = batch_x_mark.float()\n",
        "        batch_y_mark = batch_y_mark.float()\n",
        "        outputs = self(batch_x)\n",
        "        f_dim = -1 if self.configs.features == 'MS' else 0\n",
        "        outputs = outputs[:, -self.pred_len:, f_dim:]\n",
        "        batch_y = batch_y[:, -self.pred_len:, f_dim:]\n",
        "        outputs = outputs.detach().cpu().numpy()\n",
        "        batch_y = batch_y.detach().cpu().numpy()\n",
        "\n",
        "        pred = outputs  # outputs.detach().cpu().numpy()  # .squeeze()\n",
        "        true = batch_y  # batch_y.detach().cpu().numpy()  # .squeeze()\n",
        "\n",
        "        self.preds.append(pred)\n",
        "        self.trues.append(true)\n",
        "        # self.inputx.append(batch_x.detach().numpy())\n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        batch_x, batch_y, batch_x_mark, batch_y_mark = batch\n",
        "        batch_x = batch_x.float()\n",
        "        batch_y = batch_y.float()\n",
        "        batch_x_mark = batch_x_mark.float()\n",
        "        batch_y_mark = batch_y_mark.float()\n",
        "        outputs = self(batch_x)\n",
        "        f_dim = -1 if self.configs.features == 'MS' else 0\n",
        "        outputs = outputs[:, -self.pred_len:, f_dim:]\n",
        "        batch_y = batch_y[:, -self.pred_len:, f_dim:]\n",
        "        criterion = self._get_loss()\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        if self.pred_batch_index > -1 and batch_idx > self.pred_batch_index:\n",
        "            return\n",
        "        if batch_idx == 0 or (self.pred_batch_index > -1 and batch_idx == self.pred_batch_index):\n",
        "            self.best_prediction = (outputs.detach().cpu(), batch_y.detach().cpu(), loss.item(), batch_idx)\n",
        "            return\n",
        "        if loss < self.best_prediction[2]:\n",
        "            self.best_prediction = (outputs.detach().cpu(), batch_y.detach().cpu(), loss.item(), batch_idx)\n",
        "        return\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [Batch, Input length, Channel]\n",
        "        seq_last = x[:,-1:,:].detach()\n",
        "        x = x - seq_last\n",
        "        if self.individual:\n",
        "            output = torch.zeros([x.size(0),self.d_model,x.size(2)],dtype=x.dtype).to(x.device)\n",
        "            for i in range(self.channels):\n",
        "                output[:,:,i] = self.Linear[i](x[:,:,i])\n",
        "            x = output\n",
        "        else:\n",
        "            x = self.Linear(x.permute(0,2,1)).permute(0,2,1)\n",
        "        x = x + seq_last\n",
        "        return x # [Batch, Output length, Channel]"
      ],
      "metadata": {
        "id": "Emj8DIndHkhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand((16, 8, 201))\n",
        "model = NLinear(8, 320, 4)\n",
        "x = model(x)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gxE8HLUF_xn",
        "outputId": "27f0a8bf-9658-45d2-b19c-90b8bf1d4517"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 320, 201])"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## My Model 🔽"
      ],
      "metadata": {
        "id": "YP8y2ZUZP0ew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions"
      ],
      "metadata": {
        "id": "WD_TKtHHOdZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_learning_rate(optimizer, epoch, args):\n",
        "    # lr = args.learning_rate * (0.2 ** (epoch // 2))\n",
        "    if args.lradj == 'type1':\n",
        "        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
        "    elif args.lradj == 'type2':\n",
        "        lr_adjust = {\n",
        "            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
        "            10: 5e-7, 15: 1e-7, 20: 5e-8\n",
        "        }\n",
        "    elif args.lradj == '3':\n",
        "        lr_adjust = {epoch: args.learning_rate if epoch < 10 else args.learning_rate*0.1}\n",
        "    elif args.lradj == '4':\n",
        "        lr_adjust = {epoch: args.learning_rate if epoch < 15 else args.learning_rate*0.1}\n",
        "    elif args.lradj == '5':\n",
        "        lr_adjust = {epoch: args.learning_rate if epoch < 25 else args.learning_rate*0.1}\n",
        "    elif args.lradj == '6':\n",
        "        lr_adjust = {epoch: args.learning_rate if epoch < 5 else args.learning_rate*0.1}\n",
        "    if epoch in lr_adjust.keys():\n",
        "        lr = lr_adjust[epoch]\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "        # print('Updating learning rate to {}'.format(lr))"
      ],
      "metadata": {
        "id": "c5yyhXUrOc30"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DAIN-SLinear"
      ],
      "metadata": {
        "id": "fzh7fGRdl2dN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DAIN_Layer(nn.Module):\n",
        "    def __init__(self, mode='adaptive_avg', mean_lr=0.00001, gate_lr=0.001, scale_lr=0.00001, input_dim=336):\n",
        "        super(DAIN_Layer, self).__init__()\n",
        "\n",
        "        self.mode = mode\n",
        "        self.mean_lr = mean_lr\n",
        "        self.gate_lr = gate_lr\n",
        "        self.scale_lr = scale_lr\n",
        "\n",
        "        # Parameters for adaptive average\n",
        "        self.mean_layer = nn.Linear(input_dim, input_dim, bias=False)\n",
        "        self.mean_layer.weight.data = torch.FloatTensor(data=np.eye(input_dim, input_dim))\n",
        "\n",
        "        # Parameters for adaptive std\n",
        "        self.scaling_layer = nn.Linear(input_dim, input_dim, bias=False)\n",
        "        self.scaling_layer.weight.data = torch.FloatTensor(data=np.eye(input_dim, input_dim))\n",
        "\n",
        "        # Parameters for adaptive scaling\n",
        "        self.gating_layer = nn.Linear(input_dim, input_dim)\n",
        "\n",
        "        self.eps = 1e-8\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Expecting  (n_samples, dim,  n_feature_vectors)\n",
        "\n",
        "        # Nothing to normalize\n",
        "        if self.mode == None:\n",
        "            pass\n",
        "\n",
        "        # Do simple average normalization\n",
        "        elif self.mode == 'avg':\n",
        "            avg = torch.mean(x, 2)\n",
        "            avg = avg.resize(avg.size(0), avg.size(1), 1)\n",
        "            x = x - avg\n",
        "\n",
        "        # Perform only the first step (adaptive averaging)\n",
        "        elif self.mode == 'adaptive_avg':\n",
        "            avg = torch.mean(x, 2)\n",
        "            adaptive_avg = self.mean_layer(avg)\n",
        "            adaptive_avg = adaptive_avg.resize(adaptive_avg.size(0), adaptive_avg.size(1), 1)\n",
        "            x = x - adaptive_avg\n",
        "\n",
        "        # Perform the first + second step (adaptive averaging + adaptive scaling )\n",
        "        elif self.mode == 'adaptive_scale':\n",
        "\n",
        "            # Step 1:\n",
        "            avg = torch.mean(x, 2)\n",
        "            adaptive_avg = self.mean_layer(avg)\n",
        "            adaptive_avg = adaptive_avg.resize(adaptive_avg.size(0), adaptive_avg.size(1), 1)\n",
        "            x = x - adaptive_avg\n",
        "\n",
        "            # Step 2:\n",
        "            std = torch.mean(x ** 2, 2)\n",
        "            std = torch.sqrt(std + self.eps)\n",
        "            adaptive_std = self.scaling_layer(std)\n",
        "            adaptive_std[adaptive_std <= self.eps] = 1\n",
        "\n",
        "            adaptive_std = adaptive_std.resize(adaptive_std.size(0), adaptive_std.size(1), 1)\n",
        "            x = x / (adaptive_std)\n",
        "\n",
        "        elif self.mode == 'full':\n",
        "\n",
        "            # Step 1:\n",
        "            avg = torch.mean(x, 2)\n",
        "            adaptive_avg = self.mean_layer(avg)\n",
        "            adaptive_avg = adaptive_avg.resize(adaptive_avg.size(0), adaptive_avg.size(1), 1)\n",
        "            x = x - adaptive_avg\n",
        "\n",
        "            # # Step 2:\n",
        "            std = torch.mean(x ** 2, 2)\n",
        "            std = torch.sqrt(std + self.eps)\n",
        "            adaptive_std = self.scaling_layer(std)\n",
        "            adaptive_std[adaptive_std <= self.eps] = 1\n",
        "\n",
        "            adaptive_std = adaptive_std.resize(adaptive_std.size(0), adaptive_std.size(1), 1)\n",
        "            x = x / adaptive_std\n",
        "\n",
        "            # Step 3:\n",
        "            avg = torch.mean(x, 2)\n",
        "            gate = F.sigmoid(self.gating_layer(avg))\n",
        "            gate = gate.resize(gate.size(0), gate.size(1), 1)\n",
        "            x = x * gate\n",
        "\n",
        "        else:\n",
        "            assert False\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ehcTn-uSl6Ts"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SLinear"
      ],
      "metadata": {
        "id": "RX3ADmnN_M_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SLinear(pl.LightningModule):\n",
        "    def __init__(self, configs):\n",
        "        super(SLinear, self).__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.configs = configs\n",
        "        self.seq_len = configs.seq_len\n",
        "        self.pred_len = configs.pred_len\n",
        "        self.norm = configs.normalization\n",
        "        self.pred_batch_index = configs.pred_batch_index[0]\n",
        "\n",
        "\n",
        "        # Use this line if you want to visualize the weights\n",
        "        # self.NLinear.weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
        "        self.channels = configs.enc_in\n",
        "        self.individual = configs.individual\n",
        "\n",
        "        if self.norm == 'DAIN':\n",
        "            self.dain = DAIN_Layer()\n",
        "        if self.individual:\n",
        "            self.Linear = nn.ModuleList()\n",
        "            for i in range(self.channels):\n",
        "                self.Linear.append(nn.Linear(self.seq_len,self.pred_len))\n",
        "        else:\n",
        "            self.Linear = nn.Linear(self.seq_len, self.pred_len)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        model_optim = optim.Adam(self.parameters(), lr=self.configs.learning_rate)\n",
        "        return model_optim\n",
        "\n",
        "    def _get_loss(self):\n",
        "        criterion = nn.MSELoss()\n",
        "        return criterion\n",
        "\n",
        "    def on_train_epoch_start(self):\n",
        "        self.train_loss = []\n",
        "\n",
        "    def on_validation_epoch_start(self):\n",
        "        self.val_loss = []\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        train_loss = np.average(self.train_loss)\n",
        "        self.log(\"train_loss\", train_loss, prog_bar=True)\n",
        "        wandb.log({\"train\": {\"epoch\": self.current_epoch ,\"train_loss\": train_loss}})\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        val_loss = np.average(self.val_loss)\n",
        "        self.log(\"val_loss\", val_loss, prog_bar=True)\n",
        "        wandb.log({\"val\": {\"epoch\": self.current_epoch ,\"val_loss\": val_loss}})\n",
        "        model_optim = self.optimizers(use_pl_optimizer=False)\n",
        "        adjust_learning_rate(model_optim, self.current_epoch + 1, self.configs)\n",
        "\n",
        "    def on_test_start(self):\n",
        "        # Testing\n",
        "        self.preds = []\n",
        "        self.trues = []\n",
        "        self.inputx = []\n",
        "\n",
        "    def on_test_end(self):\n",
        "        self.preds = np.concatenate(self.preds, axis=0)\n",
        "        self.trues = np.concatenate(self.trues, axis=0)\n",
        "        self.mse, self.mae = metric(self.preds, self.trues)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        batch_x, batch_y, batch_x_mark, batch_y_mark = batch\n",
        "        batch_x = batch_x.float()\n",
        "        batch_y = batch_y.float()\n",
        "        batch_x_mark = batch_x_mark.float()\n",
        "        batch_y_mark = batch_y_mark.float()\n",
        "        outputs = self(batch_x)\n",
        "        f_dim = -1 if self.configs.features == 'MS' else 0\n",
        "        outputs = outputs[:, -self.pred_len:, f_dim:]\n",
        "        batch_y = batch_y[:, -self.pred_len:, f_dim:]\n",
        "        criterion = self._get_loss()\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        self.train_loss.append(loss.item())\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        batch_x, batch_y, batch_x_mark, batch_y_mark = batch\n",
        "        batch_x = batch_x.float()\n",
        "        batch_y = batch_y.float()\n",
        "        batch_x_mark = batch_x_mark.float()\n",
        "        batch_y_mark = batch_y_mark.float()\n",
        "        outputs = self(batch_x)\n",
        "        f_dim = -1 if self.configs.features == 'MS' else 0\n",
        "        outputs = outputs[:, -self.pred_len:, f_dim:]\n",
        "        batch_y = batch_y[:, -self.pred_len:, f_dim:]\n",
        "        criterion = self._get_loss()\n",
        "        pred = outputs.detach().cpu()\n",
        "        true = batch_y.detach().cpu()\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        self.val_loss.append(loss.item())\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        batch_x, batch_y, batch_x_mark, batch_y_mark = batch\n",
        "        batch_x = batch_x.float()\n",
        "        batch_y = batch_y.float()\n",
        "        batch_x_mark = batch_x_mark.float()\n",
        "        batch_y_mark = batch_y_mark.float()\n",
        "        outputs = self(batch_x)\n",
        "        f_dim = -1 if self.configs.features == 'MS' else 0\n",
        "        outputs = outputs[:, -self.pred_len:, f_dim:]\n",
        "        batch_y = batch_y[:, -self.pred_len:, f_dim:]\n",
        "        outputs = outputs.detach().cpu().numpy()\n",
        "        batch_y = batch_y.detach().cpu().numpy()\n",
        "\n",
        "        pred = outputs  # outputs.detach().cpu().numpy()  # .squeeze()\n",
        "        true = batch_y  # batch_y.detach().cpu().numpy()  # .squeeze()\n",
        "\n",
        "        self.preds.append(pred)\n",
        "        self.trues.append(true)\n",
        "        # self.inputx.append(batch_x.detach().numpy())\n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        batch_x, batch_y, batch_x_mark, batch_y_mark = batch\n",
        "        batch_x = batch_x.float()\n",
        "        batch_y = batch_y.float()\n",
        "        batch_x_mark = batch_x_mark.float()\n",
        "        batch_y_mark = batch_y_mark.float()\n",
        "        outputs = self(batch_x)\n",
        "        f_dim = -1 if self.configs.features == 'MS' else 0\n",
        "        outputs = outputs[:, -self.pred_len:, f_dim:]\n",
        "        batch_y = batch_y[:, -self.pred_len:, f_dim:]\n",
        "        criterion = self._get_loss()\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        if self.pred_batch_index > -1 and batch_idx > self.pred_batch_index:\n",
        "            return\n",
        "        if batch_idx == 0 or (self.pred_batch_index > -1 and batch_idx == self.pred_batch_index):\n",
        "            self.best_prediction = (outputs.detach().cpu(), batch_y.detach().cpu(), loss.item(), batch_idx)\n",
        "            return\n",
        "        if loss < self.best_prediction[2]:\n",
        "            self.best_prediction = (outputs.detach().cpu(), batch_y.detach().cpu(), loss.item(), batch_idx)\n",
        "        return\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [Batch, Input length, Channel]\n",
        "        # Normalization\n",
        "        # ipdb.set_trace(context=6)\n",
        "        if self.norm == 'z-score':\n",
        "            mean_x = x.mean(1, keepdim=True).detach() # B x 1 x E\n",
        "            x = x - mean_x\n",
        "            std_x = torch.sqrt(torch.var(x, dim=1, keepdim=True, unbiased=False) + 1e-5).detach() # B x 1 x E\n",
        "            x = x / std_x\n",
        "        else:\n",
        "            x = self.dain(x)\n",
        "\n",
        "        if self.individual:\n",
        "            output = torch.zeros([x.size(0),self.pred_len,x.size(2)],dtype=x.dtype).to(x.device)\n",
        "            for i in range(self.channels):\n",
        "                output[:,:,i] = self.Linear[i](x[:,:,i])\n",
        "            x = output\n",
        "        else:\n",
        "            x = self.Linear(x.permute(0,2,1)).permute(0,2,1)\n",
        "        if self.norm == 'z-score':\n",
        "            # De-normalization\n",
        "            x = x * std_x + mean_x\n",
        "        return x # [Batch, Output length, Channel]"
      ],
      "metadata": {
        "id": "0zXBfuqt_PDq"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "DYNOokNm3LCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train function\n",
        "def train(batch_size, datamodule, model, model_name, max_epochs = None, max_steps = -1,\n",
        "          check_val_every_n_epoch = 1, resume_training = True, load_model = False,\n",
        "          enable_checkpoint = True, monitor_metric = \"val_loss\", checkpoint_dir = None,\n",
        "          early_stopping = True, deterministic = False, configs = None):\n",
        "\n",
        "    # check monitor metric\n",
        "    assert monitor_metric in [\"train_loss\", \"val_loss\"], \"metric to monitor is invalid\"\n",
        "\n",
        "    # initialize callbacks array\n",
        "    callbacks = [TQDMProgressBar(refresh_rate=20)]\n",
        "\n",
        "    # add checkpoints to callbacks\n",
        "    checkpoint_callback = None\n",
        "    if enable_checkpoint and checkpoint_dir is not None:\n",
        "        checkpoint_callback = ModelCheckpoint(dirpath=checkpoint_dir,  monitor = monitor_metric, filename=model_name + '{epoch:02d}-{' + monitor_metric + ':.2f}',\n",
        "                                         save_last =True, save_on_train_epoch_end = True)\n",
        "        callbacks.append(checkpoint_callback)\n",
        "\n",
        "    # add early stopping to the callbacks\n",
        "    if early_stopping:\n",
        "        callbacks.append(EarlyStopping(monitor=\"val_loss\", patience = configs.patience, mode=\"min\", check_on_train_epoch_end = False))\n",
        "\n",
        "    # create the Trainer\n",
        "    trainer = pl.Trainer(enable_checkpointing=enable_checkpoint, devices=1, accelerator=\"auto\",\n",
        "                         max_epochs=max_epochs, max_steps=max_steps, callbacks=callbacks,\n",
        "                         check_val_every_n_epoch = check_val_every_n_epoch,\n",
        "                         deterministic = deterministic)\n",
        "\n",
        "    ckpt_path = None\n",
        "    if resume_training:\n",
        "        ckpt_path = checkpoint_dir + \"/last.ckpt\"\n",
        "    trainer.fit(ckpt_path = ckpt_path, model=model, datamodule=datamodule)\n",
        "    if checkpoint_callback is not None:\n",
        "        log.info(checkpoint_callback.best_model_path)\n",
        "\n",
        "    return trainer"
      ],
      "metadata": {
        "id": "q-936er_-snn"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "Oqxoxjh9C0rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seeds = [1]\n",
        "global_mse = []\n",
        "global_mae = []\n",
        "\n",
        "pred_lens = datasets_pred_lens[DATASET]\n",
        "for seed in seeds:\n",
        "    mse = []\n",
        "    mae = []\n",
        "    for i, pred_len in enumerate(pred_lens):\n",
        "        pred_len_folder = f\"/{pred_len}\"\n",
        "        if UNIVARIATE:\n",
        "            args = parser.parse_args([\"--is_training=1\",\n",
        "                                    \"--root_path=./dataset\", f\"--data_path={datasets_name[DATASET]}\",\n",
        "                                    f\"--model_id={MODEL_ID}\", f\"--model={MODEL}\",\n",
        "                                    f\"--data={DATASET}\", f\"--seq_len={SEQ_LEN}\",\n",
        "                                    f\"--seed={seed}\", f\"--pred_len={pred_len}\",\n",
        "                                    \"--enc_in=1\",\n",
        "                                    \"--individual\", f\"--batch_size={BATCH_SIZE}\",\n",
        "                                    \"--feature=S\", f\"--learning_rate={LR}\", f\"--normalization={NORMALIZATION}\",\n",
        "                                      f\"--pred_batch_index={BEST_BATCH_IDX[i]}\"])\n",
        "        else:\n",
        "            args = parser.parse_args([\"--is_training=1\",\n",
        "                                    \"--root_path=./dataset\", f\"--data_path={datasets_name[DATASET]}\",\n",
        "                                    f\"--model_id={MODEL_ID}\", f\"--model={MODEL}\",\n",
        "                                    f\"--data={DATASET}\", f\"--seq_len={SEQ_LEN}\",\n",
        "                                    f\"--seed={seed}\", f\"--pred_len={pred_len}\",\n",
        "                                    f\"--enc_in={enc_in[DATASET]}\",\n",
        "                                    \"--individual\", f\"--batch_size={BATCH_SIZE}\",\n",
        "                                    \"--feature=M\", f\"--learning_rate={LR}\", f\"--normalization={NORMALIZATION}\",\n",
        "                                      f\"--pred_batch_index={BEST_BATCH_IDX[i]}\"])\n",
        "        # initialize dataset\n",
        "        # datamodule = ElectricityDataModule(datasets_path[ELECTRICITY] + datasets_processed_name[ELECTRICITY], BATCH_SIZE, L)\n",
        "        datamodule = CustomDataModule(args)\n",
        "\n",
        "        # set seed if deterministic\n",
        "        if DETERMINISTIC:\n",
        "            seed_everything(seed)\n",
        "        # initialize model, or load an extisting one\n",
        "        if LOAD_MODEL:\n",
        "            log.info(\"loading model...\")\n",
        "            model = eval(MODEL).load_from_checkpoint(CHECKPOINT_FOLDER+pred_len_folder+\"/last.ckpt\")\n",
        "        else:\n",
        "            log.info(\"initializing model...\")\n",
        "            model = eval(MODEL)(args)\n",
        "\n",
        "        setting = '{}_{}_{}_{}_{}'.format(\n",
        "                args.model_id,\n",
        "                args.model,\n",
        "                args.data,\n",
        "                args.pred_len,\n",
        "                args.seed)\n",
        "\n",
        "        log.info(setting)\n",
        "\n",
        "        if TRAIN:\n",
        "            trainer = train(args.batch_size, datamodule, model, MODEL,\n",
        "                            max_epochs = args.train_epochs, check_val_every_n_epoch = 1,\n",
        "                            load_model = LOAD_MODEL,\n",
        "                            resume_training = RESUME_TRAINING,  monitor_metric = \"val_loss\",\n",
        "                            checkpoint_dir = CHECKPOINT_FOLDER+pred_len_folder,\n",
        "                            early_stopping = True, deterministic = DETERMINISTIC, configs = args)\n",
        "        if TEST:\n",
        "            trainer.test(model, datamodule=datamodule)\n",
        "\n",
        "            mse.append(model.mse)\n",
        "            mae.append(model.mae)\n",
        "            log.info(f\"result for pred_len: {pred_len} \\n mse: {model.mse}, mae: {model.mae}\")\n",
        "\n",
        "    if TEST:\n",
        "        global_mse.append(mse)\n",
        "        global_mae.append(mae)"
      ],
      "metadata": {
        "id": "AvftO5iOK9ZR",
        "outputId": "e83aa5df-1e4f-415b-cf73-10f75d46ba56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 1\n",
            "INFO:APP:loading model...\n",
            "INFO:APP:SLinear_ETTh1_univariate_Linear_ETTh1_24_1\n",
            "INFO:lightning_fabric.utilities.seed:Global seed set to 1\n",
            "INFO:APP:loading model...\n",
            "INFO:APP:SLinear_ETTh1_univariate_Linear_ETTh1_48_1\n",
            "INFO:lightning_fabric.utilities.seed:Global seed set to 1\n",
            "INFO:APP:loading model...\n",
            "INFO:APP:SLinear_ETTh1_univariate_Linear_ETTh1_168_1\n",
            "INFO:lightning_fabric.utilities.seed:Global seed set to 1\n",
            "INFO:APP:loading model...\n",
            "INFO:APP:SLinear_ETTh1_univariate_Linear_ETTh1_336_1\n",
            "INFO:lightning_fabric.utilities.seed:Global seed set to 1\n",
            "INFO:APP:loading model...\n",
            "INFO:APP:SLinear_ETTh1_univariate_Linear_ETTh1_720_1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if TEST:\n",
        "    global_mse = np.array(global_mse).transpose()\n",
        "    global_mae = np.array(global_mae).transpose()\n",
        "    mse = einops.reduce(global_mse, 'i j -> i', 'mean')\n",
        "    mae = einops.reduce(global_mae, 'i j -> i', 'mean')\n",
        "    data = [[x, y] for (x, y) in zip(pred_lens, mse)]\n",
        "    table = wandb.Table(data=data, columns = [\"pred_lens\", \"mse\"])\n",
        "    wandb.log(\n",
        "    {f\"Forecasting MSE plot\" : wandb.plot.scatter(table, \"pred_lens\", \"mse\",\n",
        "        title=f\"Forecasting MSE norm plot\")})\n",
        "\n",
        "    data = [[x, y] for (x, y) in zip(pred_lens, mae)]\n",
        "    table = wandb.Table(data=data, columns = [\"pred_lens\", \"mae\"])\n",
        "    wandb.log(\n",
        "    {f\"Forecasting MAE plot\" : wandb.plot.scatter(table, \"pred_lens\", \"mae\",\n",
        "        title=f\"Forecasting MAE norm plot\")})"
      ],
      "metadata": {
        "id": "NXZsEiDVmyrB"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "8Twh-Wiq0CqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if PREDICT:\n",
        "    global_predictions = []\n",
        "    global_true_values = []\n",
        "    best_batch_idx = []\n",
        "    for i, pred_len in enumerate(pred_lens):\n",
        "        pred_len_folder = f\"/{pred_len}\"\n",
        "        if UNIVARIATE:\n",
        "                args = parser.parse_args([\"--is_training=1\",\n",
        "                                        \"--root_path=./dataset\", f\"--data_path={datasets_name[DATASET]}\",\n",
        "                                        f\"--model_id={MODEL_ID}\", f\"--model={MODEL}\",\n",
        "                                        f\"--data={DATASET}\", f\"--seq_len={SEQ_LEN}\",\n",
        "                                        f\"--seed={seed}\", f\"--pred_len={pred_len}\",\n",
        "                                        \"--enc_in=1\",\n",
        "                                        \"--individual\", f\"--batch_size={BATCH_SIZE}\",\n",
        "                                        \"--feature=S\", f\"--learning_rate={LR}\", f\"--normalization={NORMALIZATION}\",\n",
        "                                          f\"--pred_batch_index={BEST_BATCH_IDX[i]}\"])\n",
        "        else:\n",
        "            args = parser.parse_args([\"--is_training=1\",\n",
        "                                    \"--root_path=./dataset\", f\"--data_path={datasets_name[DATASET]}\",\n",
        "                                    f\"--model_id={MODEL_ID}\", f\"--model={MODEL}\",\n",
        "                                    f\"--data={DATASET}\", f\"--seq_len={SEQ_LEN}\",\n",
        "                                    f\"--seed={seed}\", f\"--pred_len={pred_len}\",\n",
        "                                    f\"--enc_in={enc_in[DATASET]}\",\n",
        "                                    \"--individual\", f\"--batch_size={BATCH_SIZE}\",\n",
        "                                    \"--feature=M\", f\"--learning_rate={LR}\", f\"--normalization={NORMALIZATION}\",\n",
        "                                      f\"--pred_batch_index={BEST_BATCH_IDX[i]}\"])\n",
        "        # initialize dataset\n",
        "        datamodule = CustomDataModule(args)\n",
        "        log.info(\"loading model...\")\n",
        "        model = eval(MODEL).load_from_checkpoint(CHECKPOINT_FOLDER+pred_len_folder+\"/last.ckpt\")\n",
        "        trainer = pl.Trainer()\n",
        "        trainer.predict(model, datamodule)\n",
        "        predictions = einops.rearrange(model.best_prediction[0].numpy(), '1 h c -> h c')\n",
        "        true_values = einops.rearrange(model.best_prediction[1].numpy(), '1 h c -> h c')\n",
        "        best_batch_idx.append(model.best_prediction[3])\n",
        "        global_predictions.append(predictions)\n",
        "        global_true_values.append(true_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c501934c63d9462c972f78feb8dd2a9a",
            "5dc6b82929ce400db0331514d58b3faa",
            "19887a44fcaf4045ad2dc38ce4b0699d",
            "56d1995cabf04e2e850c05bbf5165f63",
            "9e3948f2487c492d97fae67cc67ae45e",
            "a370524abefb412abb0e0b3faf926eda",
            "38ae1136f9914256a72a3a4f759f8bf3",
            "ca54361675a045638fbd23fdc18910a2",
            "b823a084bfc54652a89cfb829c6cd715",
            "fe9b7d7057614f55becb7c1b971ab11b",
            "72042f6936134b07ae08dd884c134877",
            "d5528c1f2c664382b88baaf77397bebf",
            "c64379c5e04a4124b523f37c3460fff7",
            "607783d4e2444487a2415706d870de1e",
            "5b97d886decf48a4964aad020e17d6fd",
            "b8db8b41e51d43a4b0d8c260a7d7b9d9",
            "71a096ae8c6a4698a7ac4f9397b1971d",
            "5793a6b1c99c4efc82e3a3e28f57c18b",
            "3bfd0cae9dd84337a0a3c568caeb2eb9",
            "d39f66e593094b469d4c00949ca3197f",
            "d2f9db72d3dd40baad08d33c3c662838",
            "1ebebb00058c49e39ac96b2912fa2569",
            "92e98d9703214e94adda91a706f2cc9a",
            "5b2f72b2072f4417b561bfc6ab38332f",
            "b94abaa578e64e8d9fbb096ea12017a9",
            "9be9daa0cfde4fc59271e708046c0b16",
            "26a946135d3f4f358e49622ff225ba52",
            "f8326c40aa31477597401ac98680361e",
            "33051e01180d43689129ee09c88f0efa",
            "ba1070f2ca0145e492ef4f81300c151b",
            "a806b6cbce80454f9b9f4c724c0a9ba9",
            "22b577297b7a43bfb493e5ea1f2b9e90",
            "8cd3636d30514b538b375778310d7236",
            "790b035423164684bb48e3a56e81a59e",
            "4a56bdae769949b9b556bc503dc0a61f",
            "c85ad95f8ba14dc19e54b39a0dcfc2a9",
            "2f8df22038974ef5ae817b087899fe57",
            "29ea323550ac4ef783c1a9be0144b35e",
            "61b974291f974afeaa3e494c213645a7",
            "eb296f9daf764c78961ef5ab3253b639",
            "1f754e48dcfd4b1eb07b5a500167d699",
            "15de2a3bdebb4d998a0721f366b33b77",
            "65644f835f8c4d5b81cfec680f9a54fd",
            "e2d0e031ddf244ac8428f7fee507854f",
            "6457d829262d4fc0ae4d2d039d26d759",
            "e3e529219ba5487ead3ac755be77d4ee",
            "831ee33c61cb4f2d9667fd25a1e7d412",
            "cbc0178b215f4ff2a23ec6035d06106c",
            "7ffa323061094a589bd6be52b1e71a74",
            "ea5b6fd591384b90baded0881f81a327",
            "40e35c4807fa48528961060702b35cae",
            "6de860666be545788ce14e24eae1ba6a",
            "e162ee0348d44c2fa83e3d74041636d7",
            "bd21f44e6cbf4763bea96d4562f0deb9",
            "a93c2dc570be40fdb40fe10cc5ff89dd"
          ]
        },
        "id": "_juySB8q0CAQ",
        "outputId": "99142a75-761b-4025-ef17-5c17cfbf9d2f"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:APP:loading model...\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predicting: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c501934c63d9462c972f78feb8dd2a9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/prediction_loop.py:233: UserWarning: predict returned None if it was on purpose, ignore this warning...\n",
            "  self._warning_cache.warn(\"predict returned None if it was on purpose, ignore this warning...\")\n",
            "INFO:APP:loading model...\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predicting: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5528c1f2c664382b88baaf77397bebf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/prediction_loop.py:233: UserWarning: predict returned None if it was on purpose, ignore this warning...\n",
            "  self._warning_cache.warn(\"predict returned None if it was on purpose, ignore this warning...\")\n",
            "INFO:APP:loading model...\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predicting: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92e98d9703214e94adda91a706f2cc9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/prediction_loop.py:233: UserWarning: predict returned None if it was on purpose, ignore this warning...\n",
            "  self._warning_cache.warn(\"predict returned None if it was on purpose, ignore this warning...\")\n",
            "INFO:APP:loading model...\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predicting: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "790b035423164684bb48e3a56e81a59e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/prediction_loop.py:233: UserWarning: predict returned None if it was on purpose, ignore this warning...\n",
            "  self._warning_cache.warn(\"predict returned None if it was on purpose, ignore this warning...\")\n",
            "INFO:APP:loading model...\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predicting: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6457d829262d4fc0ae4d2d039d26d759"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/prediction_loop.py:233: UserWarning: predict returned None if it was on purpose, ignore this warning...\n",
            "  self._warning_cache.warn(\"predict returned None if it was on purpose, ignore this warning...\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if PREDICT:\n",
        "    log.info(f\"best_batch_idx: {best_batch_idx}\")\n",
        "    for i,pred_len in enumerate(pred_lens):\n",
        "        log.info(f\"current pred_len: {pred_len}\")\n",
        "        plt.figure(figsize=(12,6))\n",
        "        plt.plot(global_predictions[i], label = MODEL)\n",
        "        plt.plot(global_true_values[i], label = \"ground truth\")\n",
        "        plt.xlabel(\"steps\")\n",
        "        plt.ylabel(\"TS value\")\n",
        "        plt.title(f\"LSTF univariate output for {DATASET} with {pred_len} forecasting horizon\")\n",
        "        plt.legend()\n",
        "        plt.savefig(f\"/content/drive/MyDrive/Tesi/thesis/plots/{MODEL}/plot_{MODEL}_{pred_len}.png\")\n",
        "        # plt.show()\n",
        "        plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQkLkCSe8ATl",
        "outputId": "ecc3463f-837a-41d5-f8e8-322299525a12"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:APP:best_batch_idx: [2373, 901, 1223, 657, 681]\n",
            "INFO:APP:current pred_len: 24\n",
            "INFO:APP:current pred_len: 48\n",
            "INFO:APP:current pred_len: 168\n",
            "INFO:APP:current pred_len: 336\n",
            "INFO:APP:current pred_len: 720\n"
          ]
        }
      ]
    }
  ]
}