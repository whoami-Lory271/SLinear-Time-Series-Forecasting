{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6a0110a19563467494a691d863c25ec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b64d3f98834e4b5288398bb7559e339c",
              "IPY_MODEL_72cb724770d840d0b218caaaa039caab",
              "IPY_MODEL_738f0611ddb1488c82a2067d8fdee7a6"
            ],
            "layout": "IPY_MODEL_6177a21835a443e1aacfece99c6d8439"
          }
        },
        "b64d3f98834e4b5288398bb7559e339c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae3243b9ded94e5cb32cba7a62315346",
            "placeholder": "​",
            "style": "IPY_MODEL_d75c5323b2814ff78c7629813785c71c",
            "value": "Predicting DataLoader 0: 100%"
          }
        },
        "72cb724770d840d0b218caaaa039caab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33ec655026d04f7c8b0993889aa55281",
            "max": 2857,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9343d9594d28482f9199fb40b62e7e23",
            "value": 2857
          }
        },
        "738f0611ddb1488c82a2067d8fdee7a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c34cfc88729e40eb9c2de34ceefdb0a4",
            "placeholder": "​",
            "style": "IPY_MODEL_902764d4ec3a46839a8a6004da51c93d",
            "value": " 2857/2857 [00:12&lt;00:00, 226.33it/s]"
          }
        },
        "6177a21835a443e1aacfece99c6d8439": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "ae3243b9ded94e5cb32cba7a62315346": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d75c5323b2814ff78c7629813785c71c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33ec655026d04f7c8b0993889aa55281": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9343d9594d28482f9199fb40b62e7e23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c34cfc88729e40eb9c2de34ceefdb0a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "902764d4ec3a46839a8a6004da51c93d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "280d0fee924144cf9dc7161c81411f3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33907b4ae4674824b5cbfba707567b51",
              "IPY_MODEL_4e1316eb305f44a7bdb25c02f710669b",
              "IPY_MODEL_61708b025e00463c9ec928358c707d62"
            ],
            "layout": "IPY_MODEL_e0947e2c81e34457a1c8a1dc7f7d719c"
          }
        },
        "33907b4ae4674824b5cbfba707567b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c870adfeb61540608bd22be13d02ca31",
            "placeholder": "​",
            "style": "IPY_MODEL_154a17ecc0ca4b53be7806be4eacb3ca",
            "value": "Predicting DataLoader 0: 100%"
          }
        },
        "4e1316eb305f44a7bdb25c02f710669b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f3b12107b0f478c81d73518db782e7b",
            "max": 2833,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a5da96a64a34d43870d9bda931bae3f",
            "value": 2833
          }
        },
        "61708b025e00463c9ec928358c707d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd29b6786a94440a9f7f465289de8685",
            "placeholder": "​",
            "style": "IPY_MODEL_9e0ad1aff9cf46808431f80e61b44dbb",
            "value": " 2833/2833 [00:13&lt;00:00, 215.11it/s]"
          }
        },
        "e0947e2c81e34457a1c8a1dc7f7d719c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "c870adfeb61540608bd22be13d02ca31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "154a17ecc0ca4b53be7806be4eacb3ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f3b12107b0f478c81d73518db782e7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a5da96a64a34d43870d9bda931bae3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd29b6786a94440a9f7f465289de8685": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e0ad1aff9cf46808431f80e61b44dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0348a3072418482bb496ecd69a63aa91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19346f6d8bb24c0896607689b6df3c67",
              "IPY_MODEL_5a60ca9a30464e968d90b75875ea39d5",
              "IPY_MODEL_697dc735ce944682bfe7603bef1e0646"
            ],
            "layout": "IPY_MODEL_a688005a991b4e59b9911002b83839a6"
          }
        },
        "19346f6d8bb24c0896607689b6df3c67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4b3c7f87a3448269dbfeb381f4f2c58",
            "placeholder": "​",
            "style": "IPY_MODEL_4298041f3ff8409aa59641ab6d90f34e",
            "value": "Predicting DataLoader 0: 100%"
          }
        },
        "5a60ca9a30464e968d90b75875ea39d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f234c9568ed496581010e04f26a0f75",
            "max": 2713,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08b8d778fe754af79e4e7d1092373407",
            "value": 2713
          }
        },
        "697dc735ce944682bfe7603bef1e0646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8641aa882b8f4238ad5a7de0829eda50",
            "placeholder": "​",
            "style": "IPY_MODEL_f37af9819fa0452e9b572157d4bd736b",
            "value": " 2713/2713 [00:12&lt;00:00, 218.91it/s]"
          }
        },
        "a688005a991b4e59b9911002b83839a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "c4b3c7f87a3448269dbfeb381f4f2c58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4298041f3ff8409aa59641ab6d90f34e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f234c9568ed496581010e04f26a0f75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08b8d778fe754af79e4e7d1092373407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8641aa882b8f4238ad5a7de0829eda50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f37af9819fa0452e9b572157d4bd736b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bc82d160eb14eff8384e8aefc9d13ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ae8e7bf297544b282b2a1b6a32a5d36",
              "IPY_MODEL_2fba0e249aff48d7a1e777ea6d644644",
              "IPY_MODEL_52f26065157348509bb7fcbe0a6d04a3"
            ],
            "layout": "IPY_MODEL_993fa9301c3a4cbc81e1ae25f4fd7a7f"
          }
        },
        "1ae8e7bf297544b282b2a1b6a32a5d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ddbccbdc0394ed29c948f938b7889c3",
            "placeholder": "​",
            "style": "IPY_MODEL_7cc478b6aaaf4f53adf4ff4493877798",
            "value": "Predicting DataLoader 0: 100%"
          }
        },
        "2fba0e249aff48d7a1e777ea6d644644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf9d0b8c75864a86b6cdaa2275667821",
            "max": 2545,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b72f690759a4d7d9f2426f75719e88a",
            "value": 2545
          }
        },
        "52f26065157348509bb7fcbe0a6d04a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5c8b3d0d83046c0ab7f9d232c1ecd93",
            "placeholder": "​",
            "style": "IPY_MODEL_b72b34e46664456db0284cdc1b61c9e2",
            "value": " 2545/2545 [00:12&lt;00:00, 210.11it/s]"
          }
        },
        "993fa9301c3a4cbc81e1ae25f4fd7a7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "4ddbccbdc0394ed29c948f938b7889c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cc478b6aaaf4f53adf4ff4493877798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf9d0b8c75864a86b6cdaa2275667821": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b72f690759a4d7d9f2426f75719e88a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5c8b3d0d83046c0ab7f9d232c1ecd93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b72b34e46664456db0284cdc1b61c9e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab7c9b23b7b346c28156660dc130bd09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9b96ffdf97d4dba9dd12a6412d335e0",
              "IPY_MODEL_5894667bb83a42a0b3aa78ecee2cb035",
              "IPY_MODEL_da601b064c0048d3b49fa3c622bf50e3"
            ],
            "layout": "IPY_MODEL_f578709f48394306a7505a39897cbf19"
          }
        },
        "e9b96ffdf97d4dba9dd12a6412d335e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1877d236be34c93afeb292bdff21474",
            "placeholder": "​",
            "style": "IPY_MODEL_85423f776a64433489dfce1174aada20",
            "value": "Predicting DataLoader 0: 100%"
          }
        },
        "5894667bb83a42a0b3aa78ecee2cb035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_215f8e1f07ea442e934af36a5f296d7b",
            "max": 2161,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a9d048fa7ec4a509086873393630c8a",
            "value": 2161
          }
        },
        "da601b064c0048d3b49fa3c622bf50e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3e51f4ad8514db6ade418e0ee038d7d",
            "placeholder": "​",
            "style": "IPY_MODEL_55dd0d2ce80d4bca95da6f581da18915",
            "value": " 2161/2161 [00:11&lt;00:00, 193.80it/s]"
          }
        },
        "f578709f48394306a7505a39897cbf19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "d1877d236be34c93afeb292bdff21474": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85423f776a64433489dfce1174aada20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "215f8e1f07ea442e934af36a5f296d7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a9d048fa7ec4a509086873393630c8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3e51f4ad8514db6ade418e0ee038d7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55dd0d2ce80d4bca95da6f581da18915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whoami-Lory271/thesis-project/blob/main/LSTM_Linear_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Symbol legend\n",
        "\n",
        "* B: batch size\n",
        "* L: lookback window (aka input_size)\n"
      ],
      "metadata": {
        "id": "7s9odzFFQWyj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations and imports\n"
      ],
      "metadata": {
        "id": "w7opc0NsjlNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning==2.0.1.post0 --quiet\n",
        "!pip install einops==0.6.1 --quiet\n",
        "!pip install ipdb --quiet\n",
        "!pip install wandb --quiet\n",
        "# !pip install objsize --quiet"
      ],
      "metadata": {
        "id": "ehQC2AKyci-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f172006b-833c-4318-b33b-42615194b8ee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.6/718.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m742.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pandas.tseries import offsets\n",
        "from pandas.tseries.frequencies import to_offset\n",
        "from typing import List\n",
        "import logging\n",
        "# https://github.com/gotcha/ipdb\n",
        "import ipdb\n",
        "import copy\n",
        "from google.colab import drive\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import functools\n",
        "# https://theaisummer.com/einsum-attention/\n",
        "import einops\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Ridge\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "from pytorch_lightning.profilers import PyTorchProfiler\n",
        "from pytorch_lightning.tuner import Tuner\n",
        "\n",
        "import wandb\n",
        "import sys\n",
        "import pickle\n",
        "import time\n",
        "import os\n",
        "import torch.fft as fft\n",
        "import argparse\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n"
      ],
      "metadata": {
        "id": "WuaX4Ts_jqmd"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "!cp /content/drive/MyDrive/Tesi/code/.netrc /root/\n",
        "wandb.login()\n",
        "# 024a3906e525e6d2640af94c364128bb3d33e44b"
      ],
      "metadata": {
        "id": "4F86VEC4VtL8",
        "outputId": "0aa260d2-9c47-41dd-d3d4-b3f33d9dade7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdesantis-1849114\u001b[0m (\u001b[33mdesantis\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/dataset\n",
        "!cp \"/content/drive/MyDrive/Tesi/code/datasets/NLinear/ETTh1.csv\" \"/content/dataset/\"\n",
        "\n",
        "!cp \"/content/drive/MyDrive/Tesi/code/datasets/NLinear/ETTh2.csv\" \"/content/dataset/\"\n",
        "\n",
        "!cp \"/content/drive/MyDrive/Tesi/code/datasets/NLinear/ETTm1.csv\" \"/content/dataset/\"\n",
        "\n",
        "!cp \"/content/drive/MyDrive/Tesi/code/datasets/NLinear/ETTm2.csv\" \"/content/dataset/\"\n",
        "\n",
        "!cp \"/content/drive/MyDrive/Tesi/code/datasets/NLinear/electricity.csv\" \"/content/dataset/\""
      ],
      "metadata": {
        "id": "YKC7BhtXbkD9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions"
      ],
      "metadata": {
        "id": "J2UVU6VqgizJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup logger function\n",
        "def setup_log(self, level):\n",
        "    log = logging.getLogger(self.__class__.__name__)\n",
        "    log.setLevel(level)\n",
        "    return log"
      ],
      "metadata": {
        "id": "gkBTe3nko46m"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write log on a file\n",
        "def write_log(a):\n",
        "    with open(\"log.txt\", 'w') as file:\n",
        "        for row in a:\n",
        "            file.write(str(row))\n",
        "        log.debug(\"object logged\")"
      ],
      "metadata": {
        "id": "i8LE_3TogiZn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random seed functions\n",
        "def seed_everything(seed):\n",
        "    pl.seed_everything(seed, workers=True)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "mzBQAeoIi8l2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pickle helper\n",
        "def pkl_save(name, var):\n",
        "    os.makedirs(os.path.dirname(name), exist_ok=True)\n",
        "    with open(name, 'wb') as f:\n",
        "        pickle.dump(var, f)\n",
        "\n",
        "def pkl_load(name):\n",
        "    with open(name, 'rb') as f:\n",
        "        return pickle.load(f)"
      ],
      "metadata": {
        "id": "NxBH76S1gdKm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MAE(pred, true):\n",
        "    return np.mean(np.abs(pred - true))\n",
        "\n",
        "\n",
        "def MSE(pred, true):\n",
        "    return np.mean((pred - true) ** 2)\n",
        "\n",
        "\n",
        "def metric(pred, true):\n",
        "    mse = MSE(pred, true)\n",
        "    mae = MAE(pred, true)\n",
        "\n",
        "    return mse, mae"
      ],
      "metadata": {
        "id": "2YdeAger1_7N"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constants"
      ],
      "metadata": {
        "id": "94xSbfaKkOmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# logger\n",
        "LOG_LEVEL = logging.DEBUG\n",
        "\n",
        "# datasets name\n",
        "ELECTRICITY = \"electricity\"\n",
        "M5 = \"M5\"\n",
        "ETTh1 = \"ETTh1\"\n",
        "ETTh2 = \"ETTh2\"\n",
        "ETTm1 = \"ETTm1\"\n",
        "ETTm2 = \"ETTm2\"\n",
        "WEATHER = \"WTH\"\n",
        "\n",
        "# models\n",
        "SLinear = \"SLinear\"\n",
        "MODEL = SLinear\n",
        "DATASET = ETTh1\n",
        "\n",
        "# device\n",
        "\n",
        "DEVICE = torch.device('cpu') if not torch.cuda.is_available() else torch.device('cuda')\n",
        "\n",
        "# hyperparameters\n",
        "\n",
        "NORMALIZATION = 'z-score' # z-score || DAIN\n",
        "\n",
        "# Train\n",
        "EPOCHS = 10\n",
        "UNIVARIATE = True\n",
        "SEQ_LEN = 336\n",
        "lr_datasets = {\n",
        "    ETTh1: 0.005,\n",
        "    ETTh2: 0.05,\n",
        "    ETTm1: 0.0001,\n",
        "    ETTm2: 0.001,\n",
        "    ELECTRICITY: 0.001\n",
        "}\n",
        "\n",
        "batch_size_datasets = {\n",
        "    ETTh1: 32,\n",
        "    ETTh2: 32,\n",
        "    ETTm1: 8,\n",
        "    ETTm2: 8,\n",
        "    ELECTRICITY: 16\n",
        "}\n",
        "\n",
        "LR = 0.005 if UNIVARIATE else lr_datasets[DATASET]\n",
        "BATCH_SIZE = 32 if UNIVARIATE else batch_size_datasets[DATASET]\n",
        "\n",
        "# Eval\n",
        "EVALUATE = True\n",
        "\n",
        "\n",
        "# training\n",
        "TRAIN = False\n",
        "TEST = False\n",
        "PREDICT = True\n",
        "DETERMINISTIC = True\n",
        "LOAD_MODEL = True\n",
        "RESUME_TRAINING = False\n",
        "MEMORY_PROFILING = False\n",
        "LOAD_ENCODE = False\n",
        "\n",
        "# wandb\n",
        "\n",
        "SETTINGS_STRING = \"univariate\" if UNIVARIATE else \"multivariate\"\n",
        "RUN_ID = \"tbxw0sr3\"\n",
        "RESUME_RUN = True\n",
        "RUN_ID = wandb.util.generate_id() if not RESUME_RUN else RUN_ID\n",
        "if NORMALIZATION == 'DAIN':\n",
        "    MODEL_ID = MODEL+'_'+NORMALIZATION+'_'+DATASET+'_'+SETTINGS_STRING\n",
        "else:\n",
        "    MODEL_ID = MODEL+'_'+DATASET+'_'+SETTINGS_STRING\n",
        "print(f\"current RUN_ID is {RUN_ID}\")\n",
        "\n",
        "\n",
        "#paths\n",
        "MODEL_SETTINGS_FOLDER = \"/univariate\" if UNIVARIATE else \"/multivariate\"\n",
        "ROOT_FOLDER = \"/content/drive/MyDrive/Tesi/code\"\n",
        "MODEL_FOLDER = ROOT_FOLDER + \"/models\"\n",
        "CHECKPOINT_FOLDER = ROOT_FOLDER + \"/checkpoints\" + \"/\" + MODEL + \"/\" + DATASET + MODEL_SETTINGS_FOLDER\n",
        "# LOGS_FOLDER = ROOT_FOLDER + \"/logs\"\n",
        "ENCODING_FOLDER = ROOT_FOLDER + \"/encoding/\" + MODEL + \"/\" + DATASET + MODEL_SETTINGS_FOLDER\n",
        "FORECASTING_RESULT = ROOT_FOLDER + \"/forecasting_result/\" + MODEL + \"/\" + DATASET + MODEL_SETTINGS_FOLDER\n",
        "\n",
        "datasets_name = {\n",
        "    ELECTRICITY: \"electricity.csv\",\n",
        "    ETTh1: \"ETTh1.csv\",\n",
        "    ETTh2: \"ETTh2.csv\",\n",
        "    ETTm1: \"ETTm1.csv\",\n",
        "    ETTm2: \"ETTm2.csv\"\n",
        "}\n",
        "\n",
        "datasets_pred_lens = {\n",
        "    ELECTRICITY: [336, 720], # [24, 48, 168, 336, 720]\n",
        "    ETTh1: [24, 48, 168, 336, 720],\n",
        "    ETTh2: [24, 48, 168, 336, 720],\n",
        "    WEATHER: [24, 48, 168, 336, 720],\n",
        "    M5: [28],\n",
        "    ETTm1: [24, 48, 96, 288, 672],\n",
        "    ETTm2: [24, 48, 96, 288, 672]\n",
        "}\n",
        "\n",
        "enc_in = {\n",
        "    ELECTRICITY: 321,\n",
        "    ETTh1: 7,\n",
        "    ETTh2: 7,\n",
        "    ETTm1: 7,\n",
        "    ETTm2: 7\n",
        "}\n",
        "\n",
        "config = dict(\n",
        "    model_id = MODEL_ID,\n",
        "    epochs = 0 if EPOCHS is None else EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    learning_rate = LR,\n",
        "    dataset=DATASET,\n",
        "    architecture=MODEL,\n",
        "    run_id = RUN_ID)"
      ],
      "metadata": {
        "id": "ySxfaOHQkQ_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e80e7366-67f9-4bdf-83d3-fa1d9c1c983b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current RUN_ID is tbxw0sr3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WanDB"
      ],
      "metadata": {
        "id": "WXYPOAZ8O2zL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# start a new experiment\n",
        "run = wandb.init(project=config['model_id'], config = config, id = config[\"run_id\"], resume = 'allow')\n",
        "ENCODING_FOLDER += \"/\" + run.name\n",
        "FORECASTING_RESULT += \"/\" + run.name\n",
        "CHECKPOINT_FOLDER += \"/\" + run.name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sC_id8hdO5i_",
        "outputId": "a13a929f-ee9d-4d69-a720-d671b14e959d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230927_093035-tbxw0sr3</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/desantis/SLinear_ETTh1_univariate/runs/tbxw0sr3' target=\"_blank\">giddy-blaze-3</a></strong> to <a href='https://wandb.ai/desantis/SLinear_ETTh1_univariate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/desantis/SLinear_ETTh1_univariate' target=\"_blank\">https://wandb.ai/desantis/SLinear_ETTh1_univariate</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/desantis/SLinear_ETTh1_univariate/runs/tbxw0sr3' target=\"_blank\">https://wandb.ai/desantis/SLinear_ETTh1_univariate/runs/tbxw0sr3</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Argument Parser"
      ],
      "metadata": {
        "id": "A7-lHvJRzOty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser(description='Autoformer & Transformer family for Time Series Forecasting')\n",
        "\n",
        "# basic config\n",
        "parser.add_argument('--is_training', type=int, required=True, default=1, help='status')\n",
        "parser.add_argument('--train_only', type=bool, required=False, default=False, help='perform training on full input dataset without validation and testing')\n",
        "parser.add_argument('--model_id', type=str, required=True, default='test', help='model id')\n",
        "parser.add_argument('--model', type=str, required=True, default='Autoformer',\n",
        "                    help='model name, options: [Autoformer, Informer, Transformer]')\n",
        "\n",
        "# data loader\n",
        "parser.add_argument('--data', type=str, required=True, default='ETTm1', help='dataset type')\n",
        "parser.add_argument('--root_path', type=str, default='./data/ETT/', help='root path of the data file')\n",
        "parser.add_argument('--data_path', type=str, default='ETTh1.csv', help='data file')\n",
        "parser.add_argument('--features', type=str, default='M',\n",
        "                    help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')\n",
        "parser.add_argument('--target', type=str, default='OT', help='target feature in S or MS task')\n",
        "parser.add_argument('--freq', type=str, default='h',\n",
        "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
        "parser.add_argument('--checkpoints', type=str, default='./checkpoints/', help='location of model checkpoints')\n",
        "\n",
        "# forecasting task\n",
        "parser.add_argument('--seq_len', type=int, default=96, help='input sequence length')\n",
        "parser.add_argument('--label_len', type=int, default=48, help='start token length')\n",
        "parser.add_argument('--pred_len', type=int, default=96, help='prediction sequence length')\n",
        "parser.add_argument('--seed', type=int, default=0, help='random seed')\n",
        "\n",
        "\n",
        "# DLinear\n",
        "parser.add_argument('--individual', action='store_true', default=False, help='DLinear: a linear layer for each variate(channel) individually')\n",
        "\n",
        "# SLinear\n",
        "parser.add_argument('--normalization', type=str, default='z-score', help='normalization')\n",
        "\n",
        "# Formers\n",
        "parser.add_argument('--embed_type', type=int, default=0, help='0: default 1: value embedding + temporal embedding + positional embedding 2: value embedding + temporal embedding 3: value embedding + positional embedding 4: value embedding')\n",
        "parser.add_argument('--enc_in', type=int, default=7, help='encoder input size') # DLinear with --individual, use this hyperparameter as the number of channels\n",
        "parser.add_argument('--dec_in', type=int, default=7, help='decoder input size')\n",
        "parser.add_argument('--c_out', type=int, default=7, help='output size')\n",
        "parser.add_argument('--d_model', type=int, default=512, help='dimension of model')\n",
        "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
        "parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')\n",
        "parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')\n",
        "parser.add_argument('--d_ff', type=int, default=2048, help='dimension of fcn')\n",
        "parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')\n",
        "parser.add_argument('--factor', type=int, default=1, help='attn factor')\n",
        "parser.add_argument('--distil', action='store_false',\n",
        "                    help='whether to use distilling in encoder, using this argument means not using distilling',\n",
        "                    default=True)\n",
        "parser.add_argument('--dropout', type=float, default=0.05, help='dropout')\n",
        "parser.add_argument('--embed', type=str, default='timeF',\n",
        "                    help='time features encoding, options:[timeF, fixed, learned]')\n",
        "parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
        "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in ecoder')\n",
        "parser.add_argument('--do_predict', action='store_true', help='whether to predict unseen future data')\n",
        "\n",
        "# optimization\n",
        "parser.add_argument('--num_workers', type=int, default=10, help='data loader num workers')\n",
        "parser.add_argument('--train_epochs', type=int, default=10, help='train epochs')\n",
        "parser.add_argument('--batch_size', type=int, default=32, help='batch size of train input data')\n",
        "parser.add_argument('--patience', type=int, default=3, help='early stopping patience')\n",
        "parser.add_argument('--learning_rate', type=float, default=0.0001, help='optimizer learning rate')\n",
        "parser.add_argument('--des', type=str, default='test', help='exp description')\n",
        "parser.add_argument('--loss', type=str, default='mse', help='loss function')\n",
        "parser.add_argument('--lradj', type=str, default='type1', help='adjust learning rate')\n",
        "parser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=False)\n",
        "\n",
        "# GPU\n",
        "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
        "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
        "parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
        "parser.add_argument('--devices', type=str, default='0,1,2,3', help='device ids of multile gpus')\n",
        "parser.add_argument('--test_flop', action='store_true', default=False, help='See utils/tools for usage')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7o0eClOzR6d",
        "outputId": "36ad3083-d4d7-4c88-df8d-7a8801583ab9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreTrueAction(option_strings=['--test_flop'], dest='test_flop', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='See utils/tools for usage', metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logger"
      ],
      "metadata": {
        "id": "8j5-8dn5ppGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create logger\n",
        "log = logging.getLogger('APP')\n",
        "log.setLevel(LOG_LEVEL)\n",
        "logging.basicConfig(level=LOG_LEVEL)\n",
        "\n",
        "# # create console handler and set level to debug\n",
        "# ch = logging.StreamHandler()\n",
        "# ch.setLevel(logging.INFO)\n",
        "\n",
        "# # create formatter\n",
        "# formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# # add formatter to ch\n",
        "# ch.setFormatter(formatter)\n",
        "\n",
        "# # add ch to logger\n",
        "# logger.addHandler(ch)"
      ],
      "metadata": {
        "id": "iRLWiTu4mlx9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset and Datamodule"
      ],
      "metadata": {
        "id": "ma655OWbiZ0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "XYSq_-WilrgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeFeature:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        pass\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + \"()\"\n",
        "\n",
        "\n",
        "class SecondOfMinute(TimeFeature):\n",
        "    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return index.second / 59.0 - 0.5\n",
        "\n",
        "\n",
        "class MinuteOfHour(TimeFeature):\n",
        "    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return index.minute / 59.0 - 0.5\n",
        "\n",
        "\n",
        "class HourOfDay(TimeFeature):\n",
        "    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return index.hour / 23.0 - 0.5\n",
        "\n",
        "\n",
        "class DayOfWeek(TimeFeature):\n",
        "    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return index.dayofweek / 6.0 - 0.5\n",
        "\n",
        "\n",
        "class DayOfMonth(TimeFeature):\n",
        "    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return (index.day - 1) / 30.0 - 0.5\n",
        "\n",
        "\n",
        "class DayOfYear(TimeFeature):\n",
        "    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return (index.dayofyear - 1) / 365.0 - 0.5\n",
        "\n",
        "\n",
        "class MonthOfYear(TimeFeature):\n",
        "    \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return (index.month - 1) / 11.0 - 0.5\n",
        "\n",
        "\n",
        "class WeekOfYear(TimeFeature):\n",
        "    \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return (index.isocalendar().week - 1) / 52.0 - 0.5\n",
        "\n",
        "\n",
        "def time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n",
        "    \"\"\"\n",
        "    Returns a list of time features that will be appropriate for the given frequency string.\n",
        "    Parameters\n",
        "    ----------\n",
        "    freq_str\n",
        "        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n",
        "    \"\"\"\n",
        "\n",
        "    features_by_offsets = {\n",
        "        offsets.YearEnd: [],\n",
        "        offsets.QuarterEnd: [MonthOfYear],\n",
        "        offsets.MonthEnd: [MonthOfYear],\n",
        "        offsets.Week: [DayOfMonth, WeekOfYear],\n",
        "        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n",
        "        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n",
        "        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
        "        offsets.Minute: [\n",
        "            MinuteOfHour,\n",
        "            HourOfDay,\n",
        "            DayOfWeek,\n",
        "            DayOfMonth,\n",
        "            DayOfYear,\n",
        "        ],\n",
        "        offsets.Second: [\n",
        "            SecondOfMinute,\n",
        "            MinuteOfHour,\n",
        "            HourOfDay,\n",
        "            DayOfWeek,\n",
        "            DayOfMonth,\n",
        "            DayOfYear,\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    offset = to_offset(freq_str)\n",
        "\n",
        "    for offset_type, feature_classes in features_by_offsets.items():\n",
        "        if isinstance(offset, offset_type):\n",
        "            return [cls() for cls in feature_classes]\n",
        "\n",
        "    supported_freq_msg = f\"\"\"\n",
        "    Unsupported frequency {freq_str}\n",
        "    The following frequencies are supported:\n",
        "        Y   - yearly\n",
        "            alias: A\n",
        "        M   - monthly\n",
        "        W   - weekly\n",
        "        D   - daily\n",
        "        B   - business days\n",
        "        H   - hourly\n",
        "        T   - minutely\n",
        "            alias: min\n",
        "        S   - secondly\n",
        "    \"\"\"\n",
        "    raise RuntimeError(supported_freq_msg)\n",
        "\n",
        "\n",
        "def time_features(dates, freq='h'):\n",
        "    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])"
      ],
      "metadata": {
        "id": "w_x8XS1Sltek"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets"
      ],
      "metadata": {
        "id": "0dOIrBBc1ewD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset_ETT_hour(Dataset):\n",
        "    def __init__(self, root_path, flag='train', size=None,\n",
        "                 features='S', data_path='ETTh1.csv',\n",
        "                 target='OT', scale=True, timeenc=0, freq='h', train_only=False):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['train', 'test', 'val']\n",
        "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
        "        self.set_type = type_map[flag]\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
        "                                          self.data_path))\n",
        "\n",
        "        border1s = [0, 12 * 30 * 24 - self.seq_len, 12 * 30 * 24 + 4 * 30 * 24 - self.seq_len]\n",
        "        border2s = [12 * 30 * 24, 12 * 30 * 24 + 4 * 30 * 24, 12 * 30 * 24 + 8 * 30 * 24]\n",
        "        border1 = border1s[self.set_type]\n",
        "        border2 = border2s[self.set_type]\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "        elif self.features == 'S':\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            train_data = df_data[border1s[0]:border2s[0]]\n",
        "            self.scaler.fit(train_data.values)\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "        df_stamp = df_raw[['date']][border1:border2]\n",
        "        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            data_stamp = df_stamp.drop(['date'], 1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = data[border1:border2]\n",
        "        self.data_y = data[border1:border2]\n",
        "        self.data_stamp = data_stamp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        seq_y = self.data_y[r_begin:r_end]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)\n",
        "\n",
        "\n",
        "class Dataset_ETT_minute(Dataset):\n",
        "    def __init__(self, root_path, flag='train', size=None,\n",
        "                 features='S', data_path='ETTm1.csv',\n",
        "                 target='OT', scale=True, timeenc=0, freq='t', train_only=False):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['train', 'test', 'val']\n",
        "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
        "        self.set_type = type_map[flag]\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
        "                                          self.data_path))\n",
        "\n",
        "        border1s = [0, 12 * 30 * 24 * 4 - self.seq_len, 12 * 30 * 24 * 4 + 4 * 30 * 24 * 4 - self.seq_len]\n",
        "        border2s = [12 * 30 * 24 * 4, 12 * 30 * 24 * 4 + 4 * 30 * 24 * 4, 12 * 30 * 24 * 4 + 8 * 30 * 24 * 4]\n",
        "        border1 = border1s[self.set_type]\n",
        "        border2 = border2s[self.set_type]\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "        elif self.features == 'S':\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            train_data = df_data[border1s[0]:border2s[0]]\n",
        "            self.scaler.fit(train_data.values)\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "        df_stamp = df_raw[['date']][border1:border2]\n",
        "        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            df_stamp['minute'] = df_stamp.date.apply(lambda row: row.minute, 1)\n",
        "            df_stamp['minute'] = df_stamp.minute.map(lambda x: x // 15)\n",
        "            data_stamp = df_stamp.drop(['date'], 1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = data[border1:border2]\n",
        "        self.data_y = data[border1:border2]\n",
        "        self.data_stamp = data_stamp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        seq_y = self.data_y[r_begin:r_end]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)\n",
        "\n",
        "\n",
        "class Dataset_Custom(Dataset):\n",
        "    def __init__(self, root_path, flag='train', size=None,\n",
        "                 features='S', data_path='ETTh1.csv',\n",
        "                 target='OT', scale=True, timeenc=0, freq='h', train_only=False):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['train', 'test', 'val']\n",
        "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
        "        self.set_type = type_map[flag]\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "        self.train_only = train_only\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
        "                                          self.data_path))\n",
        "\n",
        "        '''\n",
        "        df_raw.columns: ['date', ...(other features), target feature]\n",
        "        '''\n",
        "        cols = list(df_raw.columns)\n",
        "        if self.features == 'S':\n",
        "            cols.remove(self.target)\n",
        "        cols.remove('date')\n",
        "        # print(cols)\n",
        "        num_train = int(len(df_raw) * (0.7 if not self.train_only else 1))\n",
        "        num_test = int(len(df_raw) * 0.2)\n",
        "        num_vali = len(df_raw) - num_train - num_test\n",
        "        border1s = [0, num_train - self.seq_len, len(df_raw) - num_test - self.seq_len]\n",
        "        border2s = [num_train, num_train + num_vali, len(df_raw)]\n",
        "        border1 = border1s[self.set_type]\n",
        "        border2 = border2s[self.set_type]\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            df_raw = df_raw[['date'] + cols]\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "        elif self.features == 'S':\n",
        "            df_raw = df_raw[['date'] + cols + [self.target]]\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            train_data = df_data[border1s[0]:border2s[0]]\n",
        "            self.scaler.fit(train_data.values)\n",
        "            # print(self.scaler.mean_)\n",
        "            # exit()\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "        df_stamp = df_raw[['date']][border1:border2]\n",
        "        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            data_stamp = df_stamp.drop(['date'], 1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = data[border1:border2]\n",
        "        self.data_y = data[border1:border2]\n",
        "        self.data_stamp = data_stamp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        seq_y = self.data_y[r_begin:r_end]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)\n",
        "\n",
        "\n",
        "class Dataset_Pred(Dataset):\n",
        "    def __init__(self, root_path, flag='pred', size=None,\n",
        "                 features='S', data_path='ETTh1.csv',\n",
        "                 target='OT', scale=True, inverse=False, timeenc=0, freq='15min', cols=None, train_only=False):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['pred']\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.inverse = inverse\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "        self.cols = cols\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
        "                                          self.data_path))\n",
        "        '''\n",
        "        df_raw.columns: ['date', ...(other features), target feature]\n",
        "        '''\n",
        "        if self.cols:\n",
        "            cols = self.cols.copy()\n",
        "        else:\n",
        "            cols = list(df_raw.columns)\n",
        "            self.cols = cols.copy()\n",
        "            cols.remove('date')\n",
        "        if self.features == 'S':\n",
        "            cols.remove(self.target)\n",
        "        border1 = len(df_raw) - self.seq_len\n",
        "        border2 = len(df_raw)\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            df_raw = df_raw[['date'] + cols]\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "        elif self.features == 'S':\n",
        "            df_raw = df_raw[['date'] + cols + [self.target]]\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            self.scaler.fit(df_data.values)\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "        tmp_stamp = df_raw[['date']][border1:border2]\n",
        "        tmp_stamp['date'] = pd.to_datetime(tmp_stamp.date)\n",
        "        pred_dates = pd.date_range(tmp_stamp.date.values[-1], periods=self.pred_len + 1, freq=self.freq)\n",
        "\n",
        "        df_stamp = pd.DataFrame(columns=['date'])\n",
        "        df_stamp.date = list(tmp_stamp.date.values) + list(pred_dates[1:])\n",
        "        self.future_dates = list(pred_dates[1:])\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            df_stamp['minute'] = df_stamp.date.apply(lambda row: row.minute, 1)\n",
        "            df_stamp['minute'] = df_stamp.minute.map(lambda x: x // 15)\n",
        "            data_stamp = df_stamp.drop(['date'], 1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = data[border1:border2]\n",
        "        if self.inverse:\n",
        "            self.data_y = df_data.values[border1:border2]\n",
        "        else:\n",
        "            self.data_y = data[border1:border2]\n",
        "        self.data_stamp = data_stamp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        if self.inverse:\n",
        "            seq_y = self.data_x[r_begin:r_begin + self.label_len]\n",
        "        else:\n",
        "            seq_y = self.data_y[r_begin:r_begin + self.label_len]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)"
      ],
      "metadata": {
        "id": "qhF8zP_w1buC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datamodule"
      ],
      "metadata": {
        "id": "5NTY0pc31jOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.args = args\n",
        "        self.data_dict = {\n",
        "            'ETTh1': Dataset_ETT_hour,\n",
        "            'ETTh2': Dataset_ETT_hour,\n",
        "            'ETTm1': Dataset_ETT_minute,\n",
        "            'ETTm2': Dataset_ETT_minute,\n",
        "            'electricity': Dataset_Custom,\n",
        "        }\n",
        "        self.Data = self.data_dict[args.data]\n",
        "        self.timeenc = 0 if args.embed != 'timeF' else 1\n",
        "        self.train_only = args.train_only\n",
        "\n",
        "    def setup(self, stage: str):\n",
        "        args = self.args\n",
        "        shuffle_flag = True\n",
        "        drop_last = True\n",
        "        batch_size = args.batch_size\n",
        "        freq = args.freq\n",
        "        Data = self.Data\n",
        "        timeenc = self.timeenc\n",
        "        train_only = self.train_only\n",
        "\n",
        "        if stage == \"fit\":\n",
        "            self.batch_size = batch_size\n",
        "            self.shuffle_flag = shuffle_flag\n",
        "            self.drop_last = drop_last\n",
        "            self.train = Data(\n",
        "                root_path=args.root_path,\n",
        "                data_path=args.data_path,\n",
        "                flag=\"train\",\n",
        "                size=[args.seq_len, args.label_len, args.pred_len],\n",
        "                features=args.features,\n",
        "                target=args.target,\n",
        "                timeenc=timeenc,\n",
        "                freq=freq,\n",
        "                train_only=train_only\n",
        "            )\n",
        "\n",
        "            self.val = Data(\n",
        "                root_path=args.root_path,\n",
        "                data_path=args.data_path,\n",
        "                flag=\"val\",\n",
        "                size=[args.seq_len, args.label_len, args.pred_len],\n",
        "                features=args.features,\n",
        "                target=args.target,\n",
        "                timeenc=timeenc,\n",
        "                freq=freq,\n",
        "                train_only=train_only\n",
        "            )\n",
        "\n",
        "        if stage == 'test':\n",
        "            shuffle_flag = False\n",
        "            drop_last = False\n",
        "            batch_size = args.batch_size\n",
        "            freq = args.freq\n",
        "\n",
        "            self.batch_size = batch_size\n",
        "            self.shuffle_flag = shuffle_flag\n",
        "            self.drop_last = drop_last\n",
        "\n",
        "            self.test = Data(\n",
        "                root_path=args.root_path,\n",
        "                data_path=args.data_path,\n",
        "                flag=\"test\",\n",
        "                size=[args.seq_len, args.label_len, args.pred_len],\n",
        "                features=args.features,\n",
        "                target=args.target,\n",
        "                timeenc=timeenc,\n",
        "                freq=freq,\n",
        "                train_only=train_only\n",
        "            )\n",
        "\n",
        "\n",
        "        if stage == 'predict':\n",
        "            shuffle_flag = False\n",
        "            drop_last = False\n",
        "            batch_size = 1\n",
        "            freq = args.freq\n",
        "            # Data = Dataset_Pred\n",
        "\n",
        "            self.batch_size = batch_size\n",
        "            self.shuffle_flag = shuffle_flag\n",
        "            self.drop_last = drop_last\n",
        "\n",
        "            self.predict = Data(\n",
        "                root_path=args.root_path,\n",
        "                data_path=args.data_path,\n",
        "                flag=\"test\",\n",
        "                size=[args.seq_len, args.label_len, args.pred_len],\n",
        "                features=args.features,\n",
        "                target=args.target,\n",
        "                timeenc=timeenc,\n",
        "                freq=freq,\n",
        "                train_only=train_only\n",
        "            )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train,\n",
        "                        batch_size=self.batch_size,\n",
        "                        shuffle=self.shuffle_flag,\n",
        "                        num_workers=self.args.num_workers,\n",
        "                        drop_last=self.drop_last)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val,\n",
        "                        batch_size=self.batch_size,\n",
        "                        shuffle=self.shuffle_flag,\n",
        "                        num_workers=self.args.num_workers,\n",
        "                        drop_last=self.drop_last)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test,\n",
        "                        batch_size=self.batch_size,\n",
        "                        shuffle=self.shuffle_flag,\n",
        "                        num_workers=self.args.num_workers,\n",
        "                        drop_last=self.drop_last)\n",
        "\n",
        "    def predict_dataloader(self):\n",
        "        return DataLoader(self.predict,\n",
        "                        batch_size=self.batch_size,\n",
        "                        shuffle=self.shuffle_flag,\n",
        "                        num_workers=self.args.num_workers,\n",
        "                        drop_last=self.drop_last)"
      ],
      "metadata": {
        "id": "37YF2vGhSYjl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "S84zQ9UjigKj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "Oq9gmXnKGmVP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OFFCIAL IMPLEMENTATIONS 🔽"
      ],
      "metadata": {
        "id": "wriuLMemIEtl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NLinear"
      ],
      "metadata": {
        "id": "9VKcjh66BBAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class NLinear(nn.Module):\n",
        "    \"\"\"\n",
        "    Normalization-Linear\n",
        "    \"\"\"\n",
        "    def __init__(self, covariate_size, d_model, layers, individual = True):\n",
        "        super(NLinear, self).__init__()\n",
        "        self.seq_len = covariate_size\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # Use this line if you want to visualize the weights\n",
        "        # self.Linear.weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
        "        self.channels = layers\n",
        "        self.individual = individual\n",
        "        if self.individual:\n",
        "            self.Linear = nn.ModuleList()\n",
        "            for i in range(self.channels):\n",
        "                self.Linear.append(nn.Linear(self.seq_len,self.d_model))\n",
        "        else:\n",
        "            self.Linear = nn.Linear(self.seq_len, self.d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [Batch, Input length, Channel]\n",
        "        seq_last = x[:,-1:,:].detach()\n",
        "        x = x - seq_last\n",
        "        if self.individual:\n",
        "            output = torch.zeros([x.size(0),self.d_model,x.size(2)],dtype=x.dtype).to(x.device)\n",
        "            for i in range(self.channels):\n",
        "                output[:,:,i] = self.Linear[i](x[:,:,i])\n",
        "            x = output\n",
        "        else:\n",
        "            x = self.Linear(x.permute(0,2,1)).permute(0,2,1)\n",
        "        x = x + seq_last\n",
        "        return x # [Batch, Output length, Channel]"
      ],
      "metadata": {
        "id": "wb7zI3HuBDo0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand((16, 8, 201))\n",
        "model = NLinear(8, 320, 4)\n",
        "x = model(x)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gxE8HLUF_xn",
        "outputId": "89562e70-e506-4aa0-cdcb-c20207186f98"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 320, 201])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## My Model 🔽"
      ],
      "metadata": {
        "id": "YP8y2ZUZP0ew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions"
      ],
      "metadata": {
        "id": "WD_TKtHHOdZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_learning_rate(optimizer, epoch, args):\n",
        "    # lr = args.learning_rate * (0.2 ** (epoch // 2))\n",
        "    if args.lradj == 'type1':\n",
        "        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
        "    elif args.lradj == 'type2':\n",
        "        lr_adjust = {\n",
        "            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
        "            10: 5e-7, 15: 1e-7, 20: 5e-8\n",
        "        }\n",
        "    elif args.lradj == '3':\n",
        "        lr_adjust = {epoch: args.learning_rate if epoch < 10 else args.learning_rate*0.1}\n",
        "    elif args.lradj == '4':\n",
        "        lr_adjust = {epoch: args.learning_rate if epoch < 15 else args.learning_rate*0.1}\n",
        "    elif args.lradj == '5':\n",
        "        lr_adjust = {epoch: args.learning_rate if epoch < 25 else args.learning_rate*0.1}\n",
        "    elif args.lradj == '6':\n",
        "        lr_adjust = {epoch: args.learning_rate if epoch < 5 else args.learning_rate*0.1}\n",
        "    if epoch in lr_adjust.keys():\n",
        "        lr = lr_adjust[epoch]\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "        # print('Updating learning rate to {}'.format(lr))"
      ],
      "metadata": {
        "id": "c5yyhXUrOc30"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DAIN-SLinear"
      ],
      "metadata": {
        "id": "fzh7fGRdl2dN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DAIN_Layer(nn.Module):\n",
        "    def __init__(self, mode='adaptive_avg', mean_lr=0.00001, gate_lr=0.001, scale_lr=0.00001, input_dim=336):\n",
        "        super(DAIN_Layer, self).__init__()\n",
        "\n",
        "        self.mode = mode\n",
        "        self.mean_lr = mean_lr\n",
        "        self.gate_lr = gate_lr\n",
        "        self.scale_lr = scale_lr\n",
        "\n",
        "        # Parameters for adaptive average\n",
        "        self.mean_layer = nn.Linear(input_dim, input_dim, bias=False)\n",
        "        self.mean_layer.weight.data = torch.FloatTensor(data=np.eye(input_dim, input_dim))\n",
        "\n",
        "        # Parameters for adaptive std\n",
        "        self.scaling_layer = nn.Linear(input_dim, input_dim, bias=False)\n",
        "        self.scaling_layer.weight.data = torch.FloatTensor(data=np.eye(input_dim, input_dim))\n",
        "\n",
        "        # Parameters for adaptive scaling\n",
        "        self.gating_layer = nn.Linear(input_dim, input_dim)\n",
        "\n",
        "        self.eps = 1e-8\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Expecting  (n_samples, dim,  n_feature_vectors)\n",
        "\n",
        "        # Nothing to normalize\n",
        "        if self.mode == None:\n",
        "            pass\n",
        "\n",
        "        # Do simple average normalization\n",
        "        elif self.mode == 'avg':\n",
        "            avg = torch.mean(x, 2)\n",
        "            avg = avg.resize(avg.size(0), avg.size(1), 1)\n",
        "            x = x - avg\n",
        "\n",
        "        # Perform only the first step (adaptive averaging)\n",
        "        elif self.mode == 'adaptive_avg':\n",
        "            avg = torch.mean(x, 2)\n",
        "            adaptive_avg = self.mean_layer(avg)\n",
        "            adaptive_avg = adaptive_avg.resize(adaptive_avg.size(0), adaptive_avg.size(1), 1)\n",
        "            x = x - adaptive_avg\n",
        "\n",
        "        # Perform the first + second step (adaptive averaging + adaptive scaling )\n",
        "        elif self.mode == 'adaptive_scale':\n",
        "\n",
        "            # Step 1:\n",
        "            avg = torch.mean(x, 2)\n",
        "            adaptive_avg = self.mean_layer(avg)\n",
        "            adaptive_avg = adaptive_avg.resize(adaptive_avg.size(0), adaptive_avg.size(1), 1)\n",
        "            x = x - adaptive_avg\n",
        "\n",
        "            # Step 2:\n",
        "            std = torch.mean(x ** 2, 2)\n",
        "            std = torch.sqrt(std + self.eps)\n",
        "            adaptive_std = self.scaling_layer(std)\n",
        "            adaptive_std[adaptive_std <= self.eps] = 1\n",
        "\n",
        "            adaptive_std = adaptive_std.resize(adaptive_std.size(0), adaptive_std.size(1), 1)\n",
        "            x = x / (adaptive_std)\n",
        "\n",
        "        elif self.mode == 'full':\n",
        "\n",
        "            # Step 1:\n",
        "            avg = torch.mean(x, 2)\n",
        "            adaptive_avg = self.mean_layer(avg)\n",
        "            adaptive_avg = adaptive_avg.resize(adaptive_avg.size(0), adaptive_avg.size(1), 1)\n",
        "            x = x - adaptive_avg\n",
        "\n",
        "            # # Step 2:\n",
        "            std = torch.mean(x ** 2, 2)\n",
        "            std = torch.sqrt(std + self.eps)\n",
        "            adaptive_std = self.scaling_layer(std)\n",
        "            adaptive_std[adaptive_std <= self.eps] = 1\n",
        "\n",
        "            adaptive_std = adaptive_std.resize(adaptive_std.size(0), adaptive_std.size(1), 1)\n",
        "            x = x / adaptive_std\n",
        "\n",
        "            # Step 3:\n",
        "            avg = torch.mean(x, 2)\n",
        "            gate = F.sigmoid(self.gating_layer(avg))\n",
        "            gate = gate.resize(gate.size(0), gate.size(1), 1)\n",
        "            x = x * gate\n",
        "\n",
        "        else:\n",
        "            assert False\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ehcTn-uSl6Ts"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SLinear"
      ],
      "metadata": {
        "id": "RX3ADmnN_M_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SLinear(pl.LightningModule):\n",
        "    def __init__(self, configs):\n",
        "        super(SLinear, self).__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.configs = configs\n",
        "        self.seq_len = configs.seq_len\n",
        "        self.pred_len = configs.pred_len\n",
        "        self.norm = configs.normalization\n",
        "\n",
        "        # Use this line if you want to visualize the weights\n",
        "        # self.NLinear.weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
        "        self.channels = configs.enc_in\n",
        "        self.individual = configs.individual\n",
        "\n",
        "        if self.norm == 'DAIN':\n",
        "            self.dain = DAIN_Layer()\n",
        "        if self.individual:\n",
        "            self.Linear = nn.ModuleList()\n",
        "            for i in range(self.channels):\n",
        "                self.Linear.append(nn.Linear(self.seq_len,self.pred_len))\n",
        "        else:\n",
        "            self.Linear = nn.Linear(self.seq_len, self.pred_len)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        model_optim = optim.Adam(self.parameters(), lr=self.configs.learning_rate)\n",
        "        return model_optim\n",
        "\n",
        "    def _get_loss(self):\n",
        "        criterion = nn.MSELoss()\n",
        "        return criterion\n",
        "\n",
        "    def on_train_epoch_start(self):\n",
        "        self.train_loss = []\n",
        "\n",
        "    def on_validation_epoch_start(self):\n",
        "        self.val_loss = []\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        train_loss = np.average(self.train_loss)\n",
        "        self.log(\"train_loss\", train_loss, prog_bar=True)\n",
        "        wandb.log({\"train\": {\"epoch\": self.current_epoch ,\"train_loss\": train_loss}})\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        val_loss = np.average(self.val_loss)\n",
        "        self.log(\"val_loss\", val_loss, prog_bar=True)\n",
        "        wandb.log({\"val\": {\"epoch\": self.current_epoch ,\"val_loss\": val_loss}})\n",
        "        model_optim = self.optimizers(use_pl_optimizer=False)\n",
        "        adjust_learning_rate(model_optim, self.current_epoch + 1, self.configs)\n",
        "\n",
        "    def on_test_start(self):\n",
        "        # Testing\n",
        "        self.preds = []\n",
        "        self.trues = []\n",
        "        self.inputx = []\n",
        "\n",
        "    def on_test_end(self):\n",
        "        self.preds = np.concatenate(self.preds, axis=0)\n",
        "        self.trues = np.concatenate(self.trues, axis=0)\n",
        "        self.mse, self.mae = metric(self.preds, self.trues)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        batch_x, batch_y, batch_x_mark, batch_y_mark = batch\n",
        "        batch_x = batch_x.float()\n",
        "        batch_y = batch_y.float()\n",
        "        batch_x_mark = batch_x_mark.float()\n",
        "        batch_y_mark = batch_y_mark.float()\n",
        "        outputs = self(batch_x)\n",
        "        f_dim = -1 if self.configs.features == 'MS' else 0\n",
        "        outputs = outputs[:, -self.pred_len:, f_dim:]\n",
        "        batch_y = batch_y[:, -self.pred_len:, f_dim:]\n",
        "        criterion = self._get_loss()\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        self.train_loss.append(loss.item())\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        batch_x, batch_y, batch_x_mark, batch_y_mark = batch\n",
        "        batch_x = batch_x.float()\n",
        "        batch_y = batch_y.float()\n",
        "        batch_x_mark = batch_x_mark.float()\n",
        "        batch_y_mark = batch_y_mark.float()\n",
        "        outputs = self(batch_x)\n",
        "        f_dim = -1 if self.configs.features == 'MS' else 0\n",
        "        outputs = outputs[:, -self.pred_len:, f_dim:]\n",
        "        batch_y = batch_y[:, -self.pred_len:, f_dim:]\n",
        "        criterion = self._get_loss()\n",
        "        pred = outputs.detach().cpu()\n",
        "        true = batch_y.detach().cpu()\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        self.val_loss.append(loss.item())\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        batch_x, batch_y, batch_x_mark, batch_y_mark = batch\n",
        "        batch_x = batch_x.float()\n",
        "        batch_y = batch_y.float()\n",
        "        batch_x_mark = batch_x_mark.float()\n",
        "        batch_y_mark = batch_y_mark.float()\n",
        "        outputs = self(batch_x)\n",
        "        f_dim = -1 if self.configs.features == 'MS' else 0\n",
        "        outputs = outputs[:, -self.pred_len:, f_dim:]\n",
        "        batch_y = batch_y[:, -self.pred_len:, f_dim:]\n",
        "        outputs = outputs.detach().cpu().numpy()\n",
        "        batch_y = batch_y.detach().cpu().numpy()\n",
        "\n",
        "        pred = outputs  # outputs.detach().cpu().numpy()  # .squeeze()\n",
        "        true = batch_y  # batch_y.detach().cpu().numpy()  # .squeeze()\n",
        "\n",
        "        self.preds.append(pred)\n",
        "        self.trues.append(true)\n",
        "        # self.inputx.append(batch_x.detach().numpy())\n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        batch_x, batch_y, batch_x_mark, batch_y_mark = batch\n",
        "        batch_x = batch_x.float()\n",
        "        batch_y = batch_y.float()\n",
        "        batch_x_mark = batch_x_mark.float()\n",
        "        batch_y_mark = batch_y_mark.float()\n",
        "        outputs = self(batch_x)\n",
        "        # ipdb.set_trace(context=6)\n",
        "        f_dim = -1 if self.configs.features == 'MS' else 0\n",
        "        outputs = outputs[:, -self.pred_len:, f_dim:]\n",
        "        batch_y = batch_y[:, -self.pred_len:, f_dim:]\n",
        "        criterion = self._get_loss()\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        if batch_idx == 0:\n",
        "            self.best_prediction = (outputs.detach().cpu(), batch_y.detach().cpu(), loss.item())\n",
        "            return\n",
        "        if loss < self.best_prediction[2]:\n",
        "            self.best_prediction = (outputs.detach().cpu(), batch_y.detach().cpu(), loss.item())\n",
        "        return\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [Batch, Input length, Channel]\n",
        "        # Normalization\n",
        "        # ipdb.set_trace(context=6)\n",
        "        if self.norm == 'z-score':\n",
        "            mean_x = x.mean(1, keepdim=True).detach() # B x 1 x E\n",
        "            x = x - mean_x\n",
        "            std_x = torch.sqrt(torch.var(x, dim=1, keepdim=True, unbiased=False) + 1e-5).detach() # B x 1 x E\n",
        "            x = x / std_x\n",
        "        else:\n",
        "            x = self.dain(x)\n",
        "\n",
        "        if self.individual:\n",
        "            output = torch.zeros([x.size(0),self.pred_len,x.size(2)],dtype=x.dtype).to(x.device)\n",
        "            for i in range(self.channels):\n",
        "                output[:,:,i] = self.Linear[i](x[:,:,i])\n",
        "            x = output\n",
        "        else:\n",
        "            x = self.Linear(x.permute(0,2,1)).permute(0,2,1)\n",
        "        if self.norm == 'z-score':\n",
        "            # De-normalization\n",
        "            x = x * std_x + mean_x\n",
        "        return x # [Batch, Output length, Channel]"
      ],
      "metadata": {
        "id": "0zXBfuqt_PDq"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "DYNOokNm3LCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train function\n",
        "def train(batch_size, datamodule, model, model_name, max_epochs = None, max_steps = -1,\n",
        "          check_val_every_n_epoch = 1, resume_training = True, load_model = False,\n",
        "          enable_checkpoint = True, monitor_metric = \"val_loss\", checkpoint_dir = None,\n",
        "          early_stopping = True, deterministic = False, configs = None):\n",
        "\n",
        "    # check monitor metric\n",
        "    assert monitor_metric in [\"train_loss\", \"val_loss\"], \"metric to monitor is invalid\"\n",
        "\n",
        "    # initialize callbacks array\n",
        "    callbacks = [TQDMProgressBar(refresh_rate=20)]\n",
        "\n",
        "    # add checkpoints to callbacks\n",
        "    checkpoint_callback = None\n",
        "    if enable_checkpoint and checkpoint_dir is not None:\n",
        "        checkpoint_callback = ModelCheckpoint(dirpath=checkpoint_dir,  monitor = monitor_metric, filename=model_name + '{epoch:02d}-{' + monitor_metric + ':.2f}',\n",
        "                                         save_last =True, save_on_train_epoch_end = True)\n",
        "        callbacks.append(checkpoint_callback)\n",
        "\n",
        "    # add early stopping to the callbacks\n",
        "    if early_stopping:\n",
        "        callbacks.append(EarlyStopping(monitor=\"val_loss\", patience = configs.patience, mode=\"min\", check_on_train_epoch_end = False))\n",
        "\n",
        "    # create the Trainer\n",
        "    trainer = pl.Trainer(enable_checkpointing=enable_checkpoint, devices=1, accelerator=\"auto\",\n",
        "                         max_epochs=max_epochs, max_steps=max_steps, callbacks=callbacks,\n",
        "                         check_val_every_n_epoch = check_val_every_n_epoch,\n",
        "                         deterministic = deterministic)\n",
        "\n",
        "    ckpt_path = None\n",
        "    if resume_training:\n",
        "        ckpt_path = checkpoint_dir + \"/last.ckpt\"\n",
        "    trainer.fit(ckpt_path = ckpt_path, model=model, datamodule=datamodule)\n",
        "    if checkpoint_callback is not None:\n",
        "        log.info(checkpoint_callback.best_model_path)\n",
        "\n",
        "    return trainer"
      ],
      "metadata": {
        "id": "q-936er_-snn"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "Oqxoxjh9C0rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seeds = [1]\n",
        "global_mse = []\n",
        "global_mae = []\n",
        "\n",
        "pred_lens = datasets_pred_lens[DATASET]\n",
        "for seed in seeds:\n",
        "    mse = []\n",
        "    mae = []\n",
        "    for pred_len in pred_lens:\n",
        "        pred_len_folder = f\"/{pred_len}\"\n",
        "        if UNIVARIATE:\n",
        "            args = parser.parse_args([\"--is_training=1\",\n",
        "                                    \"--root_path=./dataset\", f\"--data_path={datasets_name[DATASET]}\",\n",
        "                                    f\"--model_id={MODEL_ID}\", f\"--model={MODEL}\",\n",
        "                                    f\"--data={DATASET}\", f\"--seq_len={SEQ_LEN}\",\n",
        "                                    f\"--seed={seed}\", f\"--pred_len={pred_len}\",\n",
        "                                    \"--enc_in=1\",\n",
        "                                    \"--individual\", f\"--batch_size={BATCH_SIZE}\",\n",
        "                                    \"--feature=S\", f\"--learning_rate={LR}\", f\"--normalization={NORMALIZATION}\"])\n",
        "        else:\n",
        "            args = parser.parse_args([\"--is_training=1\",\n",
        "                                    \"--root_path=./dataset\", f\"--data_path={datasets_name[DATASET]}\",\n",
        "                                    f\"--model_id={MODEL_ID}\", f\"--model={MODEL}\",\n",
        "                                    f\"--data={DATASET}\", f\"--seq_len={SEQ_LEN}\",\n",
        "                                    f\"--seed={seed}\", f\"--pred_len={pred_len}\",\n",
        "                                    f\"--enc_in={enc_in[DATASET]}\",\n",
        "                                    \"--individual\", f\"--batch_size={BATCH_SIZE}\",\n",
        "                                    \"--feature=M\", f\"--learning_rate={LR}\", f\"--normalization={NORMALIZATION}\"])\n",
        "        # initialize dataset\n",
        "        # datamodule = ElectricityDataModule(datasets_path[ELECTRICITY] + datasets_processed_name[ELECTRICITY], BATCH_SIZE, L)\n",
        "        datamodule = CustomDataModule(args)\n",
        "\n",
        "        # set seed if deterministic\n",
        "        if DETERMINISTIC:\n",
        "            seed_everything(seed)\n",
        "        # initialize model, or load an extisting one\n",
        "        if LOAD_MODEL:\n",
        "            log.info(\"loading model...\")\n",
        "            model = eval(MODEL).load_from_checkpoint(CHECKPOINT_FOLDER+pred_len_folder+\"/last.ckpt\")\n",
        "        else:\n",
        "            log.info(\"initializing model...\")\n",
        "            model = eval(MODEL)(args)\n",
        "\n",
        "        setting = '{}_{}_{}_{}_{}'.format(\n",
        "                args.model_id,\n",
        "                args.model,\n",
        "                args.data,\n",
        "                args.pred_len,\n",
        "                args.seed)\n",
        "\n",
        "        log.info(setting)\n",
        "\n",
        "        if TRAIN:\n",
        "            trainer = train(args.batch_size, datamodule, model, MODEL,\n",
        "                            max_epochs = args.train_epochs, check_val_every_n_epoch = 1,\n",
        "                            load_model = LOAD_MODEL,\n",
        "                            resume_training = RESUME_TRAINING,  monitor_metric = \"val_loss\",\n",
        "                            checkpoint_dir = CHECKPOINT_FOLDER+pred_len_folder,\n",
        "                            early_stopping = True, deterministic = DETERMINISTIC, configs = args)\n",
        "        if TEST:\n",
        "            trainer.test(model, datamodule=datamodule)\n",
        "\n",
        "            mse.append(model.mse)\n",
        "            mae.append(model.mae)\n",
        "            log.info(f\"result for pred_len: {pred_len} \\n mse: {model.mse}, mae: {model.mae}\")\n",
        "\n",
        "    if TEST:\n",
        "        global_mse.append(mse)\n",
        "        global_mae.append(mae)"
      ],
      "metadata": {
        "id": "AvftO5iOK9ZR",
        "outputId": "b22a6cda-39c9-4d46-8fc7-9941efc27b10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 1\n",
            "INFO:APP:loading model...\n",
            "INFO:APP:SLinear_ETTh1_univariate_SLinear_ETTh1_24_1\n",
            "INFO:lightning_fabric.utilities.seed:Global seed set to 1\n",
            "INFO:APP:loading model...\n",
            "INFO:APP:SLinear_ETTh1_univariate_SLinear_ETTh1_48_1\n",
            "INFO:lightning_fabric.utilities.seed:Global seed set to 1\n",
            "INFO:APP:loading model...\n",
            "INFO:APP:SLinear_ETTh1_univariate_SLinear_ETTh1_168_1\n",
            "INFO:lightning_fabric.utilities.seed:Global seed set to 1\n",
            "INFO:APP:loading model...\n",
            "INFO:APP:SLinear_ETTh1_univariate_SLinear_ETTh1_336_1\n",
            "INFO:lightning_fabric.utilities.seed:Global seed set to 1\n",
            "INFO:APP:loading model...\n",
            "INFO:APP:SLinear_ETTh1_univariate_SLinear_ETTh1_720_1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if TEST:\n",
        "    global_mse = np.array(global_mse).transpose()\n",
        "    global_mae = np.array(global_mae).transpose()\n",
        "    mse = einops.reduce(global_mse, 'i j -> i', 'mean')\n",
        "    mae = einops.reduce(global_mae, 'i j -> i', 'mean')\n",
        "    data = [[x, y] for (x, y) in zip(pred_lens, mse)]\n",
        "    table = wandb.Table(data=data, columns = [\"pred_lens\", \"mse\"])\n",
        "    wandb.log(\n",
        "    {f\"Forecasting MSE plot\" : wandb.plot.scatter(table, \"pred_lens\", \"mse\",\n",
        "        title=f\"Forecasting MSE norm plot\")})\n",
        "\n",
        "    data = [[x, y] for (x, y) in zip(pred_lens, mae)]\n",
        "    table = wandb.Table(data=data, columns = [\"pred_lens\", \"mae\"])\n",
        "    wandb.log(\n",
        "    {f\"Forecasting MAE plot\" : wandb.plot.scatter(table, \"pred_lens\", \"mae\",\n",
        "        title=f\"Forecasting MAE norm plot\")})"
      ],
      "metadata": {
        "id": "NXZsEiDVmyrB"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "8Twh-Wiq0CqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global_predictions = []\n",
        "global_true_values = []\n",
        "for pred_len in pred_lens:\n",
        "    pred_len_folder = f\"/{pred_len}\"\n",
        "    if UNIVARIATE:\n",
        "            args = parser.parse_args([\"--is_training=1\",\n",
        "                                    \"--root_path=./dataset\", f\"--data_path={datasets_name[DATASET]}\",\n",
        "                                    f\"--model_id={MODEL_ID}\", f\"--model={MODEL}\",\n",
        "                                    f\"--data={DATASET}\", f\"--seq_len={SEQ_LEN}\",\n",
        "                                    f\"--seed={seed}\", f\"--pred_len={pred_len}\",\n",
        "                                    \"--enc_in=1\",\n",
        "                                    \"--individual\", f\"--batch_size={BATCH_SIZE}\",\n",
        "                                    \"--feature=S\", f\"--learning_rate={LR}\", f\"--normalization={NORMALIZATION}\"])\n",
        "    else:\n",
        "        args = parser.parse_args([\"--is_training=1\",\n",
        "                                \"--root_path=./dataset\", f\"--data_path={datasets_name[DATASET]}\",\n",
        "                                f\"--model_id={MODEL_ID}\", f\"--model={MODEL}\",\n",
        "                                f\"--data={DATASET}\", f\"--seq_len={SEQ_LEN}\",\n",
        "                                f\"--seed={seed}\", f\"--pred_len={pred_len}\",\n",
        "                                f\"--enc_in={enc_in[DATASET]}\",\n",
        "                                \"--individual\", f\"--batch_size={BATCH_SIZE}\",\n",
        "                                \"--feature=M\", f\"--learning_rate={LR}\", f\"--normalization={NORMALIZATION}\"])\n",
        "    # initialize dataset\n",
        "    # datamodule = ElectricityDataModule(datasets_path[ELECTRICITY] + datasets_processed_name[ELECTRICITY], BATCH_SIZE, L)\n",
        "    datamodule = CustomDataModule(args)\n",
        "    log.info(\"loading model...\")\n",
        "    model = eval(MODEL).load_from_checkpoint(CHECKPOINT_FOLDER+pred_len_folder+\"/last.ckpt\")\n",
        "    trainer = pl.Trainer()\n",
        "    trainer.predict(model, datamodule)[0]\n",
        "    predictions = einops.rearrange(model.best_prediction[0].numpy(), '1 h c -> h c')\n",
        "    true_values = einops.rearrange(model.best_prediction[1].numpy(), '1 h c -> h c')\n",
        "    global_predictions.append(predictions)\n",
        "    global_true_values.append(true_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6a0110a19563467494a691d863c25ec4",
            "b64d3f98834e4b5288398bb7559e339c",
            "72cb724770d840d0b218caaaa039caab",
            "738f0611ddb1488c82a2067d8fdee7a6",
            "6177a21835a443e1aacfece99c6d8439",
            "ae3243b9ded94e5cb32cba7a62315346",
            "d75c5323b2814ff78c7629813785c71c",
            "33ec655026d04f7c8b0993889aa55281",
            "9343d9594d28482f9199fb40b62e7e23",
            "c34cfc88729e40eb9c2de34ceefdb0a4",
            "902764d4ec3a46839a8a6004da51c93d",
            "280d0fee924144cf9dc7161c81411f3d",
            "33907b4ae4674824b5cbfba707567b51",
            "4e1316eb305f44a7bdb25c02f710669b",
            "61708b025e00463c9ec928358c707d62",
            "e0947e2c81e34457a1c8a1dc7f7d719c",
            "c870adfeb61540608bd22be13d02ca31",
            "154a17ecc0ca4b53be7806be4eacb3ca",
            "1f3b12107b0f478c81d73518db782e7b",
            "7a5da96a64a34d43870d9bda931bae3f",
            "bd29b6786a94440a9f7f465289de8685",
            "9e0ad1aff9cf46808431f80e61b44dbb",
            "0348a3072418482bb496ecd69a63aa91",
            "19346f6d8bb24c0896607689b6df3c67",
            "5a60ca9a30464e968d90b75875ea39d5",
            "697dc735ce944682bfe7603bef1e0646",
            "a688005a991b4e59b9911002b83839a6",
            "c4b3c7f87a3448269dbfeb381f4f2c58",
            "4298041f3ff8409aa59641ab6d90f34e",
            "1f234c9568ed496581010e04f26a0f75",
            "08b8d778fe754af79e4e7d1092373407",
            "8641aa882b8f4238ad5a7de0829eda50",
            "f37af9819fa0452e9b572157d4bd736b",
            "0bc82d160eb14eff8384e8aefc9d13ed",
            "1ae8e7bf297544b282b2a1b6a32a5d36",
            "2fba0e249aff48d7a1e777ea6d644644",
            "52f26065157348509bb7fcbe0a6d04a3",
            "993fa9301c3a4cbc81e1ae25f4fd7a7f",
            "4ddbccbdc0394ed29c948f938b7889c3",
            "7cc478b6aaaf4f53adf4ff4493877798",
            "cf9d0b8c75864a86b6cdaa2275667821",
            "3b72f690759a4d7d9f2426f75719e88a",
            "d5c8b3d0d83046c0ab7f9d232c1ecd93",
            "b72b34e46664456db0284cdc1b61c9e2",
            "ab7c9b23b7b346c28156660dc130bd09",
            "e9b96ffdf97d4dba9dd12a6412d335e0",
            "5894667bb83a42a0b3aa78ecee2cb035",
            "da601b064c0048d3b49fa3c622bf50e3",
            "f578709f48394306a7505a39897cbf19",
            "d1877d236be34c93afeb292bdff21474",
            "85423f776a64433489dfce1174aada20",
            "215f8e1f07ea442e934af36a5f296d7b",
            "0a9d048fa7ec4a509086873393630c8a",
            "c3e51f4ad8514db6ade418e0ee038d7d",
            "55dd0d2ce80d4bca95da6f581da18915"
          ]
        },
        "id": "_juySB8q0CAQ",
        "outputId": "84cf93ae-2059-4cd0-b2ad-c0cc41f107c8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:APP:loading model...\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predicting: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a0110a19563467494a691d863c25ec4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/prediction_loop.py:233: UserWarning: predict returned None if it was on purpose, ignore this warning...\n",
            "  self._warning_cache.warn(\"predict returned None if it was on purpose, ignore this warning...\")\n",
            "INFO:APP:loading model...\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predicting: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "280d0fee924144cf9dc7161c81411f3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/prediction_loop.py:233: UserWarning: predict returned None if it was on purpose, ignore this warning...\n",
            "  self._warning_cache.warn(\"predict returned None if it was on purpose, ignore this warning...\")\n",
            "INFO:APP:loading model...\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predicting: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0348a3072418482bb496ecd69a63aa91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/prediction_loop.py:233: UserWarning: predict returned None if it was on purpose, ignore this warning...\n",
            "  self._warning_cache.warn(\"predict returned None if it was on purpose, ignore this warning...\")\n",
            "INFO:APP:loading model...\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predicting: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bc82d160eb14eff8384e8aefc9d13ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/prediction_loop.py:233: UserWarning: predict returned None if it was on purpose, ignore this warning...\n",
            "  self._warning_cache.warn(\"predict returned None if it was on purpose, ignore this warning...\")\n",
            "INFO:APP:loading model...\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predicting: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab7c9b23b7b346c28156660dc130bd09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/prediction_loop.py:233: UserWarning: predict returned None if it was on purpose, ignore this warning...\n",
            "  self._warning_cache.warn(\"predict returned None if it was on purpose, ignore this warning...\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(global_predictions)"
      ],
      "metadata": {
        "id": "QOx19KgACQLd",
        "outputId": "951e8beb-6d16-4be0-f0ba-b9e9745f6dee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,pred_len in enumerate(pred_lens):\n",
        "    log.info(f\"current pred_len: {pred_len}\")\n",
        "    plt.figure(figsize=(12,6))\n",
        "    plt.plot(global_predictions[i], label = \"SLinear\")\n",
        "    plt.plot(global_true_values[i], label = \"ground truth\")\n",
        "    plt.xlabel(\"steps\")\n",
        "    plt.ylabel(\"LSTF output\")\n",
        "    plt.title(f\"LSTF univariate output for {DATASET} with {pred_len} forecasting horizon\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.savefig(f\"/content/drive/MyDrive/Tesi/thesis/plots/plot_SLinear_{pred_len}.png\")\n",
        "    plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQkLkCSe8ATl",
        "outputId": "c5b1161d-b082-4711-e746-eaa1a4d43789"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:APP:current pred_len: 24\n",
            "INFO:APP:current pred_len: 48\n",
            "INFO:APP:current pred_len: 168\n",
            "INFO:APP:current pred_len: 336\n",
            "INFO:APP:current pred_len: 720\n"
          ]
        }
      ]
    }
  ]
}