{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/whoami-Lory271/thesis-project/blob/main/thesis.ipynb",
      "authorship_tag": "ABX9TyPOGKJO9IyR0/mV8gTlTdpp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whoami-Lory271/thesis-project/blob/main/thesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Symbol legend\n",
        "\n",
        "* B: batch size \n",
        "* M: number of channel\n",
        "* P: patch dimension\n",
        "* N: number of patches\n",
        "* L: lookback window\n"
      ],
      "metadata": {
        "id": "7s9odzFFQWyj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations and imports\n"
      ],
      "metadata": {
        "id": "w7opc0NsjlNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning==2.0.1.post0 --quiet\n",
        "!pip install einops==0.6.1 --quiet"
      ],
      "metadata": {
        "id": "ehQC2AKyci-4",
        "outputId": "a31e9567-853f-4636-8056-0dbc22c1fbeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.6/718.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.3/269.3 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import logging\n",
        "from google.colab import drive\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "# https://theaisummer.com/einsum-attention/\n",
        "import einops\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pytorch_lightning as pl"
      ],
      "metadata": {
        "id": "WuaX4Ts_jqmd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4F86VEC4VtL8",
        "outputId": "b0b0fd49-b23f-412b-9809-88b86109cba5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create logger\n",
        "log = logging.getLogger('model_application')\n",
        "log.setLevel(logging.DEBUG)\n",
        "\n",
        "# # create console handler and set level to debug\n",
        "# ch = logging.StreamHandler()\n",
        "# ch.setLevel(logging.INFO)\n",
        "\n",
        "# # create formatter\n",
        "# formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# # add formatter to ch\n",
        "# ch.setFormatter(formatter)\n",
        "\n",
        "# # add ch to logger\n",
        "# logger.addHandler(ch)"
      ],
      "metadata": {
        "id": "iRLWiTu4mlx9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'application' code\n",
        "log.debug('debug message')\n",
        "log.info('info message')\n",
        "# logger.warning('warn message')\n",
        "# logger.error('error message')\n",
        "# logger.critical('critical message')"
      ],
      "metadata": {
        "id": "4HMM8XFyTvfk",
        "outputId": "e67e3048-6d4a-49ac-857b-e78ffa6cec5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:model_application:debug message\n",
            "INFO:model_application:info message\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constants"
      ],
      "metadata": {
        "id": "94xSbfaKkOmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#paths\n",
        "ELECTRICITY = \"electricity\"\n",
        "ROOT_FOLDER = \"/content/drive/MyDrive/Università/Magistrale/Tesi/code\"\n",
        "\n",
        "#hyperparameters\n",
        "BATCH_SIZE = 16"
      ],
      "metadata": {
        "id": "ySxfaOHQkQ_B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "ma655OWbiZ0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets"
      ],
      "metadata": {
        "id": "GS_gE31AieGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets_path = {\n",
        "    ELECTRICITY: ROOT_FOLDER + \"/datasets/electricity\"\n",
        "}\n",
        "\n",
        "datasets_name = {\n",
        "    ELECTRICITY: \"/LD2011_2014.txt\"    \n",
        "}\n",
        "datasets_processed_name = {\n",
        "    ELECTRICITY: \"/electricity.pkl\"\n",
        "}"
      ],
      "metadata": {
        "id": "nX8g0950j36s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Electricity"
      ],
      "metadata": {
        "id": "S84zQ9UjigKj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "o-wdZhMWZybk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv(datasets_path[ELECTRICITY] + datasets_name[ELECTRICITY], sep = ';')\n",
        "# df.rename(columns={df.columns[0]: 'Date'},inplace=True)\n",
        "# df.to_pickle(datasets_path[ELECTRICITY] + datasets_processed_name[ELECTRICITY])"
      ],
      "metadata": {
        "id": "YsyolJAOjZVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_pickle(datasets_path[ELECTRICITY] + datasets_processed_name[ELECTRICITY])"
      ],
      "metadata": {
        "id": "CqBi00jLX4oZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ElectricityDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ts = self.data.iloc[idx, 1:]\n",
        "        return ts\n",
        "\n",
        "class ElectricityDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, path, batch_size, train_size = 0.6, test_size = 0.4):\n",
        "        super().__init__()\n",
        "        self.path = path\n",
        "        data = pd.read_pickle(path)\n",
        "        self.train_data, self.validate_data ,self.test_data =  np.split(data, [int(train_size*len(data)), int(test_size*len(data))])     \n",
        "\n",
        "    # def prepare_data(self):\n",
        "    #     # download\n",
        "\n",
        "    def setup(self, stage: str):\n",
        "        # Assign train/val datasets for use in dataloaders\n",
        "        if stage == \"fit\":\n",
        "            self.train = ElectricityDataset(self.train_data)\n",
        "            self.validate = ElectricityDataset(self.validate_data)\n",
        "\n",
        "        # Assign test dataset for use in dataloader(s)\n",
        "        if stage == \"test\":\n",
        "            self.test = ElectricityDataset(self.test_data)\n",
        "\n",
        "        # if stage == \"predict\":\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train, batch_size=self.batch_size, drop_last = True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.validation, batch_size=self.batch_size, drop_last = True)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test, batch_size=self.batch_size, drop_last = True)\n",
        "\n",
        "    # def predict_dataloader(self):\n",
        "        \n"
      ],
      "metadata": {
        "id": "pWDN4NROaOAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "Oq9gmXnKGmVP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PatchTST"
      ],
      "metadata": {
        "id": "QD52xt7xGsd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randint(20, size = (4,20,2))\n",
        "print(x.shape)\n",
        "print(\"---------------------------------\")\n",
        "tail = x[:,-1:,:]\n",
        "tail = torch.repeat_interleave(tail, 2, dim = 1)\n",
        "x = torch.concatenate((x,tail), axis = 1)\n",
        "print(x.shape)\n",
        "x = x.unfold(dimension=1, size=5, step=2)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "rRpCGPiqTtaE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81c23c9a-f177-4587-ca11-01f286cb8e49"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 20, 2])\n",
            "---------------------------------\n",
            "torch.Size([4, 22, 2])\n",
            "torch.Size([4, 9, 2, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log.debug(\"my term\")\n",
        "div_term = torch.pow(10000.0, torch.arange(0, 16, 2) / 16) \n",
        "print(div_term)\n",
        "log.debug(\"other term\")\n",
        "div_term = torch.exp(torch.arange(0, 16, 2) * -(math.log(10000.0) / 16))\n",
        "print(div_term)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEHXaMcFaX2y",
        "outputId": "8ea3f258-5a3e-40dc-c943-37d376990644"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:model_application:my term\n",
            "DEBUG:model_application:other term\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.0000e+00, 3.1623e+00, 1.0000e+01, 3.1623e+01, 1.0000e+02, 3.1623e+02,\n",
            "        1.0000e+03, 3.1623e+03])\n",
            "tensor([1.0000e+00, 3.1623e-01, 1.0000e-01, 3.1623e-02, 1.0000e-02, 3.1623e-03,\n",
            "        1.0000e-03, 3.1623e-04])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randint(20, size = (32,16,7,8), dtype=torch.float32)\n",
        "y = torch.randint(20, size = (32,16,7,8), dtype=torch.float32)\n",
        "score = x @ y.transpose(2,3)\n",
        "log.debug((score @ x).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QMgYpony3Cc",
        "outputId": "93323c1e-745a-4d5d-99be-9ecac3399d50"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:model_application:torch.Size([32, 16, 7, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility functions\n",
        "\n",
        "def create_patches(xb, patch_len, stride):\n",
        "    \"\"\"\n",
        "    xb -> [B x L x M]\n",
        "    output -> [B x N x M x P], N\n",
        "    \"\"\"\n",
        "    _, num_var, _ = xb.shape\n",
        "    # compute number of patches\n",
        "    patch_num = (max(patch_len, num_var)-patch_len) // stride + 2\n",
        "\n",
        "    # we repeat the last variable of the sequence to have equal patches\n",
        "    tail = torch.repeat_interleave(x[:,-1:,:], stride, dim = 1)\n",
        "    xb = torch.concatenate((xb, tail), axis = 1)\n",
        "\n",
        "    # create patches\n",
        "    xb = xb.unfold(dimension=1, size=patch_len, step=stride)\n",
        "\n",
        "    assert patch_num == xb.shape[1], f\"wrong number of computed patches, expected {patch_num} but computed {xb.shape[1]}\"\n",
        "\n",
        "    return xb, patch_num\n",
        "\n",
        "\"\"\"\n",
        "ref: https://kazemnejad.com/blog/transformer_architecture_positional_encoding/\n",
        "\"\"\"\n",
        "\n",
        "def positional_encoding(batch_size, patch_num, d_model):\n",
        "    \"\"\"\n",
        "    output -> [B x N x D]\n",
        "    \"\"\"\n",
        "    pe = torch.zeros(batch_size, patch_num, d_model)\n",
        "    # create a positional array\n",
        "    position = torch.arange(0, patch_num).unsqueeze(1)\n",
        "    # div term for half of positions\n",
        "    div_term = torch.pow(10000.0, torch.arange(0, d_model, 2) / d_model) \n",
        "    # even positions\n",
        "    pe[:, :, 0::2] = torch.sin(position * div_term)\n",
        "    # odd positions\n",
        "    pe[:, :, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "    # if normalize:\n",
        "    #     pe = pe - pe.mean()\n",
        "    #     pe = pe / (pe.std() * 10)\n",
        "    \n",
        "    return nn.parameter.Parameter(pe, requires_grad= False)"
      ],
      "metadata": {
        "id": "hbRO5NzrNy8b"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PatchTST\n",
        "\n",
        "class PatchTSTEncoder(nn.Module):\n",
        "    def __init__(self, num_channels, patch_num, patch_len, stride, batch_size = 16, d_model = 128, n_layers = 3, n_heads = 16, dropout = 0.2):\n",
        "        super(PatchTSTEncoder, self).__init__()\n",
        "        self.num_channels = num_channels\n",
        "        self.patch_num = patch_num\n",
        "        self.patch_len = patch_len\n",
        "        self.stride = stride\n",
        "        self.d_model = d_model\n",
        "        self.n_layers = n_layers\n",
        "        self.n_heads = n_heads\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # instance normalization\n",
        "        \"\"\"\n",
        "        ref: https://wandb.ai/wandb_fc/Normalization-Series/reports/Instance-Normalization-in-PyTorch-With-Examples---VmlldzoxNDIyNTQx\n",
        "        \"\"\"\n",
        "        self.inst_norm = nn.InstanceNorm1d(num_channels)\n",
        "\n",
        "        # patch creation\n",
        "        self.create_patch = create_patches\n",
        "\n",
        "        # embedding\n",
        "        self.W_p = nn.Linear(patch_len, d_model, bias = False)\n",
        "\n",
        "        # positional encoding\n",
        "        self.W_pos = positional_encoding(batch_size * num_channels, patch_num, d_model)\n",
        "\n",
        "        # dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # encoder\n",
        "        self.encoders = nn.ModuleList([VanillaTransformerEncoder(d_model) for _ in range(n_layers)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x -> [B x L x M]\n",
        "        output -> [(B M) x N x D]\n",
        "        \"\"\"\n",
        "        # we need to reshape dimensione before apply instance normalization\n",
        "        x = einops.rearrange(self.inst_norm(einops.rearrange(x, 'b l m -> b m l')), 'b m l -> b l m')\n",
        "\n",
        "        # create patches\n",
        "        x, patch_num = self.create_patch(x, self.patch_len, self.stride)\n",
        "\n",
        "        # reshape the tensor from [B x M x P x N] -> [(B M) x P x N]\n",
        "        x = einops.rearrange(x, 'b n m p -> (b m) n p')\n",
        "        # now it can be provided to our transformer implementation\n",
        "\n",
        "        # project into transformer latent space\n",
        "        x = self.W_p(x) + self.W_pos\n",
        "\n",
        "        for layer in self.encoders:\n",
        "            x = layer(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "bhiJYUZcGvr_"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vanilla Transformer Encoder"
      ],
      "metadata": {
        "id": "lnbN5rUYocvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VanillaTransformer encoder\n",
        "\n",
        "\"\"\"\n",
        "https://arxiv.org/pdf/1706.03762.pdf\n",
        "\"\"\"\n",
        "\n",
        "class VanillaTransformerEncoder(nn.Module):\n",
        "    def __init__(self, d_model, n_heads = 16, dropout = 0.2):\n",
        "        super(VanillaTransformerEncoder, self).__init__()\n",
        "        \n",
        "        self.mha = MultiHeadAttention(d_model, n_heads)\n",
        "        self.norm1 = nn.LayerNorm(d_model) # maybe batch normalization\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.pffn = PositionWiseFeedForwardNetwork(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # new variable because of residual connection\n",
        "        z = self.mha(x,x,x)\n",
        "        z = self.dropout1(z)\n",
        "        z = self.norm1(z + x)\n",
        "\n",
        "        # set the new value for the residual connection\n",
        "        x = z\n",
        "        z = self.pffn(z)\n",
        "        z = self.dropout2(z)\n",
        "        return self.norm2(z + x)\n",
        "\n",
        "\"\"\"\n",
        "ref: https://d2l.ai/chapter_attention-mechanisms-and-transformers/multihead-attention.html\n",
        "\"\"\"\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads = 16):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "        assert d_model % n_heads == 0, \"n_heads must be a multiple of d_model\"\n",
        "\n",
        "        self.n_heads = n_heads\n",
        "        self.d_k = d_model // n_heads\n",
        "\n",
        "        self.W_q = nn.Linear(d_model, d_model, bias = False)\n",
        "        self.W_k = nn.Linear(d_model, d_model, bias = False)\n",
        "        self.W_v = nn.Linear(d_model, d_model, bias = False)\n",
        "        self.W_o = nn.Linear(d_model, d_model, bias = False)\n",
        "\n",
        "    # reshape to compute in parallel the several heads\n",
        "    def reshape_vector(self, x, inverse = False):\n",
        "        \"\"\"\n",
        "        x: [B x N x D] || [B x N x H x DIM]\n",
        "        output: [B x N x H x DIM] || [B x N x D]\n",
        "        \"\"\"\n",
        "        out = None\n",
        "\n",
        "        if not inverse:\n",
        "            out = einops.rearrange(x, 'b n (dim h) -> b h n dim', h=self.n_heads)\n",
        "        else:\n",
        "            out = einops.rearrange(x, 'b h n dim -> b n (dim h)')\n",
        "\n",
        "        return out\n",
        "\n",
        "    \"\"\"\n",
        "    ref: https://machinelearningmastery.com/the-transformer-attention-mechanism/\n",
        "    \"\"\"\n",
        "\n",
        "    def scaled_attention(self, q, k, v, dk):\n",
        "        \"\"\"\n",
        "        q: [B x H x N x DIM], k: [B x H x N x DIM] , v: [B x H x N x DIM]\n",
        "        output: [B x H x N x DIM]\n",
        "        \"\"\"\n",
        "        sqrt_d_k = math.sqrt(dk)\n",
        "\n",
        "        # using einsum to perform batch matrix multiplication\n",
        "        score = einops.einsum(q, k, 'b h n d_k, b h n_1 d_k -> b h n n_1') / sqrt_d_k\n",
        "\n",
        "        weights = F.softmax(score, dim = -1)\n",
        "\n",
        "        res = einops.einsum(weights, v, 'b h n n_1, b h n_1 d_k -> b h n d_k')\n",
        "\n",
        "        return res\n",
        "\n",
        "    def forward(self, q, k, v):\n",
        "        \"\"\"\n",
        "        q, k, v: [B x N x D]\n",
        "        output: [B x N x D]\n",
        "        \"\"\"\n",
        "        q = self.reshape_vector(self.W_q(q))\n",
        "        k = self.reshape_vector(self.W_k(k))\n",
        "        v = self.reshape_vector(self.W_v(v))\n",
        "\n",
        "        # parallel computation\n",
        "        out = self.scaled_attention(q, k, v, self.d_k)\n",
        "        out_concat = self.reshape_vector(out, inverse = True)\n",
        "\n",
        "        return self.W_o(out_concat)\n",
        "\n",
        "class PositionWiseFeedForwardNetwork(nn.Module):\n",
        "    def __init__(self, d_model, d_inner = 256):\n",
        "        super(PositionWiseFeedForwardNetwork, self).__init__()\n",
        "        self.W_1 = nn.Linear(d_model, d_inner)\n",
        "        self.act = nn.GELU()\n",
        "        self.W_2 = nn.Linear(d_inner, d_model)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.W_1(x)\n",
        "        x = self.act(x)\n",
        "        return self.W_2(x)"
      ],
      "metadata": {
        "id": "f7JI-qgOpWbs"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B = 16\n",
        "L = 20\n",
        "M = 3\n",
        "P = 5\n",
        "S = 3\n",
        "N = (L - P)  // S + 2\n",
        "\n",
        "x = torch.randint(20, size = (B,L,M), dtype=torch.float32)\n",
        "encoder = PatchTSTEncoder(M, N, P, S)\n",
        "x = encoder(x)\n",
        "log.debug(x.shape)"
      ],
      "metadata": {
        "id": "nsk_8II50vM0",
        "outputId": "960f89fa-72ff-48f5-ce1b-31f09b4af01a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:model_application:torch.Size([48, 7, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cost"
      ],
      "metadata": {
        "id": "DTlGPLvHrJ5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cost\n",
        "\n",
        "class Cost(nn.Module):\n",
        "    def __init__(self, num_channels, patch_num, patch_len, stride, batch_size = 16, d_model = 128, n_layers = 3, n_heads = 16, dropout = 0.2):\n",
        "        super(Cost, self).__init__()\n",
        "\n",
        "\n",
        "class TrendFeatureDisentangler(nn.Module):\n",
        "    def __init__(self, d_model, d_t, patch_num):\n",
        "        super(TrendFeatureDisentangler, self).__init__()\n",
        "        \n",
        "        # https://discuss.pytorch.org/t/causal-convolution/3456/3\n",
        "        # https://arxiv.org/pdf/1609.03499v2.pdf\n",
        "\n",
        "        # floor(log(N/2)) autoregressive expert\n",
        "        self.experts = nn.ModuleList([self.CausalConv1d(d_model, d_t, 2**i)] for i in range(math.floor(math.log2((patch_num + 1) / 2))))\n",
        "\n",
        "    def CausalConv1d(self, in_channels, out_channels, kernel_size, dilation=1):\n",
        "        pad = (kernel_size - 1) * dilation\n",
        "        return nn.Conv1d(in_channels, out_channels, kernel_size, padding=pad, dilation=dilation)\n"
      ],
      "metadata": {
        "id": "-U9fYJUKrN4S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}