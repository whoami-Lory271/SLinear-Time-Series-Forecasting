{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whoami-Lory271/thesis-project/blob/Pyra_Encoder/thesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Symbol legend\n",
        "\n",
        "* B: batch size\n",
        "* L: lookback window (aka input_size)\n"
      ],
      "metadata": {
        "id": "7s9odzFFQWyj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations and imports\n"
      ],
      "metadata": {
        "id": "w7opc0NsjlNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning==2.0.1.post0 --quiet\n",
        "!pip install einops==0.6.1 --quiet\n",
        "!pip install ipdb --quiet\n",
        "!pip install wandb --quiet"
      ],
      "metadata": {
        "id": "ehQC2AKyci-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a441dabd-5cf4-4dfb-9378-036c565c3ef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.6/718.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.1/731.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import logging\n",
        "# https://github.com/gotcha/ipdb\n",
        "import ipdb\n",
        "import copy\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "# https://theaisummer.com/einsum-attention/\n",
        "import einops\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Ridge\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "\n",
        "import wandb"
      ],
      "metadata": {
        "id": "WuaX4Ts_jqmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "4F86VEC4VtL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions"
      ],
      "metadata": {
        "id": "J2UVU6VqgizJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup logger function\n",
        "def setup_log(self, level):\n",
        "    log = logging.getLogger(self.__class__.__name__)\n",
        "    log.setLevel(level)\n",
        "    return log"
      ],
      "metadata": {
        "id": "gkBTe3nko46m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write log on a file\n",
        "def write_log(a):\n",
        "    with open(\"log.txt\", 'w') as file:\n",
        "        for row in a:\n",
        "            file.write(str(row))\n",
        "        log.debug(\"object logged\")"
      ],
      "metadata": {
        "id": "i8LE_3TogiZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_patch_num(patch_len, num_var, stride):\n",
        "    return (max(patch_len, num_var)-patch_len) // stride + 2"
      ],
      "metadata": {
        "id": "Ke58BUkLo-dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pad array with nan\n",
        "def pad_nan(arr, left=0, right=0, dim=0):\n",
        "    # padding the right side\n",
        "    if left > 0:\n",
        "        padshape = list(arr.shape)\n",
        "        padshape[dim] = left\n",
        "        arr = torch.cat((torch.full(padshape, np.nan).to(arr.device), arr), dim=dim)\n",
        "\n",
        "    # padding the left side\n",
        "    if right > 0:\n",
        "        padshape = list(arr.shape)\n",
        "        padshape[dim] = right\n",
        "        arr = torch.cat((arr, torch.full(padshape, np.nan)).to(arr.device), dim=dim)\n",
        "    return arr"
      ],
      "metadata": {
        "id": "T_LjdLhhiyGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split with nan\n",
        "def split_with_nan(x, sections, axis=0):\n",
        "    assert x.dtype in [np.float16, np.float32, np.float64]\n",
        "    arrs = np.array_split(x, sections, axis=axis)\n",
        "    target_length = arrs[0].shape[axis]\n",
        "    for i in range(len(arrs)):\n",
        "        arrs[i] = pad_nan_to_target(arrs[i], target_length, axis=axis)\n",
        "    return arrs"
      ],
      "metadata": {
        "id": "8Z2FotiSArtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pad with nan\n",
        "def pad_nan_to_target(array, target_length, axis=0):\n",
        "    assert array.dtype in [np.float16, np.float32, np.float64]\n",
        "    pad_size = target_length - array.shape[axis]\n",
        "    if pad_size <= 0:\n",
        "        return array\n",
        "    npad = [(0, 0)] * array.ndim\n",
        "    npad[axis] = (0, pad_size)\n",
        "\n",
        "    return np.pad(array, pad_width=npad, mode='constant', constant_values=np.nan)"
      ],
      "metadata": {
        "id": "1SAjsR_-A3RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def centerize_vary_length_series(x):\n",
        "    prefix_zeros = np.argmax(~np.isnan(x).all(axis=-1), axis=1)\n",
        "    suffix_zeros = np.argmax(~np.isnan(x[:, ::-1]).all(axis=-1), axis=1)\n",
        "    offset = (prefix_zeros + suffix_zeros) // 2 - prefix_zeros\n",
        "    rows, column_indices = np.ogrid[:x.shape[0], :x.shape[1]]\n",
        "    offset[offset < 0] += x.shape[1]\n",
        "    column_indices = column_indices - offset[:, np.newaxis]\n",
        "\n",
        "    return x[rows, column_indices]"
      ],
      "metadata": {
        "id": "eK2M1qV3JBdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random seed functions\n",
        "def seed_everything(seed):\n",
        "    pl.seed_everything(seed, workers=True)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "mzBQAeoIi8l2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constants"
      ],
      "metadata": {
        "id": "94xSbfaKkOmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# logger\n",
        "LOG_LEVEL = logging.DEBUG\n",
        "\n",
        "# datasets\n",
        "ELECTRICITY = \"electricity\"\n",
        "\n",
        "# models\n",
        "CoSpy = \"CoSpy\"\n",
        "\n",
        "model = CoSpy\n",
        "\n",
        "# device\n",
        "\n",
        "DEVICE = torch.device('cpu')\n",
        "\n",
        "if torch.cuda.is_available:\n",
        "    DEVICE = torch.device('cuda')\n",
        "\n",
        "#paths\n",
        "ROOT_FOLDER = \"/content/drive/MyDrive/Tesi/code\"\n",
        "MODEL_FOLDER = ROOT_FOLDER + \"/models\"\n",
        "CHECKPOINT_FOLDER = ROOT_FOLDER + \"/checkpoints\" + \"/\" + model\n",
        "LOGS_FOLDER = ROOT_FOLDER + \"/logs\"\n",
        "\n",
        "#hyperparameters\n",
        "\n",
        "# Train\n",
        "BATCH_SIZE = 128\n",
        "L = 201\n",
        "\n",
        "# Eval\n",
        "# MAX_TRAIN_LENGTH = 201\n",
        "# PADDING = MAX_TRAIN_LENGTH-1\n",
        "# EVAL_PATCH_NUM = get_patch_num(PATCH_LEN, MAX_TRAIN_LENGTH, STRIDE)\n",
        "# EVAL_BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "# training\n",
        "DETERMINISTIC = True\n",
        "LOAD_MODEL = False"
      ],
      "metadata": {
        "id": "ySxfaOHQkQ_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logger"
      ],
      "metadata": {
        "id": "8j5-8dn5ppGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create logger\n",
        "log = logging.getLogger('APP')\n",
        "log.setLevel(LOG_LEVEL)\n",
        "logging.basicConfig(level=LOG_LEVEL)\n",
        "\n",
        "# # create console handler and set level to debug\n",
        "# ch = logging.StreamHandler()\n",
        "# ch.setLevel(logging.INFO)\n",
        "\n",
        "# # create formatter\n",
        "# formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# # add formatter to ch\n",
        "# ch.setFormatter(formatter)\n",
        "\n",
        "# # add ch to logger\n",
        "# logger.addHandler(ch)"
      ],
      "metadata": {
        "id": "iRLWiTu4mlx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "ma655OWbiZ0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets"
      ],
      "metadata": {
        "id": "GS_gE31AieGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets_path = {\n",
        "    ELECTRICITY: ROOT_FOLDER + \"/datasets/electricity\"\n",
        "}\n",
        "\n",
        "datasets_name = {\n",
        "    ELECTRICITY: \"/LD2011_2014.txt\"\n",
        "}\n",
        "datasets_processed_name = {\n",
        "    ELECTRICITY: \"/electricity.csv\" #\"/electricity.npy\"\n",
        "}"
      ],
      "metadata": {
        "id": "nX8g0950j36s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Electricity"
      ],
      "metadata": {
        "id": "S84zQ9UjigKj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "o-wdZhMWZybk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv(datasets_path[ELECTRICITY] + datasets_name[ELECTRICITY], sep = ';')\n",
        "# df.rename(columns={df.columns[0]: 'Date'},inplace=True)\n",
        "# values = df.values\n",
        "# values = values[:, 1:].astype(str)\n",
        "# for i, value in enumerate(values):\n",
        "#   values[i] = np.char.replace(value, \",\", \".\")\n",
        "# values = values.astype(np.float32)\n",
        "# np.save(datasets_path[ELECTRICITY] + \"/electricity\", values)"
      ],
      "metadata": {
        "id": "YsyolJAOjZVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # call this function to initialize the csv file\n",
        "# def electricity_preprocess(path):\n",
        "#     data_ecl = pd.read_csv(path + '/LD2011_2014.txt', parse_dates=True, sep=';', decimal=',', index_col=0)\n",
        "#     data_ecl = data_ecl.resample('1h', closed='right').sum()\n",
        "#     data_ecl = data_ecl.loc[:, data_ecl.cumsum(axis=0).iloc[8920] != 0]  # filter out instances with missing values\n",
        "#     data_ecl.index = data_ecl.index.rename('date')\n",
        "#     data_ecl = data_ecl['2012':]\n",
        "#     data_ecl.to_csv(path + '/electricity.csv')\n",
        "#     log.info(\"electriciy.csv created!\")"
      ],
      "metadata": {
        "id": "HqM-Bf5vWJDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# electricity_preprocess(datasets_path[ELECTRICITY])"
      ],
      "metadata": {
        "id": "YS1CZBhuWei-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ElectricityDatasetENC(Dataset):\n",
        "    def __init__(self, tensors):\n",
        "        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors), \"Size mismatch between tensors\"\n",
        "        self.tensors = tensors\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return tuple(tensor[index] for tensor in self.tensors)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.tensors[0].size(0)\n",
        "\n",
        "class ElectricityDataset(Dataset):\n",
        "    def __init__(self, data, eval_mode = False, p = 0.5, multiplier = 10):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.eval_mode = eval_mode\n",
        "        self.p = p\n",
        "        self.multiplier = multiplier\n",
        "        self.epsilon = torch.empty(1).normal_(mean = 0, std = 0.5)\n",
        "        self.N, self.T, self.D = data.shape # num_ts, time, dim\n",
        "\n",
        "    def __len__(self):\n",
        "        # return self.data.shape[0] // self.look_window\n",
        "        return self.data.shape[0] * self.multiplier\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        out: [B x MAX_TRAIN_LEN x TIME_DIM]\n",
        "        \"\"\"\n",
        "        # # rescale the index\n",
        "        # start = idx * self.look_window\n",
        "        # end = start + self.look_window\n",
        "        # # tale all the channels and skip the date\n",
        "        # ts = self.data[start:end]\n",
        "        # # convert in a tensor\n",
        "        # ts = torch.from_numpy(ts) # [L x M]\n",
        "        # ts = einops.rearrange(ts, 'l m -> m l')\n",
        "\n",
        "        # # during the evaluation of the encoder we want the untouched time serie\n",
        "        # if self.eval_mode:\n",
        "        #     return ts\n",
        "        ts = self.data[idx % self.N]\n",
        "\n",
        "        return self.transform(ts), self.transform(ts)\n",
        "\n",
        "    def get_len(self):\n",
        "        return self.__len__()\n",
        "\n",
        "    # def get_channels(self):\n",
        "    #     return self.data.iloc[0, 1:].astype(str).str.replace(',', '.').astype('float32').shape[0]\n",
        "\n",
        "    def transform(self, x):\n",
        "        return self.jitter(self.shift(self.scale(x)))\n",
        "\n",
        "    def jitter(self, x):\n",
        "        if random.random() > self.p:\n",
        "            return x\n",
        "        return x + torch.empty(1).normal_(mean = 0, std = 0.5)\n",
        "\n",
        "    def scale(self, x):\n",
        "        if random.random() > self.p:\n",
        "            return x\n",
        "        return x * self.epsilon\n",
        "\n",
        "    def shift(self, x):\n",
        "        if random.random() > self.p:\n",
        "            return x\n",
        "        return x + self.epsilon\n",
        "\n",
        "class ElectricityDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, path, batch_size, max_train_length, train_size = 0.6, test_size = 0.2):\n",
        "        super().__init__()\n",
        "        self.path = path # path to csv file\n",
        "        self.batch_size = batch_size\n",
        "        self.max_train_length = max_train_length\n",
        "        self.train_size = train_size\n",
        "        self.test_size = test_size\n",
        "        # self.data = np.load(path)\n",
        "\n",
        "    # def prepare_data(self):\n",
        "    #     # download\n",
        "\n",
        "    def _get_time_features(self,dt):\n",
        "        return np.stack([\n",
        "                dt.minute.to_numpy(),\n",
        "                dt.hour.to_numpy(),\n",
        "                dt.dayofweek.to_numpy(),\n",
        "                dt.day.to_numpy(),\n",
        "                dt.dayofyear.to_numpy(),\n",
        "                dt.month.to_numpy(),\n",
        "                dt.weekofyear.to_numpy(),\n",
        "            ], axis=1).astype(float)\n",
        "\n",
        "    def _load_forecast_csv(self, path):\n",
        "        data = pd.read_csv(path, index_col='date', parse_dates=True)\n",
        "        dt_embed = self._get_time_features(data.index)\n",
        "        n_covariate_cols = dt_embed.shape[-1]\n",
        "        data = data.to_numpy()\n",
        "        # compute slices\n",
        "        self.train_slice = slice(None, int(self.train_size * len(data)))\n",
        "        self.valid_slice = slice(int(self.train_size * len(data)), - int(self.test_size * len(data)))\n",
        "        self.test_slice = slice(- int(self.test_size * len(data)), None)\n",
        "\n",
        "        return data, dt_embed, n_covariate_cols\n",
        "\n",
        "    def _scale_and_transform(self, data, dt_embed, n_covariate_cols):\n",
        "        # scale data\n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(data[self.train_slice])\n",
        "        data = scaler.transform(data)\n",
        "        # NUM_ROWS x NUM_FEATURES -> NUM_FEATURES x NUM_ROWS x 1\n",
        "        data = np.expand_dims(data.T, -1)  # Each variable is an instance rather than a feature\n",
        "        if n_covariate_cols > 0:\n",
        "            dt_scaler = StandardScaler().fit(dt_embed[self.train_slice])\n",
        "            dt_embed = np.expand_dims(dt_scaler.transform(dt_embed), 0)\n",
        "            data = np.concatenate([np.repeat(dt_embed, data.shape[0], axis=0), data], axis=-1)\n",
        "        pred_lens = [24, 48, 96, 288, 672]\n",
        "\n",
        "        return data, scaler, pred_lens, n_covariate_cols\n",
        "\n",
        "    def _fit_setup(self, train_data):\n",
        "        if self.max_train_length is not None:\n",
        "            sections = train_data.shape[1] // self.max_train_length\n",
        "        if sections >= 2:\n",
        "            train_data = np.concatenate(split_with_nan(train_data, sections, axis=1), axis=0)\n",
        "\n",
        "        temporal_missing = np.isnan(train_data).all(axis=-1).any(axis=0)\n",
        "        if temporal_missing[0] or temporal_missing[-1]:\n",
        "            train_data = centerize_vary_length_series(train_data)\n",
        "\n",
        "        train_data = train_data[~np.isnan(train_data).all(axis=2).all(axis=1)]\n",
        "\n",
        "        multiplier = 1 if train_data.shape[0] >= self.batch_size else math.ceil(self.batch_size / train_data.shape[0])\n",
        "\n",
        "        return train_data, multiplier\n",
        "\n",
        "\n",
        "    def setup(self, stage: str):\n",
        "        # load csv\n",
        "        data, dt_embed, n_covariate_cols = self._load_forecast_csv(self.path)\n",
        "\n",
        "        # scale and transform\n",
        "        data, scaler, pred_lens, n_covariate_cols = self._scale_and_transform(data, dt_embed, n_covariate_cols)\n",
        "\n",
        "        # Assign train/val datasets for use in dataloaders\n",
        "        if stage == \"fit\":\n",
        "            train_data = data[self.train_slice]\n",
        "            train_data, multiplier = self._fit_setup(train_data)\n",
        "            # fit setup\n",
        "            self.train = ElectricityDataset(torch.from_numpy(train_data).to(torch.float), multiplier = multiplier)\n",
        "            # self.validate = ElectricityDataset(data[self.valid_slice], self.look_window)\n",
        "\n",
        "        # Assign test dataset for use in dataloader(s)\n",
        "        # if stage == \"test\":\n",
        "        #     self.test = ElectricityDataset(data[self.test_slice], self.look_window)\n",
        "\n",
        "        # if stage == \"predict\":\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train, batch_size=self.batch_size, drop_last = True)\n",
        "\n",
        "    # def val_dataloader(self):\n",
        "    #     return DataLoader(self.validate, batch_size=self.batch_size, drop_last = True)\n",
        "\n",
        "    # def test_dataloader(self):\n",
        "    #     return DataLoader(self.test, batch_size=self.batch_size, drop_last = True)\n",
        "\n",
        "    # def predict_dataloader(self):\n",
        "\n"
      ],
      "metadata": {
        "id": "pWDN4NROaOAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# em = ElectricityDataModule(datasets_path[ELECTRICITY] + datasets_processed_name[ELECTRICITY],\n",
        "#                       BATCH_SIZE, 10, MAX_TRAIN_LENGTH)\n",
        "# em.setup(\"fit\")"
      ],
      "metadata": {
        "id": "6YIgF7LxsPVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# log.debug(em.train.__getitem__(0)[0].shape)"
      ],
      "metadata": {
        "id": "Mp3eSgVliKLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "Oq9gmXnKGmVP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vanilla Transformer Encoder"
      ],
      "metadata": {
        "id": "lnbN5rUYocvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VanillaTransformer encoder\n",
        "\n",
        "\"\"\"\n",
        "https://arxiv.org/pdf/1706.03762.pdf\n",
        "\"\"\"\n",
        "\n",
        "class VanillaTransformerEncoder(nn.Module):\n",
        "    def __init__(self, d_model, n_heads = 16, dropout = 0.2):\n",
        "        super(VanillaTransformerEncoder, self).__init__()\n",
        "\n",
        "        self.log = setup_log(self, LOG_LEVEL)\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, n_heads)\n",
        "        self.norm1 = nn.LayerNorm(d_model) # maybe batch normalization\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.pffn = PositionWiseFeedForwardNetwork(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # new variable because of residual connection\n",
        "        z = self.mha(x,x,x)\n",
        "        z = self.dropout1(z)\n",
        "        z = self.norm1(z + x)\n",
        "\n",
        "        # set the new value for the residual connection\n",
        "        x = z\n",
        "        z = self.pffn(z)\n",
        "        z = self.dropout2(z)\n",
        "        return self.norm2(z + x)\n",
        "\n",
        "\"\"\"\n",
        "ref: https://d2l.ai/chapter_attention-mechanisms-and-transformers/multihead-attention.html\n",
        "\"\"\"\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, d_k, n_head = 6):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "        self.log = setup_log(self, LOG_LEVEL)\n",
        "\n",
        "        self.n_heads = n_head\n",
        "        self.d_k = d_k\n",
        "\n",
        "        self.W_q = nn.Linear(d_model, n_head * d_k, bias = False)\n",
        "        self.W_k = nn.Linear(d_model, n_head * d_k, bias = False)\n",
        "        self.W_v = nn.Linear(d_model, n_head * d_k, bias = False)\n",
        "        self.W_o = nn.Linear(n_head * d_k, d_model, bias = False)\n",
        "\n",
        "    # reshape to compute in parallel the several heads\n",
        "    def reshape_vector(self, x, inverse = False):\n",
        "        \"\"\"\n",
        "        x: (batch, input_size, d_model) || (batch, n_head, input_size, d_k)\n",
        "        output: (batch, n_head, input_size, d_k) || (batch, input_size, d_model)\n",
        "        \"\"\"\n",
        "        out = None\n",
        "\n",
        "        if not inverse:\n",
        "            out = einops.rearrange(x, 'b l (dim h) -> b h l dim', h=self.n_heads)\n",
        "        else:\n",
        "            out = einops.rearrange(x, 'b h l dim -> b l (dim h)')\n",
        "\n",
        "        return out\n",
        "\n",
        "    \"\"\"\n",
        "    ref: https://machinelearningmastery.com/the-transformer-attention-mechanism/\n",
        "    \"\"\"\n",
        "\n",
        "    def scaled_attention(self, q, k, v, dk, mask = None):\n",
        "        \"\"\"\n",
        "        q, k, v: (batch, n_head, input_size, d_k)\n",
        "        output: (batch, n_head, input_size, d_k), (batch, n_head, input_size, input_size)\n",
        "        \"\"\"\n",
        "        sqrt_d_k = math.sqrt(dk)\n",
        "\n",
        "        # using einsum to perform batch matrix multiplication\n",
        "        score = einops.einsum(q, k, 'b h l d_k, b h l_1 d_k -> b h l l_1') / sqrt_d_k\n",
        "\n",
        "        if mask is not None:\n",
        "            score = score.masked_fill(mask, -1e9)\n",
        "\n",
        "        weights = F.softmax(score, dim = -1)\n",
        "        attn = weights\n",
        "\n",
        "        res = einops.einsum(weights, v, 'b h l l_1, b h l_1 d_k -> b h l d_k')\n",
        "\n",
        "        return res, attn\n",
        "\n",
        "    def forward(self, q, k, v, mask = None):\n",
        "        \"\"\"\n",
        "        q, k, v: (batch, input_size, d_model)\n",
        "        output: (batch, input_size, d_model), (batch, n_head, input_size, input_size)\n",
        "        \"\"\"\n",
        "        residual = q\n",
        "\n",
        "        q = self.reshape_vector(self.W_q(q))\n",
        "        k = self.reshape_vector(self.W_k(k))\n",
        "        v = self.reshape_vector(self.W_v(v))\n",
        "\n",
        "        if mask is not None:\n",
        "            if len(mask.size()) == 3:\n",
        "                mask = mask.unsqueeze(1)  # For head axis broadcasting.\n",
        "\n",
        "        # parallel computation\n",
        "        out, attn = self.scaled_attention(q, k, v, self.d_k, mask)\n",
        "        out_concat = self.reshape_vector(out, inverse = True)\n",
        "\n",
        "        return self.W_o(out_concat) + residual, attn\n",
        "\n",
        "class PositionWiseFeedForwardNetwork(nn.Module):\n",
        "    def __init__(self, d_model, d_inner = 512):\n",
        "        super(PositionWiseFeedForwardNetwork, self).__init__()\n",
        "\n",
        "        self.log = setup_log(self, LOG_LEVEL)\n",
        "\n",
        "        self.W_1 = nn.Linear(d_model, d_inner)\n",
        "        self.act = nn.GELU()\n",
        "        self.W_2 = nn.Linear(d_inner, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch, input_size, d_model)\n",
        "        output: (batch, input_size, d_model)\n",
        "        \"\"\"\n",
        "        res = x\n",
        "        x = self.W_1(x)\n",
        "        x = self.act(x)\n",
        "        return res + self.W_2(x)"
      ],
      "metadata": {
        "id": "f7JI-qgOpWbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyraformerEncoder"
      ],
      "metadata": {
        "id": "j4VKdJgKsshh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions"
      ],
      "metadata": {
        "id": "d0TB55l1yKvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mask(input_size, window_size, inner_size, device):\n",
        "    \"\"\"Get the attention mask of PAM-Naive\"\"\"\n",
        "    # Get the size of all layers\n",
        "    all_size = []\n",
        "    all_size.append(input_size)\n",
        "    # we split the nodes in according with the number of children\n",
        "    for i in range(len(window_size)):\n",
        "        layer_size = math.floor(all_size[i] / window_size[i])\n",
        "        all_size.append(layer_size)\n",
        "\n",
        "    # length of the flattened graph\n",
        "    seq_length = sum(all_size)\n",
        "    # mask matrix\n",
        "    mask = torch.zeros(seq_length, seq_length, device=device)\n",
        "\n",
        "    # get intra-scale mask\n",
        "    inner_window = inner_size // 2\n",
        "    for layer_idx in range(len(all_size)):\n",
        "        start = sum(all_size[:layer_idx])\n",
        "        for i in range(start, start + all_size[layer_idx]):\n",
        "            left_side = max(i - inner_window, start)\n",
        "            right_side = min(i + inner_window + 1, start + all_size[layer_idx])\n",
        "            mask[i, left_side:right_side] = 1\n",
        "\n",
        "    # get inter-scale mask\n",
        "    for layer_idx in range(1, len(all_size)):\n",
        "        start = sum(all_size[:layer_idx])\n",
        "        for i in range(start, start + all_size[layer_idx]):\n",
        "            left_side = (start - all_size[layer_idx - 1]) + (i - start) * window_size[layer_idx - 1]\n",
        "            if i == ( start + all_size[layer_idx] - 1):\n",
        "                right_side = start\n",
        "            else:\n",
        "                right_side = (start - all_size[layer_idx - 1]) + (i - start + 1) * window_size[layer_idx - 1]\n",
        "            mask[i, left_side:right_side] = 1\n",
        "            mask[left_side:right_side, i] = 1\n",
        "\n",
        "    mask = (1 - mask).bool()\n",
        "\n",
        "    return mask, all_size\n",
        "\n",
        "def get_graph_dim(input_size, window_size):\n",
        "    \"\"\" get the dimension of the graph computed by CSCM\"\"\"\n",
        "    res = input_size\n",
        "    for w in window_size:\n",
        "        input_size = math.floor(input_size / w)\n",
        "        res += input_size\n",
        "\n",
        "    return res\n",
        "\n"
      ],
      "metadata": {
        "id": "rZXf-0odyPbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "d6HSFST8yIkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck_Construct(nn.Module):\n",
        "    \"\"\"Bottleneck convolution CSCM\"\"\"\n",
        "    def __init__(self, d_model, window_size, d_inner):\n",
        "        super(Bottleneck_Construct, self).__init__()\n",
        "        if not isinstance(window_size, list):\n",
        "            self.conv_layers = nn.ModuleList([\n",
        "                ConvLayer(d_inner, window_size),\n",
        "                ConvLayer(d_inner, window_size),\n",
        "                ConvLayer(d_inner, window_size)\n",
        "                ])\n",
        "        else:\n",
        "            self.conv_layers = []\n",
        "            for i in range(len(window_size)):\n",
        "                self.conv_layers.append(ConvLayer(d_inner, window_size[i]))\n",
        "            self.conv_layers = nn.ModuleList(self.conv_layers)\n",
        "        self.up = Linear(d_inner, d_model)\n",
        "        self.down = Linear(d_model, d_inner)\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, enc_input):\n",
        "\n",
        "        temp_input = self.down(enc_input).permute(0, 2, 1)\n",
        "        all_inputs = []\n",
        "        for i in range(len(self.conv_layers)):\n",
        "            temp_input = self.conv_layers[i](temp_input)\n",
        "            all_inputs.append(temp_input)\n",
        "\n",
        "        all_inputs = torch.cat(all_inputs, dim=2).transpose(1, 2)\n",
        "        all_inputs = self.up(all_inputs)\n",
        "        all_inputs = torch.cat([enc_input, all_inputs], dim=1)\n",
        "\n",
        "        all_inputs = self.norm(all_inputs)\n",
        "\n",
        "        return all_inputs\n",
        "\"\"\" For Electricity Dataset\"\"\"\n",
        "class PositionalEmbedding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEmbedding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        # create a positional array\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        # div term for half of positions\n",
        "        div_term = torch.pow(10000.0, torch.arange(0, d_model, 2) / d_model)\n",
        "        # even positions\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        # odd positions\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "        # if normalize:\n",
        "        #     pe = pe - pe.mean()\n",
        "        #     pe = pe / (pe.std() * 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        output: (1, input_size, d_model)\n",
        "        \"\"\"\n",
        "        return self.pe[:, :x.size(1)]\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, c_in, d_model):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        padding = 1 if torch.__version__>='1.5.0' else 2\n",
        "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
        "                                    kernel_size=3, padding=padding, padding_mode='circular')\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d):\n",
        "                nn.init.kaiming_normal_(m.weight,mode='fan_in',nonlinearity='leaky_relu')\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch, input_size, enc_in)\n",
        "        output: (batch, input_size, d_model)\n",
        "        \"\"\"\n",
        "        x = self.tokenConv(einops.rearrange(x, 'b l e -> b e l')).transpose(1,2)\n",
        "        return x\n",
        "\n",
        "class CustomEmbedding(nn.Module):\n",
        "    def __init__(self, c_in, d_model, temporal_size, seq_num, dropout=0.1):\n",
        "        super(CustomEmbedding, self).__init__()\n",
        "\n",
        "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
        "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
        "        self.temporal_embedding = nn.Linear(temporal_size, d_model)\n",
        "        self.seqid_embedding = nn.Embedding(seq_num, d_model)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x, x_mark):\n",
        "        \"\"\"\n",
        "        x: (batch, input_size, enc_in)\n",
        "        x_mark: (batch, input_size)\n",
        "        output: (batch, input_size, d_model)\n",
        "        \"\"\"\n",
        "        x = self.value_embedding(x) + self.position_embedding(x) + self.temporal_embedding(x_mark[:, :, :-1]) \\\n",
        "            + self.seqid_embedding(x_mark[:, :, -1].long())\n",
        "\n",
        "\n",
        "\n",
        "        return self.dropout(x)\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    \"\"\" Compose with two layers \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, d_inner, d_k, n_head, dropout=0.1, normalize_before=True, q_k_mask=None, k_q_mask=None):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.slf_attn = MultiHeadAttention(d_model, d_k, n_head)\n",
        "\n",
        "        self.pos_ffn = PositionWiseFeedForwardNetwork(\n",
        "            d_model, d_inner)\n",
        "\n",
        "    def forward(self, enc_input, slf_attn_mask=None):\n",
        "        \"\"\"\n",
        "        enc_input: (batch, input_size, d_model)\n",
        "        output: (batch, input_size, d_model), (batch, n_head, input_size, input_size)\n",
        "        \"\"\"\n",
        "        enc_output, enc_slf_attn = self.slf_attn(enc_input, enc_input, enc_input, mask=slf_attn_mask)\n",
        "\n",
        "        enc_output = self.pos_ffn(enc_output)\n",
        "\n",
        "        return enc_output, enc_slf_attn\n",
        "\n",
        "class ConvLayer(nn.Module):\n",
        "    def __init__(self, c_in, window_size):\n",
        "        super(ConvLayer, self).__init__()\n",
        "        self.downConv = nn.Conv1d(in_channels=c_in,\n",
        "                                  out_channels=c_in,\n",
        "                                  kernel_size=window_size,\n",
        "                                  stride=window_size)\n",
        "        self.norm = nn.BatchNorm1d(c_in)\n",
        "        self.activation = nn.ELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downConv(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "class Bottleneck_Construct(nn.Module):\n",
        "    \"\"\"Bottleneck convolution CSCM\"\"\"\n",
        "    def __init__(self, d_model, window_size, d_inner):\n",
        "        super(Bottleneck_Construct, self).__init__()\n",
        "        if not isinstance(window_size, list):\n",
        "            self.conv_layers = nn.ModuleList([\n",
        "                ConvLayer(d_inner, window_size),\n",
        "                ConvLayer(d_inner, window_size),\n",
        "                ConvLayer(d_inner, window_size)\n",
        "                ])\n",
        "        else:\n",
        "            self.conv_layers = []\n",
        "            for i in range(len(window_size)):\n",
        "                self.conv_layers.append(ConvLayer(d_inner, window_size[i]))\n",
        "            self.conv_layers = nn.ModuleList(self.conv_layers)\n",
        "        self.up = nn.Linear(d_inner, d_model)\n",
        "        self.down = nn.Linear(d_model, d_inner)\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, enc_input):\n",
        "        \"\"\"\n",
        "        enc_input: (batch, input_size, d_model)\n",
        "        output: (batch, graph_size, d_model)\n",
        "        \"\"\"\n",
        "\n",
        "        temp_input = self.down(enc_input).permute(0, 2, 1)\n",
        "        all_inputs = []\n",
        "        for i in range(len(self.conv_layers)):\n",
        "            temp_input = self.conv_layers[i](temp_input)\n",
        "            all_inputs.append(temp_input)\n",
        "\n",
        "        all_inputs = torch.cat(all_inputs, dim=2).transpose(1, 2)\n",
        "        all_inputs = self.up(all_inputs)\n",
        "        # concat the computed new nodes with the input nodes\n",
        "        all_inputs = torch.cat([enc_input, all_inputs], dim=1)\n",
        "\n",
        "        all_inputs = self.norm(all_inputs)\n",
        "\n",
        "        return all_inputs\n",
        "\n",
        "class PyraformerEncoder(nn.Module):\n",
        "    \"\"\" A encoder model with self attention mechanism. \"\"\"\n",
        "\n",
        "    def __init__(self, d_model = 256, d_k = 128, window_size = [4,4,4], inner_size = 3,\n",
        "                 input_size = 201, d_inner_hid = 512, n_head = 6, n_layer = 4,\n",
        "                 # Dataloader parameters\n",
        "                 enc_in = 1, covariate_size = 7, seq_num = 321,\n",
        "                 CSCM = \"Bottleneck_Construct\", d_bottleneck = 128,\n",
        "                 device = 'cpu'):\n",
        "        super(PyraformerEncoder, self).__init__()\n",
        "        self.log = setup_log(self, LOG_LEVEL)\n",
        "\n",
        "        self.d_model = d_model # size of the latent vector\n",
        "        self.d_k = d_k # size of the inner dimension of q, k, v\n",
        "        self.window_size = window_size # The number of children of a parent node\n",
        "        self.inner_size = inner_size # The number of ajacent nodes\n",
        "        self.input_size = input_size # length of the sequence\n",
        "        self.d_inner_hid = d_inner_hid # inner size of the PostitionalFeedForward\n",
        "        self.n_head = n_head\n",
        "        self.n_layer = n_layer\n",
        "        self.enc_in = enc_in\n",
        "        self.covariate_size = covariate_size # number of temporal covariate\n",
        "        self.seq_num = seq_num # size of the time series\n",
        "        self.CSCM = CSCM # called coarser-scale construction module\n",
        "        self.g_size = get_graph_dim(input_size, window_size)\n",
        "        self.d_bottleneck = d_bottleneck #\n",
        "        self.mask, self.all_size = get_mask(self.input_size, self.window_size, self.inner_size, device)\n",
        "        self.layers = nn.ModuleList([\n",
        "                EncoderLayer(self.d_model, self.d_inner_hid, self.d_k, self.n_head) for i in range(self. n_layer)\n",
        "                ])\n",
        "        self.enc_embedding = nn.Linear(enc_in + covariate_size, d_model)#CustomEmbedding(self.enc_in, self.d_model, self.covariate_size, self.seq_num)\n",
        "\n",
        "        self.conv_layers = eval(self.CSCM)(self.d_model, self.window_size, self.d_bottleneck)\n",
        "\n",
        "        self.fc = nn.Linear(self.g_size, self.input_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch, input_size, enc_in + covariate_size)\n",
        "        output: (batch, input_size, d_model)\n",
        "        \"\"\"\n",
        "\n",
        "        seq_enc = self.enc_embedding(x)\n",
        "\n",
        "        # Repeat the mask for all the batch\n",
        "        mask = self.mask.repeat(len(seq_enc), 1, 1).to(x.device)\n",
        "        seq_enc = self.conv_layers(seq_enc)\n",
        "\n",
        "        for i in range(len(self.layers)):\n",
        "            seq_enc, _ = self.layers[i](seq_enc, mask)\n",
        "\n",
        "        seq_enc = einops.rearrange(seq_enc, 'b g d -> b d g')\n",
        "\n",
        "        seq_enc = self.fc(seq_enc)\n",
        "\n",
        "        seq_enc = einops.rearrange(seq_enc, 'b d l -> b l d')\n",
        "\n",
        "        return seq_enc"
      ],
      "metadata": {
        "id": "LiOdyvP8syOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PatchTST"
      ],
      "metadata": {
        "id": "QD52xt7xGsd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility functions\n",
        "\n",
        "def create_patches(xb, patch_len, stride):\n",
        "    \"\"\"\n",
        "    xb -> [B x L x M] // [B x L x M x T]\n",
        "    output -> [B x N x M x P] // [B x N x M x T x P], N\n",
        "    \"\"\"\n",
        "    _, num_var, _, _ = xb.shape\n",
        "    # compute number of patches\n",
        "    patch_num = (max(patch_len, num_var)-patch_len) // stride + 2\n",
        "\n",
        "    # we repeat the last variable of the sequence to have equal patches\n",
        "    tail = torch.repeat_interleave(xb[:,-1:,...], stride, dim = 1)\n",
        "    xb = torch.concatenate((xb, tail), axis = 1)\n",
        "\n",
        "    # create patches\n",
        "    xb = xb.unfold(dimension=1, size=patch_len, step=stride)\n",
        "\n",
        "    assert patch_num == xb.shape[1], f\"wrong number of computed patches, expected {patch_num} but computed {xb.shape[1]}\"\n",
        "\n",
        "    return xb, patch_num\n",
        "\n",
        "\"\"\"\n",
        "ref: https://kazemnejad.com/blog/transformer_architecture_positional_encoding/\n",
        "\"\"\"\n",
        "\n",
        "def positional_encoding(batch_size, max_len, d_model):\n",
        "    \"\"\"\n",
        "    output\n",
        "    \"\"\"\n",
        "    pe = torch.zeros(batch_size, max_len, d_model)\n",
        "    # create a positional array\n",
        "    position = torch.arange(0, max_len).unsqueeze(1)\n",
        "    # div term for half of positions\n",
        "    div_term = torch.pow(10000.0, torch.arange(0, d_model, 2) / d_model)\n",
        "    # even positions\n",
        "    pe[:, :, 0::2] = torch.sin(position * div_term)\n",
        "    # odd positions\n",
        "    pe[:, :, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "    # if normalize:\n",
        "    #     pe = pe - pe.mean()\n",
        "    #     pe = pe / (pe.std() * 10)\n",
        "\n",
        "    return nn.parameter.Parameter(pe, requires_grad= False)"
      ],
      "metadata": {
        "id": "hbRO5NzrNy8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PatchTST\n",
        "\n",
        "class PatchTSTEncoder(nn.Module):\n",
        "    def __init__(self, num_channels, num_var, patch_len, stride, batch_size, time_dimension = 8, d_model = 128, n_layers = 3, n_heads = 16, dropout = 0.2):\n",
        "        super(PatchTSTEncoder, self).__init__()\n",
        "\n",
        "        self.log = setup_log(self, LOG_LEVEL)\n",
        "\n",
        "        self.num_channels = num_channels\n",
        "        self.patch_num = (max(patch_len, num_var)-patch_len) // stride + 2\n",
        "        self.patch_len = patch_len\n",
        "        self.stride = stride\n",
        "        self.batch_size = batch_size\n",
        "        self.d_model = d_model\n",
        "        self.n_layers = n_layers\n",
        "        self.n_heads = n_heads\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # instance normalization\n",
        "        \"\"\"\n",
        "        ref: https://wandb.ai/wandb_fc/Normalization-Series/reports/Instance-Normalization-in-PyTorch-With-Examples---VmlldzoxNDIyNTQx\n",
        "        \"\"\"\n",
        "        self.inst_norm = nn.InstanceNorm2d(num_channels)\n",
        "\n",
        "        # patch creation\n",
        "        self.create_patch = create_patches\n",
        "\n",
        "        # embedding\n",
        "        self.W_p = nn.Linear(patch_len * time_dimension, d_model, bias = False)\n",
        "\n",
        "        # positional encoding\n",
        "        self.W_pos = positional_encoding(batch_size * num_channels, self.patch_num, d_model)\n",
        "\n",
        "        # dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # encoder\n",
        "        self.encoders = nn.ModuleList([VanillaTransformerEncoder(d_model) for _ in range(n_layers)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x -> [B x L x M] // [(B x M) x MAX_TRAIN_LENGTH x TIME_DIM]\n",
        "        output -> [(B M) x N x D]\n",
        "        \"\"\"\n",
        "        b_m, _, _ = x\n",
        "        assert b_m / self.num_channel == self.batch_size, f\"invalid fisrt dimension {b_m / self.num_channel} != {self.batch_size}\"\n",
        "        # [(B M) x MAX_TRAIN_LENGTH x TIME_DIM] -> [B x M x MAX_TRAIN_LENGTH x TIME_DIM]\n",
        "        x = einops.rearrange(x, '(b m) l t -> b m l t', m=self.num_channels)\n",
        "        # we need to reshape dimensione before apply instance normalization\n",
        "        x = einops.rearrange(self.inst_norm(x), 'b m l t -> b l m t')\n",
        "\n",
        "        # create patches\n",
        "        x, patch_num = self.create_patch(x, self.patch_len, self.stride)\n",
        "\n",
        "        # x: [B x N x M x T x P]\n",
        "\n",
        "        assert self.patch_num == patch_num, f\"wrong number for patch_num {self.patch_num} != {patch_num}\"\n",
        "\n",
        "        # reshape the tensor from [B x N x M x T x P] -> [(B M) x N x (P T)]\n",
        "        x = einops.rearrange(x, 'b n m t p -> (b m) n (p t)')\n",
        "        # now it can be provided to our transformer implementation\n",
        "\n",
        "        # project into transformer latent space\n",
        "        x = self.W_p(x) + self.W_pos\n",
        "\n",
        "        for layer in self.encoders:\n",
        "            x = layer(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "bhiJYUZcGvr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cost"
      ],
      "metadata": {
        "id": "DTlGPLvHrJ5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.loss import TripletMarginWithDistanceLoss\n",
        "#Cost\n",
        "\n",
        "class Cost(nn.Module):\n",
        "    def __init__(self, input_size, d_model = 256, d_s = 128, d_t = 128, n_layers = 3, n_heads = 6, dropout = 0.2):\n",
        "        super(Cost, self).__init__()\n",
        "\n",
        "        self.log = setup_log(self, LOG_LEVEL)\n",
        "\n",
        "        # Dropout for seasonal representation output\n",
        "        self.seasonal_drop = nn.Dropout(0.1)\n",
        "\n",
        "        # Trend Feature Disentangler\n",
        "        self.tfd = TrendFeatureDisentangler(d_model, d_t, input_size)\n",
        "\n",
        "        # Seasonal Feature Disentangler\n",
        "        self.sfd = SeasonalFeatureDisentangler(d_model, d_s, input_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch, input_size, d_model)\n",
        "        outputs: (batch, input_size, d_t), (batch, input_size, d_s)\n",
        "        \"\"\"\n",
        "        out_tfd = self.tfd(x)\n",
        "\n",
        "        out_svd = self.sfd(x)\n",
        "\n",
        "        out_svd = self.seasonal_drop(out_svd)\n",
        "\n",
        "        return out_tfd, out_svd\n",
        "\n",
        "\n",
        "\n",
        "# Causal Convolution (dilated)\n",
        "\n",
        "class CausalConv1d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, dilation=1):\n",
        "        super(CausalConv1d, self).__init__()\n",
        "\n",
        "        self.log = setup_log(self, LOG_LEVEL)\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "        pad = (kernel_size - 1) * dilation\n",
        "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, padding=pad, dilation=dilation)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        input: (batch, input_size, in_channels)\n",
        "        output: (batch, conv_out, out_channels)\n",
        "        \"\"\"\n",
        "        # we need to reshape before applying the convolution\n",
        "        x = einops.rearrange(x, 'b l i_c -> b i_c l')\n",
        "        x = self.conv(x)\n",
        "\n",
        "        # we need to remove the trailing padding zeros (except for the fist layer) from the values\n",
        "        if self.kernel_size > 1:\n",
        "            x = x[...,0:-(self.kernel_size-1)]\n",
        "\n",
        "        # rearrange to the original shape\n",
        "        x = einops.rearrange(x, 'b o_c l -> b l o_c')\n",
        "\n",
        "        return x\n",
        "\n",
        "# TFD\n",
        "\n",
        "class TrendFeatureDisentangler(nn.Module):\n",
        "    def __init__(self, d_model, d_t, input_size):\n",
        "        super(TrendFeatureDisentangler, self).__init__()\n",
        "\n",
        "        self.log = setup_log(self, LOG_LEVEL)\n",
        "        self.d_model = d_model\n",
        "        self.d_t = d_t\n",
        "        self.input_size = input_size\n",
        "\n",
        "        # https://discuss.pytorch.org/t/causal-convolution/3456/3\n",
        "        # https://arxiv.org/pdf/1609.03499v2.pdf\n",
        "\n",
        "        # floor(log(N/2)) autoregressive expert\n",
        "        self.conv_num = math.floor(math.log2(input_size / 2)) + 1\n",
        "        self.kernel = [2**i for i in range(self.conv_num)]\n",
        "        self.convolutions = nn.ModuleList([CausalConv1d(d_model, d_t, k) for k in self.kernel])\n",
        "\n",
        "    def avg_pooling(self, input):\n",
        "        \"\"\"\n",
        "        input: (list, batch, input_size, d_t)\n",
        "        \"\"\"\n",
        "        return einops.reduce(input, 'list b l d_t -> b l d_t', 'mean')\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch, input_size, d_model)\n",
        "        output: (batch, input_size, d_t)\n",
        "        \"\"\"\n",
        "        batch_size, input_size, d_model = x.shape\n",
        "\n",
        "        assert input_size == self.input_size and d_model == self.d_model, \"wrong input dimensions\"\n",
        "\n",
        "        # create the result tensor\n",
        "        trend = torch.zeros(self.conv_num, batch_size, input_size, self.d_t, device = x.device)\n",
        "\n",
        "        for i, conv in enumerate(self.convolutions):\n",
        "            out = conv(x)\n",
        "            trend[i,...] = out\n",
        "\n",
        "        # apply the average pooling operation\n",
        "        trend = self.avg_pooling(trend)\n",
        "\n",
        "        return trend\n",
        "\n",
        "# SVD\n",
        "\n",
        "class SeasonalFeatureDisentangler(nn.Module):\n",
        "    def __init__(self, d_model, d_s, input_size):\n",
        "        super(SeasonalFeatureDisentangler, self).__init__()\n",
        "\n",
        "        self.log = setup_log(self, LOG_LEVEL)\n",
        "\n",
        "        self.input_size = input_size\n",
        "\n",
        "        # number of frequencies after dft\n",
        "        self.f = input_size // 2 + 1\n",
        "\n",
        "        # discrete fast fourier transform, rfft output contains only the positive frequencies below the Nyquist frequency\n",
        "        self.dft = torch.fft.rfft\n",
        "\n",
        "        # Learnable Fourier Layer\n",
        "        self.fl = FourierLayer(self.f, d_model, d_s, input_size)\n",
        "\n",
        "        # inverse of discrete fast fourier transform\n",
        "        self.idft = torch.fft.irfft\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch, input_size, d_model)\n",
        "        output: (batch, input_size, d_s)\n",
        "        \"\"\"\n",
        "        # we apply dft along the temporal dimension\n",
        "        x = self.dft(x, dim = 1)\n",
        "\n",
        "        assert self.f == x.shape[1], \"wrong dimension of dft\"\n",
        "\n",
        "        # apply fourier layer\n",
        "        x = self.fl(x)\n",
        "\n",
        "        # compute the inverse of dft to come back to time domain\n",
        "        x = self.idft(x, n = self.input_size, dim = 1) # pass also the legth in order to avoid odd-length problems\n",
        "\n",
        "        return x\n",
        "\n",
        "class FourierLayer(nn.Module):\n",
        "    def __init__(self, f, d_model, d_s, input_size):\n",
        "        super(FourierLayer, self).__init__()\n",
        "\n",
        "        self.log = setup_log(self, LOG_LEVEL)\n",
        "\n",
        "        self.f = f\n",
        "        self.d_model = d_model\n",
        "\n",
        "        self.A = nn.Parameter(torch.rand((f, d_model, d_s), dtype=torch.cfloat))\n",
        "        self.B = nn.Parameter(torch.rand((f, d_s), dtype=torch.cfloat))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch, f, d_model)\n",
        "        out: (batch, f, d_s)\n",
        "        \"\"\"\n",
        "        batch_size, f, _ = x.shape\n",
        "\n",
        "        assert f == self.f, \"wrong dimensions of x\"\n",
        "\n",
        "        out = einops.einsum(self.A, x, 'f d d_s, b f d -> b f d_s') + self.B\n",
        "\n",
        "        return out\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-U9fYJUKrN4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CoSpy Encoder"
      ],
      "metadata": {
        "id": "omgfLK9mFicv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %debug\n",
        "class CoSpyEncoder(nn.Module):\n",
        "    def __init__(self, input_size,\n",
        "                 d_model = 256, d_s = 128, d_t = 128,\n",
        "                 dropout = 0.2, device = 'cpu'):\n",
        "        super(CoSpyEncoder, self).__init__()\n",
        "        # self.save_hyperparameters()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.log = setup_log(self, LOG_LEVEL)\n",
        "\n",
        "        # Pyraformer layer (backbone encoder)\n",
        "        self.py = PyraformerEncoder(d_model, device = device)\n",
        "\n",
        "\n",
        "        # CoST layer (disentangler)\n",
        "        self.cost = Cost(self.input_size)\n",
        "\n",
        "    # def encode(self, loader, batch_size, ts_l, device, sliding_length=1, padding=200):\n",
        "    #     reprs = []\n",
        "\n",
        "    #     n_samples, ts_l, _ = data.shape\n",
        "\n",
        "    #     org_training = self.training\n",
        "    #     self.eval()\n",
        "\n",
        "    #     with torch.no_grad():\n",
        "    #         output = []\n",
        "    #         for batch in tqdm(loader, desc=\"input encoding\"):\n",
        "    #             self.log.debug(f\"x.shape {x.shape}\")\n",
        "    #             x = batch[0] # [B x L x M]\n",
        "    #             x = x.to(device)\n",
        "    #             # self.log.debug(type(x))\n",
        "    #             # self.log.debug(f\"shape of batch: {x.shape}\")\n",
        "\n",
        "    #             # if self.batch_size != batch_size:\n",
        "    #             #     self.log.debug(\"different batch size return same batch\")\n",
        "    #             #     return batch\n",
        "\n",
        "    #             for i in range(0, ts_l, sliding_length):\n",
        "    #                 l = i - padding # sliding_padding=200\n",
        "    #                 r = i + sliding_length\n",
        "    #                 # self.log.debug(x.device)\n",
        "    #                 x_sliding = pad_nan(\n",
        "    #                     x[:, max(l, 0) : min(r, ts_l)],\n",
        "    #                     left=-l if l<0 else 0,\n",
        "    #                     right=r-ts_l if r>ts_l else 0,\n",
        "    #                     dim=1\n",
        "    #                 )\n",
        "    #                 if x_sliding.shape[1] != padding+1:\n",
        "    #                     self.log.debug(f\"l: {l}, r: {r}, ts_l: {ts_l}\")\n",
        "    #                 # self.log.debug(x_sliding.device)\n",
        "    #                 # self.log.debug(f\"shape of x_sliding: {x_sliding.shape}\")\n",
        "    #                 # self.log.debug(x_sliding.shape)\n",
        "    #                 reprs.append(self.eval_with_pooling(x_sliding))\n",
        "\n",
        "    #             out = torch.cat(reprs, dim=1)\n",
        "    #             self.log.debug(f\"out.shape: {out.shape}\")\n",
        "    #             output.append(out)\n",
        "\n",
        "    #         output = torch.cat(output, dim=0)\n",
        "\n",
        "    #     self.train(org_training)\n",
        "    #     return output.numpy()\n",
        "\n",
        "    def eval_with_pooling(self, x):\n",
        "        out_t, out_s = self(x)\n",
        "        out = torch.cat([out_t[:, -1], out_s[:, -1]], dim=-1)\n",
        "        return einops.rearrange(out.cpu(), 'b d -> b () d')\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch, input_size, enc_in + covariate_size)\n",
        "        outputs: (batch, input_size, d_t), (batch, input_size, d_s)\n",
        "        \"\"\"\n",
        "\n",
        "        nan_mask = ~x.isnan().any(axis=-1)\n",
        "        x[~nan_mask] = 0\n",
        "\n",
        "        x = self.py(x)\n",
        "\n",
        "        trend, season = self.cost(x)\n",
        "\n",
        "        return trend, season"
      ],
      "metadata": {
        "id": "uSr7enmSFptR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CoSpy Model"
      ],
      "metadata": {
        "id": "niFGAd70x41j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Constrastive model similar to MoCo\n",
        "\"\"\"\n",
        "https://arxiv.org/pdf/1911.05722.pdf\n",
        "https://github.com/facebookresearch/moco/blob/main/moco/builder.py\n",
        "\"\"\"\n",
        "\n",
        "class CoSpyModel(pl.LightningModule):\n",
        "    def __init__(self, max_train_length, comp_dimension = 128, alpha = 5e-4, K = 65536, m = 0.999, T = 0.07,\n",
        "                 lr = 1e-3, om = 0.9, wd = 1e-4):\n",
        "        super(CoSpyModel, self).__init__()\n",
        "\n",
        "        self.input_size = max_train_length\n",
        "        self.max_train_length = max_train_length\n",
        "\n",
        "        self.K = K\n",
        "        self.m = m\n",
        "        self.T = T\n",
        "\n",
        "        self.alpha = alpha\n",
        "\n",
        "        self.lr = lr\n",
        "        self.om = om\n",
        "        self.wd = wd\n",
        "\n",
        "        self.encoder_q = CoSpyEncoder(self.input_size)\n",
        "        self.encoder_k = copy.deepcopy(self.encoder_q)\n",
        "\n",
        "        # projections head for queries and keyes\n",
        "        self.head_q = nn.Sequential(\n",
        "            nn.Linear(comp_dimension, comp_dimension),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(comp_dimension, comp_dimension)\n",
        "        )\n",
        "        self.head_k = nn.Sequential(\n",
        "            nn.Linear(comp_dimension, comp_dimension),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(comp_dimension, comp_dimension)\n",
        "        )\n",
        "\n",
        "        # initialize the parameters of the keyes encoder and projection head\n",
        "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
        "            param_k.data.copy_(param_q.data)\n",
        "            param_k.requires_grad = False # the keyes encoder will be updated by the momentum update\n",
        "\n",
        "        for param_q, param_k in zip(self.head_q.parameters(), self.head_k.parameters()):\n",
        "            param_k.data.copy_(param_q.data)\n",
        "            param_k.requires_grad = False # the head_k will be updated by the momentum update\n",
        "\n",
        "        # register a dictionary buffer as a queue (decouped from the minibatch size)\n",
        "        # https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_buffer\n",
        "        self.register_buffer('queue', F.normalize(torch.randn(comp_dimension, K), dim=0))\n",
        "        self.register_buffer('queue_ptr', torch.zeros(1, dtype=torch.long))\n",
        "\n",
        "        self.save_hyperparameters(ignore=['encoder_q', 'encoder_k'])\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # set parameters of SGD\n",
        "        optimizer = torch.optim.SGD(self.parameters(), lr = self.lr, momentum = self.om, weight_decay = self.wd)\n",
        "        # cosine annelling is a wrapper for SGD\n",
        "        cosine_anneling = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer = optimizer, T_max = 100)\n",
        "        return optimizer\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _momentum_update_key_encoder(self):\n",
        "        \"\"\"\n",
        "        Momentum update for key encoder\n",
        "        \"\"\"\n",
        "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
        "            param_k.data = param_k.data * self.m + param_q.data * (1 - self.m)\n",
        "\n",
        "        for param_q, param_k in zip(self.head_q.parameters(), self.head_k.parameters()):\n",
        "            param_k.data = param_k.data * self.m + param_q.data * (1 - self.m)\n",
        "\n",
        "    def compute_loss(self, q, k, k_negs):\n",
        "        # compute logits\n",
        "        # positive logits: Bx1 (one timestamp as postive)\n",
        "        l_pos = einops.einsum(q, k, 'b c,b c->b').unsqueeze(-1)\n",
        "        # negative logits: BxK\n",
        "        l_neg = einops.einsum(q, k_negs, 'b c,c k->b k')\n",
        "\n",
        "        # logits: Bx(1+K)\n",
        "        logits = torch.cat([l_pos, l_neg], dim=1)\n",
        "\n",
        "        # apply temperature\n",
        "        logits /= self.T\n",
        "\n",
        "        # labels: positive key indicators - first dim of each batch (it will be considered the positive sample)\n",
        "        # so we can consider this as a classification problem and use the CE\n",
        "        labels = torch.zeros(logits.shape[0], dtype=torch.long, device = logits.device)\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def get_polar(self, x):\n",
        "        mod = x.abs()\n",
        "        phase = x.angle()\n",
        "\n",
        "        return (mod, phase)\n",
        "\n",
        "    def instance_contrastive_loss(self, z1, z2):\n",
        "        B = z1.shape[0]\n",
        "        z = torch.cat([z1, z2], dim=0)  # 2B x F x d_s\n",
        "        z = einops.rearrange(z, 'b f d_s -> f b d_s')  # F x 2B x d_s\n",
        "        sim = einops.einsum(z, z, 'f b_1 d_s, f b_2 d_s -> f b_1 b_2')  # F x 2B x 2B\n",
        "        logits = torch.tril(sim, diagonal=-1)[:, :, :-1]  # F x 2B x (2B-1)\n",
        "        logits += torch.triu(sim, diagonal=1)[:, :, 1:]\n",
        "        logits = -F.log_softmax(logits, dim=-1)\n",
        "        # log.debug(logits)\n",
        "\n",
        "        i = torch.arange(B)\n",
        "        loss = (logits[:, i, B + i - 1].mean() + logits[:, B + i, i].mean()) / 2\n",
        "        return loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _dequeue_and_enqueue(self, keys):\n",
        "        batch_size = keys.shape[0]\n",
        "\n",
        "        ptr = int(self.queue_ptr)\n",
        "        assert self.K % batch_size == 0, \"K must be a multiple of batch_size\"\n",
        "\n",
        "        # replace keys at ptr (dequeue and enqueue)\n",
        "        self.queue[:, ptr:ptr + batch_size] = keys.T\n",
        "\n",
        "        ptr = (ptr + batch_size) % self.K\n",
        "        self.queue_ptr[0] = ptr\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x_q, x_k = batch\n",
        "\n",
        "        if self.max_train_length is not None and x_q.size(1) > self.max_train_length:\n",
        "            window_offset = np.random.randint(x_q.size(1) - self.max_train_length + 1)\n",
        "            x_q = x_q[:, window_offset : window_offset + self.max_train_length]\n",
        "            x_k = x_k[:, window_offset : window_offset + self.max_train_length]\n",
        "\n",
        "        loss = self.forward(x_q, x_k)\n",
        "\n",
        "        # logs metrics for each training_step,\n",
        "        # and the average across the epoch, to the progress bar and logger\n",
        "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger = True)\n",
        "        wandb.log({\"train_loss\":loss})\n",
        "        return loss\n",
        "\n",
        "    # def validation_step(self, batch, batch_idx):\n",
        "    #     x_q, x_k = batch\n",
        "    #     loss = self.forward(x_q, x_k)\n",
        "\n",
        "    #     # logs metrics for each training_step,\n",
        "    #     # and the average across the epoch, to the progress bar and logger\n",
        "    #     self.log(\"val_loss\", loss)\n",
        "    #     return loss\n",
        "\n",
        "    # def test_step(self, batch, batch_idx):\n",
        "    #     x_q, x_k = batch\n",
        "    #     loss = self.forward(x_q, x_k)\n",
        "\n",
        "    #     # logs metrics for each training_step,\n",
        "    #     # and the average across the epoch, to the progress bar and logger\n",
        "    #     self.log(\"test_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "    #     return loss\n",
        "\n",
        "    def forward(self, x_q, x_k):\n",
        "        \"\"\"\n",
        "        x_q, x_k: (batch, input_size, enc_in + covariate_size)\n",
        "        \"\"\"\n",
        "        # select a random timestamp\n",
        "        rand_idx = np.random.randint(0, self.input_size)\n",
        "\n",
        "        # trend and seasonal queries\n",
        "        q_t, q_s = self.encoder_q(x_q)\n",
        "\n",
        "        if q_t is not None:\n",
        "            q_t = F.normalize(self.head_q(q_t[:, rand_idx]), dim=-1)\n",
        "\n",
        "        # compute key features\n",
        "        with torch.no_grad():  # no gradient update for keys (momentum update will be used)\n",
        "            self._momentum_update_key_encoder()  # update key encoder using momentum\n",
        "            k_t, k_s = self.encoder_k(x_k)\n",
        "            k_t = F.normalize(self.head_k(k_t[:, rand_idx]), dim=-1)\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "        loss += self.compute_loss(q_t, k_t, self.queue.clone().detach())\n",
        "        self._dequeue_and_enqueue(k_t)\n",
        "\n",
        "        q_s = F.normalize(q_s, dim=-1)\n",
        "        _, k_s = self.encoder_q(x_k)\n",
        "        k_s = F.normalize(k_s, dim=-1)\n",
        "\n",
        "        # the frequency and phase lost must be computed in the frequency domain\n",
        "        q_s_freq = torch.fft.rfft(q_s, dim=1)\n",
        "        k_s_freq = torch.fft.rfft(k_s, dim=1)\n",
        "        q_s_amp, q_s_phase = self.get_polar(q_s_freq)\n",
        "        k_s_amp, k_s_phase = self.get_polar(k_s_freq)\n",
        "\n",
        "        seasonal_loss = self.instance_contrastive_loss(q_s_amp, k_s_amp) + \\\n",
        "                        self.instance_contrastive_loss(q_s_phase,k_s_phase)\n",
        "        loss += (self.alpha * (seasonal_loss/2))\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "xSBWEMomx4KG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Forecasting Evaluation"
      ],
      "metadata": {
        "id": "UrfWPDRev3PO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data = np.load(datasets_path[ELECTRICITY] + datasets_processed_name[ELECTRICITY])\n",
        "# dataset = ElectricityDataset(data, L, True)\n",
        "# loader = DataLoader(dataset, batch_size=EVAL_BATCH_SIZE, drop_last = True)\n",
        "# log.info(f\"device: {DEVICE}\")\n",
        "# encoder = CoPSTEncoder(EVAL_PATCH_NUM, M, MAX_TRAIN_LENGTH, PATCH_LEN, STRIDE, EVAL_BATCH_SIZE).to(DEVICE)\n",
        "\n",
        "\n",
        "# callbacks = [TQDMProgressBar(refresh_rate=20)]\n",
        "# trainer = pl.Trainer(devices=1, accelerator=\"auto\", callbacks=callbacks)"
      ],
      "metadata": {
        "id": "2w0iIA_sx3cF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder.encode(loader, window_len=L, device=DEVICE, padding=PADDING)"
      ],
      "metadata": {
        "id": "3l_4jLK2LkrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pred = trainer.predict(encoder, loader)\n",
        "# if dataset.__len__() % BATCH_SIZE:\n",
        "#     pred = pred[:-2] # drop last batch\n",
        "# pred = torch.cat(pred, dim=0)"
      ],
      "metadata": {
        "id": "pXug9zzMzGWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gkJZLSd8mf3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "HKVmJP1d-q7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions"
      ],
      "metadata": {
        "id": "lNnO72b3clMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train function\n",
        "def train(batch_size, datamodule, model, model_name, max_epochs = 500, checkpoint_every_n_epochs = 5,\n",
        "          check_val_every_n_epoch = 5, resume_training = True, load_model = False,\n",
        "          enable_checkpoint = True, monitor_metric = \"val_loss\", checkpoint_dir = None,\n",
        "          log_flag = True, logs_dir = None,\n",
        "          early_stopping = True, deterministic = False):\n",
        "\n",
        "    # check monitor metric\n",
        "    assert monitor_metric in [\"train_loss\", \"vall_loss\"], \"metric to monitor is invalid\"\n",
        "\n",
        "    # initialize callbacks array\n",
        "    callbacks = [TQDMProgressBar(refresh_rate=20)]\n",
        "\n",
        "    # add checkpoints to callbacks\n",
        "    checkpoint_callback = None\n",
        "    if enable_checkpoint and checkpoint_dir is not None:\n",
        "        checkpoint_callback = ModelCheckpoint(dirpath=checkpoint_dir,  monitor = monitor_metric, filename=model_name + '-mnist-{epoch:02d}-{' + monitor_metric + ':.2f}',\n",
        "                                         save_last =True, every_n_epochs = checkpoint_every_n_epochs, save_on_train_epoch_end = True)\n",
        "        callbacks.append(checkpoint_callback)\n",
        "\n",
        "    # add early stopping to the callbacks\n",
        "    if early_stopping:\n",
        "        callbacks.append(EarlyStopping(monitor=\"val_loss\", min_delta = 0.1, patience = 3, mode=\"min\", check_on_train_epoch_end = False))\n",
        "\n",
        "    # define the logger object\n",
        "    logger = None\n",
        "    if log_flag:\n",
        "        # logger = TensorBoardLogger(logs_dir, name=model_name)\n",
        "        wandb_logger = WandbLogger(name = model_name, log_model = 'all')\n",
        "\n",
        "    # create the Trainer\n",
        "    trainer = pl.Trainer(enable_checkpointing=enable_checkpoint, devices=1, accelerator=\"auto\",\n",
        "                         max_epochs=max_epochs, logger=logger, callbacks=callbacks,  ## remove max_step\n",
        "                         check_val_every_n_epoch = check_val_every_n_epoch, ## remove\n",
        "                         deterministic = deterministic)\n",
        "\n",
        "    ckpt_path = None\n",
        "    if resume_training:\n",
        "        ckpt_path = checkpoint_dir + \"last\"\n",
        "    trainer.fit(ckpt_path = ckpt_path, model=model, datamodule=datamodule)\n",
        "    if checkpoint_callback is not None:\n",
        "        log.info(checkpoint_callback.best_model_path)"
      ],
      "metadata": {
        "id": "q-936er_-snn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main"
      ],
      "metadata": {
        "id": "Oqxoxjh9C0rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 1\n",
        "# initialize dataset\n",
        "# datamodule = ElectricityDataModule(datasets_path[ELECTRICITY] + datasets_processed_name[ELECTRICITY], BATCH_SIZE, L)\n",
        "datamodule = ElectricityDataModule(datasets_path[ELECTRICITY] + datasets_processed_name[ELECTRICITY],\n",
        "                       BATCH_SIZE, L)\n",
        "\n",
        "# set seed if deterministic\n",
        "if DETERMINISTIC:\n",
        "    seed_everything(seed)\n",
        "# initialize model, or load an extisting one\n",
        "model = CoSpyModel(L)\n",
        "if LOAD_MODEL:\n",
        "    model = CoSpyModel.load_from_checkpoint(CHECKPOINT_FOLDER)\n",
        "\n",
        "train(BATCH_SIZE, datamodule, model, CoSpy, max_epochs = 100, check_val_every_n_epoch = None,\n",
        "    resume_training = False, monitor_metric = \"train_loss\", checkpoint_dir = CHECKPOINT_FOLDER,\n",
        "    logs_dir = LOGS_FOLDER, early_stopping = False, deterministic = DETERMINISTIC)"
      ],
      "metadata": {
        "id": "AvftO5iOK9ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train(BATCH_SIZE, datamodule, model, CoPST, max_epochs = 100, check_val_every_n_epoch = None,\n",
        "#       resume_training = False, monitor_metric = \"train_loss\", checkpoint_dir = CHECKPOINT_FOLDER,\n",
        "#       logs_dir = LOGS_FOLDER, early_stopping = False, deterministic = DETERMINISTIC)"
      ],
      "metadata": {
        "id": "M-K47tMzHvIK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}