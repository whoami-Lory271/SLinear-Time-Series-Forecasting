{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/whoami-Lory271/thesis-project/blob/main/thesis.ipynb",
      "authorship_tag": "ABX9TyPwAjlA38HFeAw+Kt26FAjP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whoami-Lory271/thesis-project/blob/main/thesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Symbol legend\n",
        "\n",
        "* B: batch size \n",
        "* M: number of channel\n",
        "* P: patch dimension\n",
        "* N: number of patches\n"
      ],
      "metadata": {
        "id": "7s9odzFFQWyj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations and imports\n"
      ],
      "metadata": {
        "id": "w7opc0NsjlNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning==2.0.1.post0 --quiet"
      ],
      "metadata": {
        "id": "ehQC2AKyci-4",
        "outputId": "c64b3669-8112-4d40-a52a-8709265ddfa0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.6/718.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import logging\n",
        "from google.colab import drive\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pytorch_lightning as pl"
      ],
      "metadata": {
        "id": "WuaX4Ts_jqmd"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4F86VEC4VtL8",
        "outputId": "0b96aef7-2a0e-445b-c8bf-1d2f6effe098",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create logger\n",
        "log = logging.getLogger('model_application')\n",
        "log.setLevel(logging.DEBUG)\n",
        "\n",
        "# # create console handler and set level to debug\n",
        "# ch = logging.StreamHandler()\n",
        "# ch.setLevel(logging.INFO)\n",
        "\n",
        "# # create formatter\n",
        "# formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# # add formatter to ch\n",
        "# ch.setFormatter(formatter)\n",
        "\n",
        "# # add ch to logger\n",
        "# logger.addHandler(ch)"
      ],
      "metadata": {
        "id": "iRLWiTu4mlx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'application' code\n",
        "log.debug('debug message')\n",
        "log.info('info message')\n",
        "# logger.warning('warn message')\n",
        "# logger.error('error message')\n",
        "# logger.critical('critical message')"
      ],
      "metadata": {
        "id": "4HMM8XFyTvfk",
        "outputId": "bb254d5c-7376-45a4-bbc6-cce459894864",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:model_application:debug message\n",
            "INFO:model_application:info message\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constants"
      ],
      "metadata": {
        "id": "94xSbfaKkOmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#paths\n",
        "ELECTRICITY = \"electricity\"\n",
        "ROOT_FOLDER = \"/content/drive/MyDrive/Università/Magistrale/Tesi/code\"\n",
        "\n",
        "#hyperparameters\n",
        "BATCH_SIZE = 16"
      ],
      "metadata": {
        "id": "ySxfaOHQkQ_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "ma655OWbiZ0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets"
      ],
      "metadata": {
        "id": "GS_gE31AieGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets_path = {\n",
        "    ELECTRICITY: ROOT_FOLDER + \"/datasets/electricity\"\n",
        "}\n",
        "\n",
        "datasets_name = {\n",
        "    ELECTRICITY: \"/LD2011_2014.txt\"    \n",
        "}\n",
        "datasets_processed_name = {\n",
        "    ELECTRICITY: \"/electricity.pkl\"\n",
        "}"
      ],
      "metadata": {
        "id": "nX8g0950j36s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Electricity"
      ],
      "metadata": {
        "id": "S84zQ9UjigKj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "o-wdZhMWZybk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv(datasets_path[ELECTRICITY] + datasets_name[ELECTRICITY], sep = ';')\n",
        "# df.rename(columns={df.columns[0]: 'Date'},inplace=True)\n",
        "# df.to_pickle(datasets_path[ELECTRICITY] + datasets_processed_name[ELECTRICITY])"
      ],
      "metadata": {
        "id": "YsyolJAOjZVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_pickle(datasets_path[ELECTRICITY] + datasets_processed_name[ELECTRICITY])"
      ],
      "metadata": {
        "id": "CqBi00jLX4oZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ElectricityDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ts = self.data.iloc[idx, 1:]\n",
        "        return ts\n",
        "\n",
        "class ElectricityDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, path, batch_size, train_size = 0.6, test_size = 0.4):\n",
        "        super().__init__()\n",
        "        self.path = path\n",
        "        data = pd.read_pickle(path)\n",
        "        self.train_data, self.validate_data ,self.test_data =  np.split(data, [int(train_size*len(data)), int(test_size*len(data))])     \n",
        "\n",
        "    # def prepare_data(self):\n",
        "    #     # download\n",
        "\n",
        "    def setup(self, stage: str):\n",
        "        # Assign train/val datasets for use in dataloaders\n",
        "        if stage == \"fit\":\n",
        "            self.train = ElectricityDataset(self.train_data)\n",
        "            self.validate = ElectricityDataset(self.validate_data)\n",
        "\n",
        "        # Assign test dataset for use in dataloader(s)\n",
        "        if stage == \"test\":\n",
        "            self.test = ElectricityDataset(self.test_data)\n",
        "\n",
        "        # if stage == \"predict\":\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train, batch_size=self.batch_size, drop_last = True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.validation, batch_size=self.batch_size, drop_last = True)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test, batch_size=self.batch_size, drop_last = True)\n",
        "\n",
        "    # def predict_dataloader(self):\n",
        "        \n"
      ],
      "metadata": {
        "id": "pWDN4NROaOAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "Oq9gmXnKGmVP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PatchTST"
      ],
      "metadata": {
        "id": "QD52xt7xGsd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randint(20, size = (4,20,2))\n",
        "print(x.shape)\n",
        "print(\"---------------------------------\")\n",
        "tail = x[:,-1:,:]\n",
        "tail = torch.repeat_interleave(tail, 2, dim = 1)\n",
        "x = torch.concatenate((x,tail), axis = 1)\n",
        "print(x.shape)\n",
        "x = x.unfold(dimension=1, size=5, step=2)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "rRpCGPiqTtaE",
        "outputId": "0ba29d70-34c3-44f1-9e26-d3bad4052dd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 20, 2])\n",
            "---------------------------------\n",
            "torch.Size([4, 22, 2])\n",
            "torch.Size([4, 9, 2, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility functions\n",
        "\n",
        "def createPatches(xb, patch_len, stride):\n",
        "    \"\"\"\n",
        "    xb -> [B x L x M]\n",
        "    output -> [B x N x M x P], N\n",
        "    \"\"\"\n",
        "    batch_size, num_channels, num_var = xb.shape\n",
        "    # compute number of patches\n",
        "    patch_num = max(patch_len, num_var)-patch_len // stride + 2\n",
        "\n",
        "    # we repeat the last variable of the sequence to have equal patches\n",
        "    tail = torch.repeat_interleave(x[:,-1:,:], stride, dim = 1)\n",
        "    xb = torch.concatenate((xb, tail), axis = 1)\n",
        "\n",
        "    # create patches\n",
        "    xb = xb.unfold(dimension=1, size=patch_len, step=stride)  \n",
        "\n",
        "    return xb, patch_num\n"
      ],
      "metadata": {
        "id": "hbRO5NzrNy8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model\n",
        "\n",
        "class PatchTSTEncoder(nn.Module):\n",
        "    def __init__():\n",
        "        super().__init__()\n",
        "\n"
      ],
      "metadata": {
        "id": "bhiJYUZcGvr_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}