{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5a65746075854979a4973a903f053e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fbe1f6b1deb4890beb8157c12b2a60d",
              "IPY_MODEL_7068685713e84d07a8c1729319c53ebc"
            ],
            "layout": "IPY_MODEL_1cb8dbe2aa0e49bd90572f07bcea19cd"
          }
        },
        "0fbe1f6b1deb4890beb8157c12b2a60d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9493a631126b409ea0d804ace681aa7a",
            "placeholder": "​",
            "style": "IPY_MODEL_7c1fef1b0f41460ba41ca8062fc2ba75",
            "value": "Waiting for wandb.init()...\r"
          }
        },
        "7068685713e84d07a8c1729319c53ebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_947145cd7eb44c2fa969719423e565dd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5b24f70d89b4533953546c351f652e4",
            "value": 1
          }
        },
        "1cb8dbe2aa0e49bd90572f07bcea19cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9493a631126b409ea0d804ace681aa7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c1fef1b0f41460ba41ca8062fc2ba75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "947145cd7eb44c2fa969719423e565dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5b24f70d89b4533953546c351f652e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af29f5b6142143ba938c5981d1ffb81f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78ccc1f0179d4765b534b222047f113e",
              "IPY_MODEL_56cae7ae21034e0590012797e96fe32d",
              "IPY_MODEL_f0adb392711d4ac980269a4f5f43b339"
            ],
            "layout": "IPY_MODEL_86685613d7b74cd28a3ed26ad9cbd128"
          }
        },
        "78ccc1f0179d4765b534b222047f113e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9e08390171b4477805f80fa954cf52b",
            "placeholder": "​",
            "style": "IPY_MODEL_c4deddb155ae45deaec5f55f4ba0e42f",
            "value": "Finding best initial lr: 100%"
          }
        },
        "56cae7ae21034e0590012797e96fe32d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_929caaffaf024772afb9695099abc053",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd3e52e8ea78457baff759960a1d4095",
            "value": 100
          }
        },
        "f0adb392711d4ac980269a4f5f43b339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee819c78d378490eb1a6d92e590f6d0a",
            "placeholder": "​",
            "style": "IPY_MODEL_0f9dc8cefb794971a899627b6bf16489",
            "value": " 100/100 [00:12&lt;00:00,  9.70it/s]"
          }
        },
        "86685613d7b74cd28a3ed26ad9cbd128": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9e08390171b4477805f80fa954cf52b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4deddb155ae45deaec5f55f4ba0e42f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "929caaffaf024772afb9695099abc053": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd3e52e8ea78457baff759960a1d4095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee819c78d378490eb1a6d92e590f6d0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f9dc8cefb794971a899627b6bf16489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whoami-Lory271/thesis-project/blob/main/thesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Symbol legend\n",
        "\n",
        "* B: batch size\n",
        "* L: lookback window (aka input_size)\n"
      ],
      "metadata": {
        "id": "7s9odzFFQWyj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations and imports\n"
      ],
      "metadata": {
        "id": "w7opc0NsjlNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning==2.0.1.post0 --quiet\n",
        "!pip install einops==0.6.1 --quiet\n",
        "!pip install ipdb --quiet\n",
        "!pip install wandb --quiet\n",
        "# !pip install objsize --quiet"
      ],
      "metadata": {
        "id": "ehQC2AKyci-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b70f9e06-989d-416e-ee47-66abb56b9143"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.6/718.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.6/731.6 kB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.6/215.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import logging\n",
        "# https://github.com/gotcha/ipdb\n",
        "import ipdb\n",
        "import copy\n",
        "from google.colab import drive\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "import numpy as np\n",
        "import random\n",
        "# https://theaisummer.com/einsum-attention/\n",
        "import einops\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Ridge\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "from pytorch_lightning.profilers import PyTorchProfiler\n",
        "from pytorch_lightning.tuner import Tuner\n",
        "\n",
        "import wandb\n",
        "import sys\n",
        "import pickle\n",
        "import time\n",
        "import os\n",
        "import torch.fft as fft\n",
        "# import objsize"
      ],
      "metadata": {
        "id": "WuaX4Ts_jqmd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "!cp /content/drive/MyDrive/Tesi/code/.netrc /root/\n",
        "wandb.login()\n",
        "# 024a3906e525e6d2640af94c364128bb3d33e44b"
      ],
      "metadata": {
        "id": "4F86VEC4VtL8",
        "outputId": "21e2b678-cac3-41a4-e053-953f45dd2346",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdesantis-1849114\u001b[0m (\u001b[33mdesantis\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions"
      ],
      "metadata": {
        "id": "J2UVU6VqgizJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup logger function\n",
        "def setup_log(self, level):\n",
        "    log = logging.getLogger(self.__class__.__name__)\n",
        "    log.setLevel(level)\n",
        "    return log"
      ],
      "metadata": {
        "id": "gkBTe3nko46m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write log on a file\n",
        "def write_log(a):\n",
        "    with open(\"log.txt\", 'w') as file:\n",
        "        for row in a:\n",
        "            file.write(str(row))\n",
        "        log.debug(\"object logged\")"
      ],
      "metadata": {
        "id": "i8LE_3TogiZn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_patch_num(patch_len, num_var, stride):\n",
        "    return (max(patch_len, num_var)-patch_len) // stride + 2"
      ],
      "metadata": {
        "id": "Ke58BUkLo-dd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pad array with nan\n",
        "def pad_nan(arr, left=0, right=0, dim=0):\n",
        "    # padding the right side\n",
        "    if left > 0:\n",
        "        padshape = list(arr.shape)\n",
        "        padshape[dim] = left\n",
        "        arr = torch.cat((torch.full(padshape, np.nan).to(arr.device), arr), dim=dim)\n",
        "\n",
        "    # padding the left side\n",
        "    if right > 0:\n",
        "        padshape = list(arr.shape)\n",
        "        padshape[dim] = right\n",
        "        arr = torch.cat((arr, torch.full(padshape, np.nan)).to(arr.device), dim=dim)\n",
        "    return arr"
      ],
      "metadata": {
        "id": "T_LjdLhhiyGm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split with nan\n",
        "def split_with_nan(x, sections, axis=0):\n",
        "    assert x.dtype in [np.float16, np.float32, np.float64]\n",
        "    arrs = np.array_split(x, sections, axis=axis)\n",
        "    target_length = arrs[0].shape[axis]\n",
        "    for i in range(len(arrs)):\n",
        "        arrs[i] = pad_nan_to_target(arrs[i], target_length, axis=axis)\n",
        "    return arrs"
      ],
      "metadata": {
        "id": "8Z2FotiSArtJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pad with nan\n",
        "def pad_nan_to_target(array, target_length, axis=0):\n",
        "    assert array.dtype in [np.float16, np.float32, np.float64]\n",
        "    pad_size = target_length - array.shape[axis]\n",
        "    if pad_size <= 0:\n",
        "        return array\n",
        "    npad = [(0, 0)] * array.ndim\n",
        "    npad[axis] = (0, pad_size)\n",
        "\n",
        "    return np.pad(array, pad_width=npad, mode='constant', constant_values=np.nan)"
      ],
      "metadata": {
        "id": "1SAjsR_-A3RB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def centerize_vary_length_series(x):\n",
        "    prefix_zeros = np.argmax(~np.isnan(x).all(axis=-1), axis=1)\n",
        "    suffix_zeros = np.argmax(~np.isnan(x[:, ::-1]).all(axis=-1), axis=1)\n",
        "    offset = (prefix_zeros + suffix_zeros) // 2 - prefix_zeros\n",
        "    rows, column_indices = np.ogrid[:x.shape[0], :x.shape[1]]\n",
        "    offset[offset < 0] += x.shape[1]\n",
        "    column_indices = column_indices - offset[:, np.newaxis]\n",
        "\n",
        "    return x[rows, column_indices]"
      ],
      "metadata": {
        "id": "eK2M1qV3JBdl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random seed functions\n",
        "def seed_everything(seed):\n",
        "    pl.seed_everything(seed, workers=True)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "mzBQAeoIi8l2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pickle helper\n",
        "def pkl_save(name, var):\n",
        "    os.makedirs(os.path.dirname(name), exist_ok=True)\n",
        "    with open(name, 'wb') as f:\n",
        "        pickle.dump(var, f)\n",
        "\n",
        "def pkl_load(name):\n",
        "    with open(name, 'rb') as f:\n",
        "        return pickle.load(f)"
      ],
      "metadata": {
        "id": "NxBH76S1gdKm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constants"
      ],
      "metadata": {
        "id": "94xSbfaKkOmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# logger\n",
        "LOG_LEVEL = logging.DEBUG\n",
        "\n",
        "# datasets name\n",
        "ELECTRICITY = \"electricity\"\n",
        "M5 = \"M5\"\n",
        "ETTh1 = \"ETTh1\"\n",
        "ETTh2 = \"ETTh2\"\n",
        "WEATHER = \"WTH\"\n",
        "\n",
        "\n",
        "# models\n",
        "CoSpy = \"CoSpy\"\n",
        "\n",
        "MODEL = CoSpy\n",
        "ENCODER = \"Pyraformer\" # TCN Pyraformer\n",
        "\n",
        "# device\n",
        "\n",
        "DEVICE = torch.device('cpu') if not torch.cuda.is_available() else torch.device('cuda')\n",
        "\n",
        "#hyperparameters\n",
        "\n",
        "DATASET = ELECTRICITY\n",
        "\n",
        "# Train\n",
        "BATCH_SIZE = 4\n",
        "EPOCHS = None\n",
        "ITERS = None\n",
        "L = 201\n",
        "UNIVARIATE = True\n",
        "\n",
        "# Eval\n",
        "EVALUATE = False\n",
        "MAX_TRAIN_LENGTH = 201\n",
        "PADDING = MAX_TRAIN_LENGTH-1\n",
        "ENCODE_BATCH_SIZE = 256\n",
        "\n",
        "\n",
        "# training\n",
        "TRAIN = True\n",
        "DETERMINISTIC = True\n",
        "LOAD_MODEL = False\n",
        "RESUME_TRAINING = False\n",
        "MEMORY_PROFILING = False\n",
        "LOAD_ENCODE = False\n",
        "\n",
        "# training techniques\n",
        "\n",
        "GRADIENT_CLIPPING = None # None is default, 0.5 is by norm\n",
        "FIND_LR = True\n",
        "\n",
        "# wandb\n",
        "\n",
        "RUN_ID = \"RUN_ID\"\n",
        "RESUME_RUN = False\n",
        "RUN_ID = wandb.util.generate_id() if not RESUME_RUN else RUN_ID\n",
        "print(f\"current RUN_ID is {RUN_ID}\")\n",
        "\n",
        "config = dict(\n",
        "    epochs= EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    dataset=DATASET,\n",
        "    architecture=MODEL,\n",
        "    run_id = RUN_ID)\n",
        "\n",
        "\n",
        "#paths\n",
        "MODEL_SETTINGS_FOLDER = \"/univariate\" if UNIVARIATE else \"/multivariate\"\n",
        "ROOT_FOLDER = \"/content/drive/MyDrive/Tesi/code\"\n",
        "MODEL_FOLDER = ROOT_FOLDER + \"/models\"\n",
        "CHECKPOINT_FOLDER = ROOT_FOLDER + \"/checkpoints\" + \"/\" + MODEL + MODEL_SETTINGS_FOLDER\n",
        "LOGS_FOLDER = ROOT_FOLDER + \"/logs\"\n",
        "ENCODING_FOLDER = ROOT_FOLDER + \"/encoding/\" + MODEL + MODEL_SETTINGS_FOLDER\n",
        "FORECASTING_RESULT = ROOT_FOLDER + \"/forecasting_result/\" + MODEL + MODEL_SETTINGS_FOLDER"
      ],
      "metadata": {
        "id": "ySxfaOHQkQ_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e519120-c5a9-435e-9512-959418a93cf1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current RUN_ID is voyn766d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasets_path = {\n",
        "    ELECTRICITY: ROOT_FOLDER + \"/datasets/electricity\"\n",
        "}\n",
        "\n",
        "datasets_name = {\n",
        "    ELECTRICITY: \"/LD2011_2014.txt\"\n",
        "}\n",
        "datasets_processed_name = {\n",
        "    ELECTRICITY: \"/electricity.csv\" #\"/electricity.npy\"\n",
        "}\n",
        "\n",
        "datasets_pred_lens = {\n",
        "    ELECTRICITY: [24, 48], # [24, 48, 168, 336, 720]\n",
        "    ETTh1: [24, 48],\n",
        "    ETTh2: [24, 48],\n",
        "    WEATHER: [24, 48],\n",
        "    M5: [28]\n",
        "}\n",
        "\n",
        "datasets_n_iters = {\n",
        "    ELECTRICITY: 600\n",
        "}\n",
        "\n",
        "ADJUST_LR, ITERS = (True, ITERS) if EPOCHS is not None or ITERS is not None else (False, datasets_n_iters[DATASET])"
      ],
      "metadata": {
        "id": "XgPwzK8WeJ7D"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WanDB"
      ],
      "metadata": {
        "id": "WXYPOAZ8O2zL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# start a new experiment\n",
        "run = wandb.init(project=config[\"architecture\"], config = config, id = config[\"run_id\"], resume = 'allow')\n",
        "ENCODING_FOLDER += \"/\" + run.name\n",
        "FORECASTING_RESULT += \"/\" + run.name\n",
        "CHECKPOINT_FOLDER += \"/\" + run.name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "5a65746075854979a4973a903f053e49",
            "0fbe1f6b1deb4890beb8157c12b2a60d",
            "7068685713e84d07a8c1729319c53ebc",
            "1cb8dbe2aa0e49bd90572f07bcea19cd",
            "9493a631126b409ea0d804ace681aa7a",
            "7c1fef1b0f41460ba41ca8062fc2ba75",
            "947145cd7eb44c2fa969719423e565dd",
            "c5b24f70d89b4533953546c351f652e4"
          ]
        },
        "id": "sC_id8hdO5i_",
        "outputId": "6a17a0bb-01ec-4c0e-cf43-02b318fa655d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668805766666614, max=1.0…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a65746075854979a4973a903f053e49"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230818_131303-voyn766d</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/desantis/CoSpy/runs/voyn766d' target=\"_blank\">jumping-salad-68</a></strong> to <a href='https://wandb.ai/desantis/CoSpy' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/desantis/CoSpy' target=\"_blank\">https://wandb.ai/desantis/CoSpy</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/desantis/CoSpy/runs/voyn766d' target=\"_blank\">https://wandb.ai/desantis/CoSpy/runs/voyn766d</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logger"
      ],
      "metadata": {
        "id": "8j5-8dn5ppGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create logger\n",
        "log = logging.getLogger('APP')\n",
        "log.setLevel(LOG_LEVEL)\n",
        "logging.basicConfig(level=LOG_LEVEL)\n",
        "\n",
        "# # create console handler and set level to debug\n",
        "# ch = logging.StreamHandler()\n",
        "# ch.setLevel(logging.INFO)\n",
        "\n",
        "# # create formatter\n",
        "# formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# # add formatter to ch\n",
        "# ch.setFormatter(formatter)\n",
        "\n",
        "# # add ch to logger\n",
        "# logger.addHandler(ch)"
      ],
      "metadata": {
        "id": "iRLWiTu4mlx9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset and Datamodule"
      ],
      "metadata": {
        "id": "ma655OWbiZ0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, sigma, eval_mode = False,p = 0.5, multiplier = 10):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.sigma = sigma\n",
        "        self.eval_mode = eval_mode\n",
        "        self.p = p\n",
        "        self.multiplier = multiplier\n",
        "        self.N, self.T, self.D = data.shape # num_ts, time, dim\n",
        "\n",
        "    def __len__(self):\n",
        "        # return self.data.shape[0] // self.look_window\n",
        "        return self.data.shape[0] * self.multiplier\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ts = self.data[idx % self.N]\n",
        "\n",
        "        return self.transform(ts), self.transform(ts)\n",
        "\n",
        "    def get_len(self):\n",
        "        return self.__len__()\n",
        "\n",
        "    # def get_channels(self):\n",
        "    #     return self.data.iloc[0, 1:].astype(str).str.replace(',', '.').astype('float32').shape[0]\n",
        "\n",
        "    def transform(self, x):\n",
        "        return self.jitter(self.shift(self.scale(x)))\n",
        "\n",
        "    def jitter(self, x):\n",
        "        if random.random() > self.p:\n",
        "            return x\n",
        "        return x + (torch.empty(x.shape).normal_(mean = 0, std = 0.5) * self.sigma)\n",
        "\n",
        "    def scale(self, x):\n",
        "        if random.random() > self.p:\n",
        "            return x\n",
        "        return x * (torch.empty(x.size(-1)).normal_(mean = 0, std = 0.5) * self.sigma + 1)\n",
        "\n",
        "    def shift(self, x):\n",
        "        if random.random() > self.p:\n",
        "            return x\n",
        "        return x + (torch.empty(x.size(-1)).normal_(mean = 0, std = 0.5) * self.sigma)\n",
        "\n",
        "class CustomDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, name, path, batch_size, max_train_length, pred_lens = [24, 48, 96, 288, 672],\n",
        "                 encode_batch_size = 256, train_size = 0.6, test_size = 0.2, univariate = False):\n",
        "        super().__init__()\n",
        "        self.path = path # path to csv file\n",
        "        self.batch_size = batch_size\n",
        "        self.encode_batch_size = encode_batch_size\n",
        "        self.max_train_length = max_train_length\n",
        "        self.pred_lens = pred_lens\n",
        "        self.padding = max_train_length-1\n",
        "        self.train_size = train_size\n",
        "        self.test_size = test_size\n",
        "        self.univariate = univariate\n",
        "        self.name = name\n",
        "        # self.data = np.load(path)\n",
        "\n",
        "    # def prepare_data(self):\n",
        "    #     # download\n",
        "\n",
        "    def _get_time_features(self,dt):\n",
        "        return np.stack([\n",
        "                dt.minute.to_numpy(),\n",
        "                dt.hour.to_numpy(),\n",
        "                dt.dayofweek.to_numpy(),\n",
        "                dt.day.to_numpy(),\n",
        "                dt.dayofyear.to_numpy(),\n",
        "                dt.month.to_numpy(),\n",
        "                dt.weekofyear.to_numpy(),\n",
        "            ], axis=1).astype(float)\n",
        "\n",
        "    def _load_forecast_csv(self, path, name):\n",
        "        data = pd.read_csv(path, index_col='date', parse_dates=True)\n",
        "        dt_embed = self._get_time_features(data.index)\n",
        "        n_covariate_cols = dt_embed.shape[-1]\n",
        "        if self.univariate:\n",
        "            if name in ('ETTh1', 'ETTh2', 'ETTm1', 'ETTm2'):\n",
        "                data = data[['OT']]\n",
        "            elif name == 'electricity':\n",
        "                data = data[['MT_001']]\n",
        "            elif name == 'WTH':\n",
        "                data = data[['WetBulbCelsius']]\n",
        "            else:\n",
        "                data = data.iloc[:, -1:]\n",
        "        data = data.to_numpy()\n",
        "        # compute slices\n",
        "        if name == 'ETTh1' or name == 'ETTh2':\n",
        "            self.train_slice = slice(None, 12 * 30 * 24)\n",
        "            self.valid_slice = slice(12 * 30 * 24, 16 * 30 * 24)\n",
        "            self.test_slice = slice(16 * 30 * 24, 20 * 30 * 24)\n",
        "        elif name == 'ETTm1' or name == 'ETTm2':\n",
        "            self.train_slice = slice(None, 12 * 30 * 24 * 4)\n",
        "            self.valid_slice = slice(12 * 30 * 24 * 4, 16 * 30 * 24 * 4)\n",
        "            self.test_slice = slice(16 * 30 * 24 * 4, 20 * 30 * 24 * 4)\n",
        "        elif name.startswith('M5'):\n",
        "            self.train_slice = slice(None, int(0.8 * (1913 + 28)))\n",
        "            self.valid_slice = slice(int(0.8 * (1913 + 28)), 1913 + 28)\n",
        "            self.test_slice = slice(1913 + 28 - 1, 1913 + 2 * 28)\n",
        "        else:\n",
        "            self.train_slice = slice(None, int(self.train_size * len(data)))\n",
        "            self.valid_slice = slice(int(self.train_size * len(data)), - int(self.test_size * len(data)))\n",
        "            self.test_slice = slice(- int(self.test_size * len(data)), None)\n",
        "\n",
        "        return data, dt_embed, n_covariate_cols\n",
        "\n",
        "    def _scale_and_transform(self, data, dt_embed, n_covariate_cols, name):\n",
        "        # scale data\n",
        "        scaler = StandardScaler().fit(data[self.train_slice])\n",
        "        data = scaler.transform(data)\n",
        "        # NUM_ROWS x NUM_FEATURES -> NUM_FEATURES x NUM_ROWS x 1\n",
        "        if name in ('electricity') or name.startswith('M5'):\n",
        "            data = np.expand_dims(data.T, -1)  # Each variable is an instance rather than a feature\n",
        "        else:\n",
        "            data = np.expand_dims(data, 0)\n",
        "        if n_covariate_cols > 0:\n",
        "            dt_scaler = StandardScaler().fit(dt_embed[self.train_slice])\n",
        "            dt_embed = np.expand_dims(dt_scaler.transform(dt_embed), 0)\n",
        "            data = np.concatenate([np.repeat(dt_embed, data.shape[0], axis=0), data], axis=-1)\n",
        "\n",
        "        return data, scaler, n_covariate_cols\n",
        "\n",
        "    def _fit_setup(self, train_data):\n",
        "        if self.max_train_length is not None:\n",
        "            sections = train_data.shape[1] // self.max_train_length\n",
        "        if sections >= 2:\n",
        "            train_data = np.concatenate(split_with_nan(train_data, sections, axis=1), axis=0)\n",
        "\n",
        "        temporal_missing = np.isnan(train_data).all(axis=-1).any(axis=0)\n",
        "        if temporal_missing[0] or temporal_missing[-1]:\n",
        "            train_data = centerize_vary_length_series(train_data)\n",
        "\n",
        "        train_data = train_data[~np.isnan(train_data).all(axis=2).all(axis=1)]\n",
        "        # pkl_save(\"/content/drive/MyDrive/Tesi/code/test/my_train_data.pkl\", train_data)\n",
        "\n",
        "        multiplier = 1 if train_data.shape[0] >= self.batch_size else math.ceil(self.batch_size / train_data.shape[0])\n",
        "\n",
        "        return train_data, multiplier\n",
        "\n",
        "\n",
        "    def setup(self, stage: str):\n",
        "        # load csv\n",
        "        data, dt_embed, n_covariate_cols = self._load_forecast_csv(self.path, self.name)\n",
        "\n",
        "        # scale and transform\n",
        "        self.data, self.scaler, self.n_covariate_cols = self._scale_and_transform(data, dt_embed, n_covariate_cols, self.name)\n",
        "\n",
        "        # Assign train/val datasets for use in dataloaders\n",
        "        if stage == \"fit\":\n",
        "            train_data = self.data[:, self.train_slice]\n",
        "            train_data, multiplier = self._fit_setup(train_data)\n",
        "            # fit setup\n",
        "            self.train = CustomDataset(torch.from_numpy(train_data).to(torch.float), sigma = 0.5, multiplier = multiplier)\n",
        "            # self.validate = ElectricityDataset(data[self.valid_slice], self.look_window)\n",
        "        if stage == 'encoding':\n",
        "            self.encode = TensorDataset(torch.from_numpy(self.data).to(torch.float))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Assign test dataset for use in dataloader(s)\n",
        "        # if stage == \"test\":\n",
        "        #     self.test = ElectricityDataset(data[self.test_slice], self.look_window)\n",
        "\n",
        "        # if stage == \"predict\":\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train, batch_size=min(self.batch_size, len(self.train)), drop_last = True, shuffle = True)\n",
        "\n",
        "    def encode_dataloader(self):\n",
        "        return DataLoader(self.encode, batch_size=self.encode_batch_size)\n",
        "\n",
        "    # def test_dataloader(self):\n",
        "    #     return DataLoader(self.test, batch_size=self.batch_size, drop_last = True)\n",
        "\n",
        "    # def predict_dataloader(self):"
      ],
      "metadata": {
        "id": "37YF2vGhSYjl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "S84zQ9UjigKj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Electricity"
      ],
      "metadata": {
        "id": "o-wdZhMWZybk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv(datasets_path[ELECTRICITY] + datasets_name[ELECTRICITY], sep = ';')\n",
        "# df.rename(columns={df.columns[0]: 'Date'},inplace=True)\n",
        "# values = df.values\n",
        "# values = values[:, 1:].astype(str)\n",
        "# for i, value in enumerate(values):\n",
        "#   values[i] = np.char.replace(value, \",\", \".\")\n",
        "# values = values.astype(np.float32)\n",
        "# np.save(datasets_path[ELECTRICITY] + \"/electricity\", values)"
      ],
      "metadata": {
        "id": "YsyolJAOjZVS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # # call this function to initialize the csv file\n",
        "# def electricity_preprocess(path):\n",
        "#     data_ecl = pd.read_csv(path + '/LD2011_2014.txt', parse_dates=True, sep=';', decimal=',', index_col=0)\n",
        "#     data_ecl = data_ecl.resample('1h', closed='right').sum()\n",
        "#     data_ecl = data_ecl.loc[:, data_ecl.cumsum(axis=0).iloc[8920] != 0]  # filter out instances with missing values\n",
        "#     data_ecl.index = data_ecl.index.rename('date')\n",
        "#     data_ecl = data_ecl['2012':]\n",
        "#     data_ecl.to_csv(path + '/electricity.csv')\n",
        "#     log.info(\"electriciy.csv created!\")"
      ],
      "metadata": {
        "id": "HqM-Bf5vWJDg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# electricity_preprocess(datasets_path[ELECTRICITY])"
      ],
      "metadata": {
        "id": "YS1CZBhuWei-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "Oq9gmXnKGmVP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vanilla Transformer Encoder"
      ],
      "metadata": {
        "id": "lnbN5rUYocvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VanillaTransformer encoder\n",
        "\n",
        "\"\"\"\n",
        "https://arxiv.org/pdf/1706.03762.pdf\n",
        "\"\"\"\n",
        "\n",
        "class VanillaTransformerEncoder(nn.Module):\n",
        "    def __init__(self, d_model, n_heads = 16, dropout = 0.2):\n",
        "        super(VanillaTransformerEncoder, self).__init__()\n",
        "\n",
        "        self.log = setup_log(self, LOG_LEVEL)\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, n_heads)\n",
        "        self.norm1 = nn.LayerNorm(d_model) # maybe batch normalization\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.pffn = PositionWiseFeedForwardNetwork(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # new variable because of residual connection\n",
        "        z = self.mha(x,x,x)\n",
        "        z = self.dropout1(z)\n",
        "        z = self.norm1(z + x)\n",
        "\n",
        "        # set the new value for the residual connection\n",
        "        x = z\n",
        "        z = self.pffn(z)\n",
        "        z = self.dropout2(z)\n",
        "        return self.norm2(z + x)\n",
        "\n",
        "\"\"\"\n",
        "ref: https://d2l.ai/chapter_attention-mechanisms-and-transformers/multihead-attention.html\n",
        "\"\"\"\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, d_k, n_head = 6):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "        self.log = setup_log(self, LOG_LEVEL)\n",
        "\n",
        "        self.n_heads = n_head\n",
        "        self.d_k = d_k\n",
        "\n",
        "        self.W_q = nn.Linear(d_model, n_head * d_k, bias = False)\n",
        "        self.W_k = nn.Linear(d_model, n_head * d_k, bias = False)\n",
        "        self.W_v = nn.Linear(d_model, n_head * d_k, bias = False)\n",
        "        self.W_o = nn.Linear(n_head * d_k, d_model, bias = False)\n",
        "\n",
        "    # reshape to compute in parallel the several heads\n",
        "    def reshape_vector(self, x, inverse = False):\n",
        "        \"\"\"\n",
        "        x: (batch, input_size, d_model) || (batch, n_head, input_size, d_k)\n",
        "        output: (batch, n_head, input_size, d_k) || (batch, input_size, d_model)\n",
        "        \"\"\"\n",
        "        out = None\n",
        "\n",
        "        if not inverse:\n",
        "            out = einops.rearrange(x, 'b l (dim h) -> b h l dim', h=self.n_heads)\n",
        "        else:\n",
        "            out = einops.rearrange(x, 'b h l dim -> b l (dim h)')\n",
        "\n",
        "        return out\n",
        "\n",
        "    \"\"\"\n",
        "    ref: https://machinelearningmastery.com/the-transformer-attention-mechanism/\n",
        "    \"\"\"\n",
        "\n",
        "    def scaled_attention(self, q, k, v, dk, mask = None):\n",
        "        \"\"\"\n",
        "        q, k, v: (batch, n_head, input_size, d_k)\n",
        "        output: (batch, n_head, input_size, d_k), (batch, n_head, input_size, input_size)\n",
        "        \"\"\"\n",
        "        sqrt_d_k = math.sqrt(dk)\n",
        "\n",
        "        # using einsum to perform batch matrix multiplication\n",
        "        score = einops.einsum(q, k, 'b h l d_k, b h l_1 d_k -> b h l l_1') / sqrt_d_k\n",
        "\n",
        "        if mask is not None:\n",
        "            score = score.masked_fill(mask, -1e9)\n",
        "\n",
        "        weights = F.softmax(score, dim = -1)\n",
        "        attn = weights\n",
        "\n",
        "        res = einops.einsum(weights, v, 'b h l l_1, b h l_1 d_k -> b h l d_k')\n",
        "\n",
        "        return res, attn\n",
        "\n",
        "    def forward(self, q, k, v, mask = None):\n",
        "        \"\"\"\n",
        "        q, k, v: (batch, input_size, d_model)\n",
        "        output: (batch, input_size, d_model), (batch, n_head, input_size, input_size)\n",
        "        \"\"\"\n",
        "        residual = q\n",
        "\n",
        "        q = self.reshape_vector(self.W_q(q))\n",
        "        k = self.reshape_vector(self.W_k(k))\n",
        "        v = self.reshape_vector(self.W_v(v))\n",
        "\n",
        "        if mask is not None:\n",
        "            if len(mask.size()) == 3:\n",
        "                mask = mask.unsqueeze(1)  # For head axis broadcasting.\n",
        "\n",
        "        # parallel computation\n",
        "        out, attn = self.scaled_attention(q, k, v, self.d_k, mask)\n",
        "        out_concat = self.reshape_vector(out, inverse = True)\n",
        "\n",
        "        return self.W_o(out_concat) + residual, attn\n",
        "\n",
        "class PositionWiseFeedForwardNetwork(nn.Module):\n",
        "    def __init__(self, d_model, d_inner = 512):\n",
        "        super(PositionWiseFeedForwardNetwork, self).__init__()\n",
        "\n",
        "        self.log = setup_log(self, LOG_LEVEL)\n",
        "\n",
        "        self.W_1 = nn.Linear(d_model, d_inner)\n",
        "        self.act = nn.GELU()\n",
        "        self.W_2 = nn.Linear(d_inner, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch, input_size, d_model)\n",
        "        output: (batch, input_size, d_model)\n",
        "        \"\"\"\n",
        "        res = x\n",
        "        x = self.W_1(x)\n",
        "        x = self.act(x)\n",
        "        return res + self.W_2(x)"
      ],
      "metadata": {
        "id": "f7JI-qgOpWbs"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyraformerEncoder"
      ],
      "metadata": {
        "id": "j4VKdJgKsshh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions"
      ],
      "metadata": {
        "id": "d0TB55l1yKvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mask(input_size, window_size, inner_size, device):\n",
        "    \"\"\"Get the attention mask of PAM-Naive\"\"\"\n",
        "    # Get the size of all layers\n",
        "    all_size = []\n",
        "    all_size.append(input_size)\n",
        "    # we split the nodes in according with the number of children\n",
        "    for i in range(len(window_size)):\n",
        "        layer_size = math.floor(all_size[i] / window_size[i])\n",
        "        all_size.append(layer_size)\n",
        "\n",
        "    # length of the flattened graph\n",
        "    seq_length = sum(all_size)\n",
        "    # mask matrix\n",
        "    mask = torch.zeros(seq_length, seq_length, device=device)\n",
        "\n",
        "    # get intra-scale mask\n",
        "    inner_window = inner_size // 2\n",
        "    for layer_idx in range(len(all_size)):\n",
        "        start = sum(all_size[:layer_idx])\n",
        "        for i in range(start, start + all_size[layer_idx]):\n",
        "            left_side = max(i - inner_window, start)\n",
        "            right_side = min(i + inner_window + 1, start + all_size[layer_idx])\n",
        "            mask[i, left_side:right_side] = 1\n",
        "\n",
        "    # get inter-scale mask\n",
        "    for layer_idx in range(1, len(all_size)):\n",
        "        start = sum(all_size[:layer_idx])\n",
        "        for i in range(start, start + all_size[layer_idx]):\n",
        "            left_side = (start - all_size[layer_idx - 1]) + (i - start) * window_size[layer_idx - 1]\n",
        "            if i == ( start + all_size[layer_idx] - 1):\n",
        "                right_side = start\n",
        "            else:\n",
        "                right_side = (start - all_size[layer_idx - 1]) + (i - start + 1) * window_size[layer_idx - 1]\n",
        "            mask[i, left_side:right_side] = 1\n",
        "            mask[left_side:right_side, i] = 1\n",
        "\n",
        "    mask = (1 - mask).bool()\n",
        "\n",
        "    return mask, all_size\n",
        "\n",
        "def get_graph_dim(input_size, window_size):\n",
        "    \"\"\" get the dimension of the graph computed by CSCM\"\"\"\n",
        "    res = input_size\n",
        "    for w in window_size:\n",
        "        input_size = math.floor(input_size / w)\n",
        "        res += input_size\n",
        "\n",
        "    return res\n",
        "\n"
      ],
      "metadata": {
        "id": "rZXf-0odyPbJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "d6HSFST8yIkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck_Construct(nn.Module):\n",
        "    \"\"\"Bottleneck convolution CSCM\"\"\"\n",
        "    def __init__(self, d_model, window_size, d_inner):\n",
        "        super(Bottleneck_Construct, self).__init__()\n",
        "        if not isinstance(window_size, list):\n",
        "            self.conv_layers = nn.ModuleList([\n",
        "                ConvLayer(d_inner, window_size),\n",
        "                ConvLayer(d_inner, window_size),\n",
        "                ConvLayer(d_inner, window_size)\n",
        "                ])\n",
        "        else:\n",
        "            self.conv_layers = []\n",
        "            for i in range(len(window_size)):\n",
        "                self.conv_layers.append(ConvLayer(d_inner, window_size[i]))\n",
        "            self.conv_layers = nn.ModuleList(self.conv_layers)\n",
        "        self.up = nn.Linear(d_inner, d_model)\n",
        "        self.down = nn.Linear(d_model, d_inner)\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, enc_input):\n",
        "\n",
        "        temp_input = self.down(enc_input).permute(0, 2, 1)\n",
        "        all_inputs = []\n",
        "        for i in range(len(self.conv_layers)):\n",
        "            temp_input = self.conv_layers[i](temp_input)\n",
        "            all_inputs.append(temp_input)\n",
        "\n",
        "        all_inputs = torch.cat(all_inputs, dim=2).transpose(1, 2)\n",
        "        all_inputs = self.up(all_inputs)\n",
        "        all_inputs = torch.cat([enc_input, all_inputs], dim=1)\n",
        "\n",
        "        all_inputs = self.norm(all_inputs)\n",
        "\n",
        "        return all_inputs\n",
        "\"\"\" For Electricity Dataset\"\"\"\n",
        "class PositionalEmbedding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEmbedding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        # create a positional array\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        # div term for half of positions\n",
        "        div_term = torch.pow(10000.0, torch.arange(0, d_model, 2) / d_model)\n",
        "        # even positions\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        # odd positions\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "        # if normalize:\n",
        "        #     pe = pe - pe.mean()\n",
        "        #     pe = pe / (pe.std() * 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        output: (1, input_size, d_model)\n",
        "        \"\"\"\n",
        "        return self.pe[:, :x.size(1)]\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, c_in, d_model):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        padding = 1 if torch.__version__>='1.5.0' else 2\n",
        "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
        "                                    kernel_size=3, padding=padding, padding_mode='circular')\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d):\n",
        "                nn.init.kaiming_normal_(m.weight,mode='fan_in',nonlinearity='leaky_relu')\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch, input_size, enc_in)\n",
        "        output: (batch, input_size, d_model)\n",
        "        \"\"\"\n",
        "        x = self.tokenConv(einops.rearrange(x, 'b l e -> b e l')).transpose(1,2)\n",
        "        return x\n",
        "\n",
        "class CustomEmbedding(nn.Module):\n",
        "    def __init__(self, c_in, d_model, temporal_size, seq_num, dropout=0.1):\n",
        "        super(CustomEmbedding, self).__init__()\n",
        "\n",
        "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
        "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
        "        self.temporal_embedding = nn.Linear(temporal_size, d_model)\n",
        "        self.seqid_embedding = nn.Embedding(seq_num, d_model)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x, x_mark):\n",
        "        \"\"\"\n",
        "        x: (batch, input_size, enc_in)\n",
        "        x_mark: (batch, input_size)\n",
        "        output: (batch, input_size, d_model)\n",
        "        \"\"\"\n",
        "        x = self.value_embedding(x) + self.position_embedding(x) + self.temporal_embedding(x_mark[:, :, :-1]) \\\n",
        "            + self.seqid_embedding(x_mark[:, :, -1].long())\n",
        "\n",
        "\n",
        "\n",
        "        return self.dropout(x)\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    \"\"\" Compose with two layers \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, d_inner, d_k, n_head, dropout=0.1, normalize_before=True, q_k_mask=None, k_q_mask=None):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.slf_attn = MultiHeadAttention(d_model, d_k, n_head)\n",
        "\n",
        "        self.pos_ffn = PositionWiseFeedForwardNetwork(\n",
        "            d_model, d_inner)\n",
        "\n",
        "    def forward(self, enc_input, slf_attn_mask=None):\n",
        "        \"\"\"\n",
        "        enc_input: (batch, input_size, d_model)\n",
        "        output: (batch, input_size, d_model), (batch, n_head, input_size, input_size)\n",
        "        \"\"\"\n",
        "        enc_output, enc_slf_attn = self.slf_attn(enc_input, enc_input, enc_input, mask=slf_attn_mask)\n",
        "\n",
        "        enc_output = self.pos_ffn(enc_output)\n",
        "\n",
        "        return enc_output, enc_slf_attn\n",
        "\n",
        "class ConvLayer(nn.Module):\n",
        "    def __init__(self, c_in, window_size):\n",
        "        super(ConvLayer, self).__init__()\n",
        "        self.downConv = nn.Conv1d(in_channels=c_in,\n",
        "                                  out_channels=c_in,\n",
        "                                  kernel_size=window_size,\n",
        "                                  stride=window_size)\n",
        "        self.norm = nn.BatchNorm1d(c_in)\n",
        "        self.activation = nn.ELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downConv(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "class Bottleneck_Construct(nn.Module):\n",
        "    \"\"\"Bottleneck convolution CSCM\"\"\"\n",
        "    def __init__(self, d_model, window_size, d_inner):\n",
        "        super(Bottleneck_Construct, self).__init__()\n",
        "        if not isinstance(window_size, list):\n",
        "            self.conv_layers = nn.ModuleList([\n",
        "                ConvLayer(d_inner, window_size),\n",
        "                ConvLayer(d_inner, window_size),\n",
        "                ConvLayer(d_inner, window_size)\n",
        "                ])\n",
        "        else:\n",
        "            self.conv_layers = []\n",
        "            for i in range(len(window_size)):\n",
        "                self.conv_layers.append(ConvLayer(d_inner, window_size[i]))\n",
        "            self.conv_layers = nn.ModuleList(self.conv_layers)\n",
        "        self.up = nn.Linear(d_inner, d_model)\n",
        "        self.down = nn.Linear(d_model, d_inner)\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, enc_input):\n",
        "        \"\"\"\n",
        "        enc_input: (batch, input_size, d_model)\n",
        "        output: (batch, graph_size, d_model)\n",
        "        \"\"\"\n",
        "\n",
        "        temp_input = self.down(enc_input).permute(0, 2, 1)\n",
        "        all_inputs = []\n",
        "        for i in range(len(self.conv_layers)):\n",
        "            temp_input = self.conv_layers[i](temp_input)\n",
        "            all_inputs.append(temp_input)\n",
        "\n",
        "        all_inputs = torch.cat(all_inputs, dim=2).transpose(1, 2)\n",
        "        all_inputs = self.up(all_inputs)\n",
        "        # concat the computed new nodes with the input nodes\n",
        "        all_inputs = torch.cat([enc_input, all_inputs], dim=1)\n",
        "\n",
        "        all_inputs = self.norm(all_inputs)\n",
        "\n",
        "        return all_inputs\n",
        "\n",
        "class PyraformerEncoder(nn.Module):\n",
        "    \"\"\" A encoder model with self attention mechanism. \"\"\"\n",
        "\n",
        "    def __init__(self, d_model = 320, d_k = 160, window_size = [4,4,4], inner_size = 3,\n",
        "                 input_size = 201, d_inner_hid = 512, n_head = 6, n_layer = 4,\n",
        "                 # Dataloader parameters\n",
        "                 enc_in = 1, covariate_size = 7, seq_num = 321,\n",
        "                 CSCM = \"Bottleneck_Construct\", d_bottleneck = 128, device = 'cpu'):\n",
        "        super(PyraformerEncoder, self).__init__()\n",
        "        self.log = setup_log(self, LOG_LEVEL)\n",
        "\n",
        "        self.d_model = d_model # size of the latent vector\n",
        "        self.d_k = d_k # size of the inner dimension of q, k, v\n",
        "        self.window_size = window_size # The number of children of a parent node\n",
        "        self.inner_size = inner_size # The number of ajacent nodes\n",
        "        self.input_size = input_size # length of the sequence\n",
        "        self.d_inner_hid = d_inner_hid # inner size of the PostitionalFeedForward\n",
        "        self.n_head = n_head\n",
        "        self.n_layer = n_layer\n",
        "        self.enc_in = enc_in\n",
        "        self.covariate_size = covariate_size # number of temporal covariate\n",
        "        self.seq_num = seq_num # size of the time series\n",
        "        self.CSCM = CSCM # called coarser-scale construction module\n",
        "        self.g_size = get_graph_dim(input_size, window_size)\n",
        "        self.d_bottleneck = d_bottleneck #\n",
        "        self.mask, self.all_size = get_mask(self.input_size, self.window_size, self.inner_size, device)\n",
        "        self.layers = nn.ModuleList([\n",
        "                EncoderLayer(self.d_model, self.d_inner_hid, self.d_k, self.n_head) for i in range(self. n_layer)\n",
        "                ])\n",
        "        self.enc_embedding = nn.Linear(enc_in + covariate_size, d_model)#CustomEmbedding(self.enc_in, self.d_model, self.covariate_size, self.seq_num)\n",
        "\n",
        "        self.conv_layers = eval(self.CSCM)(self.d_model, self.window_size, self.d_bottleneck)\n",
        "\n",
        "        self.fc = nn.Linear(self.g_size, self.input_size)\n",
        "\n",
        "        self.test = nn.Linear(enc_in + covariate_size, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch, input_size, enc_in + covariate_size)\n",
        "        output: (batch, input_size, d_model)\n",
        "        \"\"\"\n",
        "\n",
        "        seq_enc = self.enc_embedding(x)\n",
        "\n",
        "        # Repeat the mask for all the batch\n",
        "        mask = self.mask.repeat(len(seq_enc), 1, 1)\n",
        "\n",
        "        seq_enc = self.conv_layers(seq_enc)\n",
        "\n",
        "        for i in range(len(self.layers)):\n",
        "            seq_enc, _ = self.layers[i](seq_enc, mask)\n",
        "\n",
        "        seq_enc = einops.rearrange(seq_enc, 'b g d -> b d g')\n",
        "\n",
        "        seq_enc = self.fc(seq_enc)\n",
        "\n",
        "        seq_enc = einops.rearrange(seq_enc, 'b d l -> b l d')\n",
        "\n",
        "        return seq_enc"
      ],
      "metadata": {
        "id": "LiOdyvP8syOH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PatchTST"
      ],
      "metadata": {
        "id": "QD52xt7xGsd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility functions\n",
        "\n",
        "def create_patches(xb, patch_len, stride):\n",
        "    \"\"\"\n",
        "    xb -> [B x L x M] // [B x L x M x T]\n",
        "    output -> [B x N x M x P] // [B x N x M x T x P], N\n",
        "    \"\"\"\n",
        "    _, num_var, _, _ = xb.shape\n",
        "    # compute number of patches\n",
        "    patch_num = (max(patch_len, num_var)-patch_len) // stride + 2\n",
        "\n",
        "    # we repeat the last variable of the sequence to have equal patches\n",
        "    tail = torch.repeat_interleave(xb[:,-1:,...], stride, dim = 1)\n",
        "    xb = torch.concatenate((xb, tail), axis = 1)\n",
        "\n",
        "    # create patches\n",
        "    xb = xb.unfold(dimension=1, size=patch_len, step=stride)\n",
        "\n",
        "    assert patch_num == xb.shape[1], f\"wrong number of computed patches, expected {patch_num} but computed {xb.shape[1]}\"\n",
        "\n",
        "    return xb, patch_num\n",
        "\n",
        "\"\"\"\n",
        "ref: https://kazemnejad.com/blog/transformer_architecture_positional_encoding/\n",
        "\"\"\"\n",
        "\n",
        "def positional_encoding(batch_size, max_len, d_model):\n",
        "    \"\"\"\n",
        "    output\n",
        "    \"\"\"\n",
        "    pe = torch.zeros(batch_size, max_len, d_model)\n",
        "    # create a positional array\n",
        "    position = torch.arange(0, max_len).unsqueeze(1)\n",
        "    # div term for half of positions\n",
        "    div_term = torch.pow(10000.0, torch.arange(0, d_model, 2) / d_model)\n",
        "    # even positions\n",
        "    pe[:, :, 0::2] = torch.sin(position * div_term)\n",
        "    # odd positions\n",
        "    pe[:, :, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "    # if normalize:\n",
        "    #     pe = pe - pe.mean()\n",
        "    #     pe = pe / (pe.std() * 10)\n",
        "\n",
        "    return nn.parameter.Parameter(pe, requires_grad= False)"
      ],
      "metadata": {
        "id": "hbRO5NzrNy8b"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PatchTST\n",
        "\n",
        "class PatchTSTEncoder(nn.Module):\n",
        "    def __init__(self, num_channels, num_var, patch_len, stride, batch_size, time_dimension = 8, d_model = 128, n_layers = 3, n_heads = 16, dropout = 0.2):\n",
        "        super(PatchTSTEncoder, self).__init__()\n",
        "\n",
        "        self.log = setup_log(self, LOG_LEVEL)\n",
        "\n",
        "        self.num_channels = num_channels\n",
        "        self.patch_num = (max(patch_len, num_var)-patch_len) // stride + 2\n",
        "        self.patch_len = patch_len\n",
        "        self.stride = stride\n",
        "        self.batch_size = batch_size\n",
        "        self.d_model = d_model\n",
        "        self.n_layers = n_layers\n",
        "        self.n_heads = n_heads\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # instance normalization\n",
        "        \"\"\"\n",
        "        ref: https://wandb.ai/wandb_fc/Normalization-Series/reports/Instance-Normalization-in-PyTorch-With-Examples---VmlldzoxNDIyNTQx\n",
        "        \"\"\"\n",
        "        self.inst_norm = nn.InstanceNorm2d(num_channels)\n",
        "\n",
        "        # patch creation\n",
        "        self.create_patch = create_patches\n",
        "\n",
        "        # embedding\n",
        "        self.W_p = nn.Linear(patch_len * time_dimension, d_model, bias = False)\n",
        "\n",
        "        # positional encoding\n",
        "        self.W_pos = positional_encoding(batch_size * num_channels, self.patch_num, d_model)\n",
        "\n",
        "        # dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # encoder\n",
        "        self.encoders = nn.ModuleList([VanillaTransformerEncoder(d_model) for _ in range(n_layers)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x -> [B x L x M] // [(B x M) x MAX_TRAIN_LENGTH x TIME_DIM]\n",
        "        output -> [(B M) x N x D]\n",
        "        \"\"\"\n",
        "        b_m, _, _ = x\n",
        "        assert b_m / self.num_channel == self.batch_size, f\"invalid fisrt dimension {b_m / self.num_channel} != {self.batch_size}\"\n",
        "        # [(B M) x MAX_TRAIN_LENGTH x TIME_DIM] -> [B x M x MAX_TRAIN_LENGTH x TIME_DIM]\n",
        "        x = einops.rearrange(x, '(b m) l t -> b m l t', m=self.num_channels)\n",
        "        # we need to reshape dimensione before apply instance normalization\n",
        "        x = einops.rearrange(self.inst_norm(x), 'b m l t -> b l m t')\n",
        "\n",
        "        # create patches\n",
        "        x, patch_num = self.create_patch(x, self.patch_len, self.stride)\n",
        "\n",
        "        # x: [B x N x M x T x P]\n",
        "\n",
        "        assert self.patch_num == patch_num, f\"wrong number for patch_num {self.patch_num} != {patch_num}\"\n",
        "\n",
        "        # reshape the tensor from [B x N x M x T x P] -> [(B M) x N x (P T)]\n",
        "        x = einops.rearrange(x, 'b n m t p -> (b m) n (p t)')\n",
        "        # now it can be provided to our transformer implementation\n",
        "\n",
        "        # project into transformer latent space\n",
        "        x = self.W_p(x) + self.W_pos\n",
        "\n",
        "        for layer in self.encoders:\n",
        "            x = layer(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "bhiJYUZcGvr_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TCN"
      ],
      "metadata": {
        "id": "2xgjSvFBQUiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TCN(nn.Module):\n",
        "    def __init__(self, input_dims, hidden_dims, output_dims, depth):\n",
        "        super(TCN, self).__init__()\n",
        "\n",
        "        self.log = setup_log(self, LOG_LEVEL)\n",
        "\n",
        "        self.input_fc = nn.Linear(input_dims, hidden_dims)\n",
        "\n",
        "        self.feature_extractor = DilatedConvEncoder(\n",
        "                hidden_dims,\n",
        "                [hidden_dims] * depth + [output_dims],\n",
        "                kernel_size=3\n",
        "            )\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch, input_size, enc_in + covariate_size)\n",
        "        outputs: (batch, input_size, d_model)\n",
        "        \"\"\"\n",
        "        x = self.input_fc(x)\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.feature_extractor(x)\n",
        "        x = x.transpose(1, 2)\n",
        "        return x\n",
        "\n",
        "class DilatedConvEncoder(nn.Module):\n",
        "    def __init__(self, in_channels, channels, kernel_size, extract_layers=None):\n",
        "        super().__init__()\n",
        "\n",
        "        if extract_layers is not None:\n",
        "            assert len(channels) - 1 in extract_layers\n",
        "\n",
        "        self.extract_layers = extract_layers\n",
        "        self.net = nn.Sequential(*[\n",
        "            ConvBlock(\n",
        "                channels[i-1] if i > 0 else in_channels,\n",
        "                channels[i],\n",
        "                kernel_size=kernel_size,\n",
        "                dilation=2**i,\n",
        "                final=(i == len(channels)-1)\n",
        "            )\n",
        "            for i in range(len(channels))\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.extract_layers is not None:\n",
        "            outputs = []\n",
        "            for idx, mod in enumerate(self.net):\n",
        "                x = mod(x)\n",
        "                if idx in self.extract_layers:\n",
        "                    outputs.append(x)\n",
        "            return outputs\n",
        "        return self.net(x)\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, dilation, final=False):\n",
        "        super().__init__()\n",
        "        self.conv1 = SamePadConv(in_channels, out_channels, kernel_size, dilation=dilation)\n",
        "        self.conv2 = SamePadConv(out_channels, out_channels, kernel_size, dilation=dilation)\n",
        "        self.projector = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels or final else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x if self.projector is None else self.projector(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.conv1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.conv2(x)\n",
        "        return x + residual\n",
        "\n",
        "class SamePadConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, dilation=1, groups=1):\n",
        "        super().__init__()\n",
        "        self.receptive_field = (kernel_size - 1) * dilation + 1\n",
        "        padding = self.receptive_field // 2\n",
        "        self.conv = nn.Conv1d(\n",
        "            in_channels, out_channels, kernel_size,\n",
        "            padding=padding,\n",
        "            dilation=dilation,\n",
        "            groups=groups\n",
        "        )\n",
        "        self.remove = 1 if self.receptive_field % 2 == 0 else 0\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        if self.remove > 0:\n",
        "            out = out[:, :, : -self.remove]\n",
        "        return out"
      ],
      "metadata": {
        "id": "YtqxPp42QXsJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cost"
      ],
      "metadata": {
        "id": "DTlGPLvHrJ5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.loss import TripletMarginWithDistanceLoss\n",
        "#Cost\n",
        "\n",
        "class Cost(nn.Module):\n",
        "    def __init__(self, input_size, d_model = 320, d_s = 160, d_t = 160, n_layers = 3, n_heads = 6, dropout = 0.2):\n",
        "        super(Cost, self).__init__()\n",
        "\n",
        "        self.log = setup_log(self, LOG_LEVEL)\n",
        "\n",
        "        # Dropout for seasonal representation output\n",
        "        self.seasonal_drop = nn.Dropout(0.1)\n",
        "\n",
        "        # Trend Feature Disentangler\n",
        "        self.tfd = TrendFeatureDisentangler(d_model, d_t, input_size)\n",
        "\n",
        "        # Seasonal Feature Disentangler\n",
        "        self.sfd = SeasonalFeatureDisentangler(d_model, d_s, input_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch, input_size, d_model)\n",
        "        outputs: (batch, input_size, d_t), (batch, input_size, d_s)\n",
        "        \"\"\"\n",
        "        out_tfd = self.tfd(x)\n",
        "\n",
        "        out_svd = self.sfd(x)\n",
        "\n",
        "        out_svd = self.seasonal_drop(out_svd)\n",
        "\n",
        "        return out_tfd, out_svd\n",
        "\n",
        "\n",
        "\n",
        "# Causal Convolution (dilated)\n",
        "\n",
        "class CausalConv1d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, dilation=1):\n",
        "        super(CausalConv1d, self).__init__()\n",
        "\n",
        "        self.log = setup_log(self, LOG_LEVEL)\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "        pad = (kernel_size - 1) * dilation\n",
        "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, padding=pad, dilation=dilation)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        input: (batch, input_size, in_channels)\n",
        "        output: (batch, conv_out, out_channels)\n",
        "        \"\"\"\n",
        "        # we need to reshape before applying the convolution\n",
        "        x = einops.rearrange(x, 'b l i_c -> b i_c l')\n",
        "        x = self.conv(x)\n",
        "\n",
        "        # we need to remove the trailing padding zeros (except for the fist layer) from the values\n",
        "        if self.kernel_size > 1:\n",
        "            x = x[...,0:-(self.kernel_size-1)]\n",
        "\n",
        "        # rearrange to the original shape\n",
        "        x = einops.rearrange(x, 'b o_c l -> b l o_c')\n",
        "\n",
        "        return x\n",
        "\n",
        "# TFD\n",
        "\n",
        "class TrendFeatureDisentangler(nn.Module):\n",
        "    def __init__(self, d_model, d_t, input_size):\n",
        "        super(TrendFeatureDisentangler, self).__init__()\n",
        "\n",
        "        self.log = setup_log(self, LOG_LEVEL)\n",
        "        self.d_model = d_model\n",
        "        self.d_t = d_t\n",
        "        self.input_size = input_size\n",
        "\n",
        "        # https://discuss.pytorch.org/t/causal-convolution/3456/3\n",
        "        # https://arxiv.org/pdf/1609.03499v2.pdf\n",
        "\n",
        "        # floor(log(N/2)) autoregressive expert\n",
        "        self.conv_num = math.floor(math.log2(input_size / 2)) + 1\n",
        "        self.kernel = [2**i for i in range(self.conv_num)]\n",
        "        self.convolutions = nn.ModuleList([CausalConv1d(d_model, d_t, k) for k in self.kernel])\n",
        "\n",
        "    def avg_pooling(self, input):\n",
        "        \"\"\"\n",
        "        input: (list, batch, input_size, d_t)\n",
        "        \"\"\"\n",
        "        return einops.reduce(input, 'list b l d_t -> b l d_t', 'mean')\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch, input_size, d_model)\n",
        "        output: (batch, input_size, d_t)\n",
        "        \"\"\"\n",
        "        batch_size, input_size, d_model = x.shape\n",
        "\n",
        "        assert input_size == self.input_size and d_model == self.d_model, \"wrong input dimensions\"\n",
        "\n",
        "        # create the result tensor\n",
        "        trend = torch.zeros(self.conv_num, batch_size, input_size, self.d_t, device = x.device)\n",
        "\n",
        "        for i, conv in enumerate(self.convolutions):\n",
        "            out = conv(x)\n",
        "            trend[i,...] = out\n",
        "\n",
        "        # apply the average pooling operation\n",
        "        trend = self.avg_pooling(trend)\n",
        "\n",
        "        return trend\n",
        "\n",
        "# SVD\n",
        "\n",
        "class SeasonalFeatureDisentangler(nn.Module):\n",
        "    def __init__(self, d_model, d_s, input_size):\n",
        "        super(SeasonalFeatureDisentangler, self).__init__()\n",
        "\n",
        "        self.log = setup_log(self, LOG_LEVEL)\n",
        "\n",
        "        self.input_size = input_size\n",
        "\n",
        "        # number of frequencies after dft\n",
        "        self.f = input_size // 2 + 1\n",
        "\n",
        "        # discrete fast fourier transform, rfft output contains only the positive frequencies below the Nyquist frequency\n",
        "        self.dft = torch.fft.rfft\n",
        "\n",
        "        # Learnable Fourier Layer\n",
        "        self.fl = FourierLayer(self.f, d_model, d_s, input_size)\n",
        "\n",
        "        # inverse of discrete fast fourier transform\n",
        "        self.idft = torch.fft.irfft\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch, input_size, d_model)\n",
        "        output: (batch, input_size, d_s)\n",
        "        \"\"\"\n",
        "        # we apply dft along the temporal dimension\n",
        "        x = self.dft(x, dim = 1)\n",
        "\n",
        "        assert self.f == x.shape[1], \"wrong dimension of dft\"\n",
        "\n",
        "        # apply fourier layer\n",
        "        x = self.fl(x)\n",
        "\n",
        "        # compute the inverse of dft to come back to time domain\n",
        "        x = self.idft(x, n = self.input_size, dim = 1) # pass also the legth in order to avoid odd-length problems\n",
        "\n",
        "        return x\n",
        "\n",
        "class FourierLayer(nn.Module):\n",
        "    def __init__(self, f, d_model, d_s, input_size):\n",
        "        super(FourierLayer, self).__init__()\n",
        "\n",
        "        self.log = setup_log(self, LOG_LEVEL)\n",
        "\n",
        "        self.f = f\n",
        "        self.d_model = d_model\n",
        "\n",
        "        self.A = nn.Parameter(torch.empty((f, d_model, d_s), dtype=torch.cfloat))\n",
        "        self.B = nn.Parameter(torch.empty((f, d_s), dtype=torch.cfloat))\n",
        "        self._reset_parameters()\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))\n",
        "        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.A)\n",
        "        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
        "        nn.init.uniform_(self.B, -bound, bound)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch, f, d_model)\n",
        "        out: (batch, f, d_s)\n",
        "        \"\"\"\n",
        "        batch_size, f, _ = x.shape\n",
        "\n",
        "        assert f == self.f, \"wrong dimensions of x\"\n",
        "\n",
        "        out = einops.einsum(x, self.A, 'b f d, f d d_s -> b f d_s') + self.B\n",
        "\n",
        "        return out\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-U9fYJUKrN4S"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CoSpy Encoder"
      ],
      "metadata": {
        "id": "omgfLK9mFicv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %debug\n",
        "class CoSpyEncoder(nn.Module):\n",
        "    def __init__(self, input_size,\n",
        "                 d_model = 320, d_s = 160, d_t = 160,\n",
        "                 dropout = 0.2, device = 'cpu', enc = \"Pyraformer\",\n",
        "                 input_dims = 8, hidden_dims = 64, output_dims = 320, depth = 10):\n",
        "        super(CoSpyEncoder, self).__init__()\n",
        "        # self.save_hyperparameters()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.device = device\n",
        "        self.log = setup_log(self, LOG_LEVEL)\n",
        "\n",
        "        # Pyraformer or TCN layer (backbone encoder)\n",
        "        self.en = PyraformerEncoder(d_model, device = device) if enc == \"Pyraformer\" \\\n",
        "            else TCN(input_dims, hidden_dims, output_dims, depth)\n",
        "\n",
        "\n",
        "        # CoST layer (disentangler)\n",
        "        self.cost = Cost(self.input_size)\n",
        "\n",
        "    def encode(self, data_shape, loader, batch_size = 256, sliding_length=1, padding=200):\n",
        "\n",
        "        encoding_window = None\n",
        "        slicing = None\n",
        "\n",
        "        n_samples, ts_l, _ = data_shape\n",
        "\n",
        "        org_training = self.training\n",
        "        self.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = []\n",
        "            for batch in tqdm(loader, desc=\"data encoding\"):\n",
        "                x = batch[0]\n",
        "                reprs = []\n",
        "                # x = x.to(device)\n",
        "                if n_samples < batch_size:\n",
        "                    calc_buffer = []\n",
        "                    calc_buffer_l = 0\n",
        "                # self.log.debug(type(x))\n",
        "                # self.log.debug(f\"shape of batch: {x.shape}\")\n",
        "\n",
        "                # if self.batch_size != batch_size:\n",
        "                #     self.log.debug(\"different batch size return same batch\")\n",
        "                #     return batch\n",
        "\n",
        "                for i in tqdm(range(0, ts_l, sliding_length),\n",
        "                              desc = \"sequence encoding\"):\n",
        "                    l = i - padding # sliding_padding=200\n",
        "                    r = i + sliding_length\n",
        "                    # self.log.debug(x.device)\n",
        "                    x_sliding = pad_nan(\n",
        "                        x[:, max(l, 0) : min(r, ts_l)],\n",
        "                        left=-l if l<0 else 0,\n",
        "                        right=r-ts_l if r>ts_l else 0,\n",
        "                        dim=1\n",
        "                    )\n",
        "                    if n_samples < batch_size:\n",
        "                        if calc_buffer_l + n_samples > batch_size:\n",
        "                            out = self._eval_with_pooling(\n",
        "                                torch.cat(calc_buffer, dim=0)\n",
        "                            )\n",
        "                            reprs += torch.split(out, n_samples)\n",
        "                            calc_buffer = []\n",
        "                            calc_buffer_l = 0\n",
        "                        calc_buffer.append(x_sliding)\n",
        "                        calc_buffer_l += n_samples\n",
        "                    else:\n",
        "                        reprs.append(self._eval_with_pooling(x_sliding))\n",
        "\n",
        "                if n_samples < batch_size:\n",
        "                    if calc_buffer_l > 0:\n",
        "                        out = self._eval_with_pooling(\n",
        "                            torch.cat(calc_buffer, dim=0)\n",
        "                        )\n",
        "                        reprs += torch.split(out, n_samples)\n",
        "                        calc_buffer = []\n",
        "                        calc_buffer_l = 0\n",
        "\n",
        "                out = torch.cat(reprs, dim=1)\n",
        "                output.append(out)\n",
        "\n",
        "            output = torch.cat(output, dim=0)\n",
        "\n",
        "        self.train(org_training)\n",
        "        return output.numpy()\n",
        "\n",
        "    def _eval_with_pooling(self, x):\n",
        "        out_t, out_s = self(x.to(self.device, non_blocking=True))\n",
        "        out = torch.cat([out_t[:, -1], out_s[:, -1]], dim=-1)\n",
        "        return einops.rearrange(out.cpu(), 'b d -> b () d')\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch, input_size, enc_in + covariate_size)\n",
        "        outputs: (batch, input_size, d_t), (batch, input_size, d_s)\n",
        "        \"\"\"\n",
        "\n",
        "        nan_mask = ~x.isnan().any(axis=-1)\n",
        "        x[~nan_mask] = 0\n",
        "\n",
        "        x = self.en(x)\n",
        "\n",
        "        trend, season = self.cost(x)\n",
        "\n",
        "        return trend, season"
      ],
      "metadata": {
        "id": "uSr7enmSFptR"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CoSpy Model"
      ],
      "metadata": {
        "id": "niFGAd70x41j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Constrastive model similar to MoCo\n",
        "\"\"\"\n",
        "https://arxiv.org/pdf/1911.05722.pdf\n",
        "https://github.com/facebookresearch/moco/blob/main/moco/builder.py\n",
        "\"\"\"\n",
        "\n",
        "class CoSpyModel(pl.LightningModule):\n",
        "    def __init__(self, max_train_length, comp_dimension = 160, alpha = 5e-4, K = 65536, m = 0.999, T = 0.07,\n",
        "                 lr = 1e-3, om = 0.9, wd = 1e-4, epochs = 10, n_iters = 600, device = 'cpu', enc = \"Pyraformer\"):\n",
        "        super(CoSpyModel, self).__init__()\n",
        "\n",
        "        self.cum_loss = 0\n",
        "        self.n_epoch_iters = 0\n",
        "        self.epochs = epochs\n",
        "        self.n_iters = n_iters\n",
        "\n",
        "        self.input_size = max_train_length\n",
        "        self.max_train_length = max_train_length\n",
        "\n",
        "        self.K = K\n",
        "        self.m = m\n",
        "        self.T = T\n",
        "\n",
        "        self.alpha = alpha\n",
        "\n",
        "        self.lr = lr\n",
        "        self.om = om\n",
        "        self.wd = wd\n",
        "\n",
        "        self.encoder_q = CoSpyEncoder(self.input_size, device = device, enc = enc)\n",
        "        self.encoder_k = copy.deepcopy(self.encoder_q)\n",
        "\n",
        "        # projections head for queries and keyes\n",
        "        self.head_q = nn.Sequential(\n",
        "            nn.Linear(comp_dimension, comp_dimension),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(comp_dimension, comp_dimension)\n",
        "        )\n",
        "        self.head_k = nn.Sequential(\n",
        "            nn.Linear(comp_dimension, comp_dimension),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(comp_dimension, comp_dimension)\n",
        "        )\n",
        "\n",
        "        # initialize the parameters of the keyes encoder and projection head\n",
        "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
        "            param_k.data.copy_(param_q.data)\n",
        "            param_k.requires_grad = False # the keyes encoder will be updated by the momentum update\n",
        "\n",
        "        for param_q, param_k in zip(self.head_q.parameters(), self.head_k.parameters()):\n",
        "            param_k.data.copy_(param_q.data)\n",
        "            param_k.requires_grad = False # the head_k will be updated by the momentum update\n",
        "\n",
        "        # register a dictionary buffer as a queue (decouped from the minibatch size)\n",
        "        # https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_buffer\n",
        "        self.register_buffer('queue', F.normalize(torch.randn(comp_dimension, K), dim=0))\n",
        "        self.register_buffer('queue_ptr', torch.zeros(1, dtype=torch.long))\n",
        "\n",
        "        self.save_hyperparameters(ignore=['encoder_q', 'encoder_k'])\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # set parameters of SGD\n",
        "        optimizer = torch.optim.SGD([p for p in self.parameters() if p.requires_grad],\n",
        "                                    lr = self.lr, momentum = self.om, weight_decay = self.wd)\n",
        "        # cosine annelling is a wrapper for SGD\n",
        "        # cosine_anneling = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer = optimizer, T_max = 100)\n",
        "        return optimizer\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return self.train_dataloader\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _momentum_update_key_encoder(self):\n",
        "        \"\"\"\n",
        "        Momentum update for key encoder\n",
        "        \"\"\"\n",
        "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
        "            param_k.data = param_k.data * self.m + param_q.data * (1 - self.m)\n",
        "\n",
        "        for param_q, param_k in zip(self.head_q.parameters(), self.head_k.parameters()):\n",
        "            param_k.data = param_k.data * self.m + param_q.data * (1 - self.m)\n",
        "\n",
        "    def compute_loss(self, q, k, k_negs):\n",
        "        # compute logits\n",
        "        # positive logits: Bx1 (one timestamp as postive)\n",
        "        l_pos = einops.einsum(q, k, 'b c,b c->b').unsqueeze(-1)\n",
        "        # negative logits: BxK\n",
        "        l_neg = einops.einsum(q, k_negs, 'b c,c k->b k')\n",
        "\n",
        "        # logits: Bx(1+K)\n",
        "        logits = torch.cat([l_pos, l_neg], dim=1)\n",
        "\n",
        "        # apply temperature\n",
        "        logits /= self.T\n",
        "\n",
        "        # labels: positive key indicators - first dim of each batch (it will be considered the positive sample)\n",
        "        # so we can consider this as a classification problem and use the CE\n",
        "        labels = torch.zeros(logits.shape[0], dtype=torch.long, device = logits.device)\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def get_polar(self, x, eps=1e-6):\n",
        "        amp = torch.sqrt((x.real + eps).pow(2) + (x.imag + eps).pow(2))\n",
        "        phase = torch.atan2(x.imag, x.real + eps)\n",
        "\n",
        "        return amp, phase\n",
        "\n",
        "    def instance_contrastive_loss(self, z1, z2):\n",
        "        B = z1.shape[0]\n",
        "        z = torch.cat([z1, z2], dim=0)  # 2B x F x d_s\n",
        "        z = einops.rearrange(z, 'b f d_s -> f b d_s')  # F x 2B x d_s\n",
        "        sim = einops.einsum(z, z, 'f b_1 d_s, f b_2 d_s -> f b_1 b_2')  # F x 2B x 2B\n",
        "        logits = torch.tril(sim, diagonal=-1)[:, :, :-1]  # F x 2B x (2B-1)\n",
        "        logits += torch.triu(sim, diagonal=1)[:, :, 1:]\n",
        "        logits = -F.log_softmax(logits, dim=-1)\n",
        "        # log.debug(logits)\n",
        "\n",
        "        i = torch.arange(B)\n",
        "        loss = (logits[:, i, B + i - 1].mean() + logits[:, B + i, i].mean()) / 2\n",
        "        return loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _dequeue_and_enqueue(self, keys):\n",
        "        batch_size = keys.shape[0]\n",
        "\n",
        "        ptr = int(self.queue_ptr)\n",
        "        assert self.K % batch_size == 0, \"K must be a multiple of batch_size\"\n",
        "\n",
        "        # replace keys at ptr (dequeue and enqueue)\n",
        "        self.queue[:, ptr:ptr + batch_size] = keys.T\n",
        "\n",
        "        ptr = (ptr + batch_size) % self.K\n",
        "        self.queue_ptr[0] = ptr\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x_q, x_k = batch\n",
        "        if self.max_train_length is not None and x_q.size(1) > self.max_train_length:\n",
        "            window_offset = np.random.randint(x_q.size(1) - self.max_train_length + 1)\n",
        "            x_q = x_q[:, window_offset : window_offset + self.max_train_length]\n",
        "            x_k = x_k[:, window_offset : window_offset + self.max_train_length]\n",
        "\n",
        "        loss = self.forward(x_q, x_k)\n",
        "\n",
        "        self.cum_loss += loss.item()\n",
        "        self.n_epoch_iters += 1\n",
        "\n",
        "        if self.n_iters is not None:\n",
        "            optimizer = self.optimizers().optimizer\n",
        "            self._adjust_learning_rate(self.lr, optimizer, self.global_step, self.n_iters)\n",
        "\n",
        "        # logs metrics for each training_step,\n",
        "        # and the average across the epoch, to the progress bar and logger\n",
        "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
        "        wandb.log({\"train\": {\"loss\":loss}})\n",
        "        return loss\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        # self.log(self.log(\"cum_loss\", self.cum_loss, on_step=True, on_epoch=True, prog_bar=True, logger = True))\n",
        "        wandb.log({\"train\": {\"epoch\": self.current_epoch ,\"cum_loss_epoch\": self.cum_loss / self.n_epoch_iters}})\n",
        "        # adjust learning rate\n",
        "        optimizer = self.optimizers().optimizer\n",
        "        if self.epochs is not None:\n",
        "            self._adjust_learning_rate(self.lr, optimizer, self.current_epoch, self.epochs)\n",
        "        self.n_epoch_iters = 0\n",
        "        self.cum_loss = 0\n",
        "\n",
        "\n",
        "\n",
        "    def _adjust_learning_rate(self, lr, optimizer, epoch, epochs):\n",
        "        \"\"\"Decay the learning rate based on schedule\"\"\"\n",
        "        lr *= 0.5 * (1. + math.cos(math.pi * epoch / epochs))\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "\n",
        "    # def validation_step(self, batch, batch_idx):\n",
        "    #     x_q, x_k = batch\n",
        "    #     loss = self.forward(x_q, x_k)\n",
        "\n",
        "    #     # logs metrics for each training_step,\n",
        "    #     # and the average across the epoch, to the progress bar and logger\n",
        "    #     self.log(\"val_loss\", loss)\n",
        "    #     return loss\n",
        "\n",
        "    # def test_step(self, batch, batch_idx):\n",
        "    #     x_q, x_k = batch\n",
        "    #     loss = self.forward(x_q, x_k)\n",
        "\n",
        "    #     # logs metrics for each training_step,\n",
        "    #     # and the average across the epoch, to the progress bar and logger\n",
        "    #     self.log(\"test_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "    #     return loss\n",
        "\n",
        "    def forward(self, x_q, x_k):\n",
        "        \"\"\"\n",
        "        x_q, x_k: (batch, input_size, enc_in + covariate_size)\n",
        "        \"\"\"\n",
        "        # select a random timestamp\n",
        "        rand_idx = np.random.randint(0, self.input_size)\n",
        "\n",
        "        # trend and seasonal queries\n",
        "        q_t, q_s = self.encoder_q(x_q)\n",
        "\n",
        "        if q_t is not None:\n",
        "            q_t = F.normalize(self.head_q(q_t[:, rand_idx]), dim=-1)\n",
        "\n",
        "        # compute key features\n",
        "        with torch.no_grad():  # no gradient update for keys (momentum update will be used)\n",
        "            self._momentum_update_key_encoder()  # update key encoder using momentum\n",
        "            k_t, k_s = self.encoder_k(x_k)\n",
        "            if k_t is not None:\n",
        "                k_t = F.normalize(self.head_k(k_t[:, rand_idx]), dim=-1)\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "        loss += self.compute_loss(q_t, k_t, self.queue.clone().detach())\n",
        "        self._dequeue_and_enqueue(k_t)\n",
        "\n",
        "        q_s = F.normalize(q_s, dim=-1)\n",
        "        _, k_s = self.encoder_q(x_k)\n",
        "        k_s = F.normalize(k_s, dim=-1)\n",
        "\n",
        "        # the frequency and phase lost must be computed in the frequency domain\n",
        "        q_s_freq = torch.fft.rfft(q_s, dim=1)\n",
        "        k_s_freq = torch.fft.rfft(k_s, dim=1)\n",
        "        q_s_amp, q_s_phase = self.get_polar(q_s_freq)\n",
        "        k_s_amp, k_s_phase = self.get_polar(k_s_freq)\n",
        "\n",
        "        seasonal_loss = self.instance_contrastive_loss(q_s_amp, k_s_amp) + \\\n",
        "                        self.instance_contrastive_loss(q_s_phase,k_s_phase)\n",
        "        loss += (self.alpha * (seasonal_loss/2))\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "xSBWEMomx4KG"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "Oqxoxjh9C0rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 1\n",
        "# initialize dataset\n",
        "# datamodule = ElectricityDataModule(datasets_path[ELECTRICITY] + datasets_processed_name[ELECTRICITY], BATCH_SIZE, L)\n",
        "datamodule = CustomDataModule(DATASET, datasets_path[ELECTRICITY] + datasets_processed_name[DATASET],\n",
        "                       BATCH_SIZE, L, encode_batch_size=ENCODE_BATCH_SIZE,\n",
        "                            pred_lens = datasets_pred_lens[DATASET], univariate=UNIVARIATE)\n",
        "\n",
        "# set seed if deterministic\n",
        "if DETERMINISTIC:\n",
        "    seed_everything(seed)\n",
        "# initialize model, or load an extisting one\n",
        "model = CoSpyModel(L, epochs = EPOCHS, device = DEVICE, n_iters = ITERS, enc = ENCODER)\n",
        "if LOAD_MODEL:\n",
        "    log.info(\"loading model...\")\n",
        "    model = CoSpyModel.load_from_checkpoint(CHECKPOINT_FOLDER + \"/last.ckpt\")\n",
        "\n",
        "if MEMORY_PROFILING:\n",
        "    profiler = PyTorchProfiler()"
      ],
      "metadata": {
        "id": "AvftO5iOK9ZR",
        "outputId": "2c60a942-df77-4570-9412-0a0ae467eac1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "DYNOokNm3LCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train function\n",
        "def train(batch_size, datamodule, model, model_name, max_epochs = None, max_steps = -1, checkpoint_every_n_epochs = 5,\n",
        "          check_val_every_n_epoch = 5, gradient_clip_val=0, resume_training = True, load_model = False,\n",
        "          enable_checkpoint = True, monitor_metric = \"val_loss\", checkpoint_dir = None,\n",
        "          log_flag = False, logs_dir = None,\n",
        "          early_stopping = True, deterministic = False, profiler = None, find_lr = False):\n",
        "\n",
        "    # check monitor metric\n",
        "    assert monitor_metric in [\"train_loss\", \"vall_loss\"], \"metric to monitor is invalid\"\n",
        "\n",
        "    # initialize callbacks array\n",
        "    callbacks = [TQDMProgressBar(refresh_rate=20)]\n",
        "\n",
        "    # add checkpoints to callbacks\n",
        "    checkpoint_callback = None\n",
        "    if enable_checkpoint and checkpoint_dir is not None:\n",
        "        checkpoint_callback = ModelCheckpoint(dirpath=checkpoint_dir,  monitor = monitor_metric, filename=model_name + '-mnist-{epoch:02d}-{' + monitor_metric + ':.2f}',\n",
        "                                         save_last =True, every_n_epochs = checkpoint_every_n_epochs, save_on_train_epoch_end = True)\n",
        "        callbacks.append(checkpoint_callback)\n",
        "\n",
        "    # add early stopping to the callbacks\n",
        "    if early_stopping:\n",
        "        callbacks.append(EarlyStopping(monitor=\"val_loss\", min_delta = 0.1, patience = 3, mode=\"min\", check_on_train_epoch_end = False))\n",
        "\n",
        "    # define the logger object\n",
        "    logger = None\n",
        "    if log_flag:\n",
        "        # logger = TensorBoardLogger(logs_dir, name=model_name)\n",
        "        wandb_logger = WandbLogger(name = model_name, log_model = 'all')\n",
        "\n",
        "    # create the Trainer\n",
        "    trainer = pl.Trainer(enable_checkpointing=enable_checkpoint, devices=1, accelerator=\"auto\",\n",
        "                         max_epochs=max_epochs, max_steps=max_steps, logger=logger, callbacks=callbacks,  ## remove max_step\n",
        "                         check_val_every_n_epoch = check_val_every_n_epoch, gradient_clip_val=gradient_clip_val,## remove\n",
        "                         deterministic = deterministic, profiler = profiler)\n",
        "\n",
        "    if find_lr:\n",
        "        model.train_dataloader\n",
        "        tuner = Tuner(trainer)\n",
        "        # Run learning rate finder\n",
        "        lr_finder = tuner.lr_find(model, datamodule = datamodule, early_stop_threshold=None)\n",
        "\n",
        "        # Plot with\n",
        "        fig = lr_finder.plot(suggest=True)\n",
        "        fig.show()\n",
        "        # Pick point based on plot, or get suggestion\n",
        "        new_lr = lr_finder.suggestion()\n",
        "        log.info(f\"the suggested lr is {new_lr}\")\n",
        "        return trainer\n",
        "\n",
        "    ckpt_path = None\n",
        "    if resume_training:\n",
        "        ckpt_path = checkpoint_dir + \"/last.ckpt\"\n",
        "    trainer.fit(ckpt_path = ckpt_path, model=model, datamodule=datamodule)\n",
        "    if checkpoint_callback is not None:\n",
        "        log.info(checkpoint_callback.best_model_path)\n",
        "\n",
        "    return trainer"
      ],
      "metadata": {
        "id": "q-936er_-snn"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if TRAIN:\n",
        "    trainer = train(BATCH_SIZE, datamodule, model, CoSpy, max_epochs = EPOCHS, max_steps = ITERS, check_val_every_n_epoch = None, load_model = LOAD_MODEL,\n",
        "                    gradient_clip_val=GRADIENT_CLIPPING,\n",
        "        resume_training = RESUME_TRAINING, monitor_metric = \"train_loss\", checkpoint_dir = CHECKPOINT_FOLDER,\n",
        "        logs_dir = LOGS_FOLDER, early_stopping = False, deterministic = DETERMINISTIC, find_lr = FIND_LR)"
      ],
      "metadata": {
        "id": "r3xeKsgm2792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749,
          "referenced_widgets": [
            "af29f5b6142143ba938c5981d1ffb81f",
            "78ccc1f0179d4765b534b222047f113e",
            "56cae7ae21034e0590012797e96fe32d",
            "f0adb392711d4ac980269a4f5f43b339",
            "86685613d7b74cd28a3ed26ad9cbd128",
            "a9e08390171b4477805f80fa954cf52b",
            "c4deddb155ae45deaec5f55f4ba0e42f",
            "929caaffaf024772afb9695099abc053",
            "cd3e52e8ea78457baff759960a1d4095",
            "ee819c78d378490eb1a6d92e590f6d0a",
            "0f9dc8cefb794971a899627b6bf16489"
          ]
        },
        "outputId": "5ab280c1-4386-4abb-f056-a68f3a784129"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "<ipython-input-17-b93ed930a62f>:71: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series. To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
            "  dt.weekofyear.to_numpy(),\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (19) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af29f5b6142143ba938c5981d1ffb81f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=100` reached.\n",
            "INFO:pytorch_lightning.tuner.lr_finder:Learning rate set to 0.01445439770745928\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Restoring states from the checkpoint path at /content/.lr_find_5f190351-c2fe-4367-8912-86da28fe40fb.ckpt\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Restored all states from the checkpoint at /content/.lr_find_5f190351-c2fe-4367-8912-86da28fe40fb.ckpt\n",
            "INFO:APP:the suggested lr is 0.01445439770745928\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Encoding"
      ],
      "metadata": {
        "id": "6lzsSVC6kmJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_encoding(datamodule):\n",
        "    datamodule.setup(\"encoding\")\n",
        "    loader = datamodule.encode_dataloader()\n",
        "    return loader, datamodule.data.shape\n",
        "\n",
        "def encode(model, data_shape, loader, batch_size, device, save_path):\n",
        "    model.to(device)\n",
        "    model = model.encoder_q\n",
        "    res = model.encode(data_shape, loader, batch_size = batch_size, padding = PADDING)\n",
        "    file_name = f\"encoding_{time.time()}.pkl\"\n",
        "    pkl_save(f'{save_path}/{file_name}', res)\n",
        "    pkl_save(f'{save_path}/last.pkl', res)\n",
        "    log.info(f\"encoding {file_name} saved\")\n",
        "\n",
        "    return res"
      ],
      "metadata": {
        "id": "BIhjMuNq2nOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if EVALUATE:\n",
        "    encoding_loader, data_shape = prepare_encoding(datamodule)\n",
        "    # if LOAD_ENCODE:\n",
        "    #     repr = pkl_load(ENCODING_FOLDER + \"/last.pkl\")\n",
        "    # else:\n",
        "    #     repr = encode(model, data_shape, encoding_loader, ENCODE_BATCH_SIZE, DEVICE, ENCODING_FOLDER)"
      ],
      "metadata": {
        "id": "s32ambAiMImm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Forecasting Evaluation"
      ],
      "metadata": {
        "id": "sLMxIOWrOckk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions\n",
        "def generate_pred_samples(features, data, pred_len, drop=0):\n",
        "    n = data.shape[1]\n",
        "    features = features[:, :-pred_len]\n",
        "    labels = np.stack([ data[:, i:1+n+i-pred_len] for i in range(pred_len)], axis=2)[:, 1:]\n",
        "    features = features[:, drop:]\n",
        "    labels = labels[:, drop:]\n",
        "    return features.reshape(-1, features.shape[-1]), labels.reshape(-1, labels.shape[2]*labels.shape[3])\n",
        "\n",
        "def fit_ridge(train_features, train_y, valid_features, valid_y, MAX_SAMPLES=100000):\n",
        "    # If the training set is too large, subsample MAX_SAMPLES examples\n",
        "    if train_features.shape[0] > MAX_SAMPLES:\n",
        "        split = train_test_split(\n",
        "            train_features, train_y,\n",
        "            train_size=MAX_SAMPLES, random_state=0\n",
        "        )\n",
        "        train_features = split[0]\n",
        "        train_y = split[2]\n",
        "    if valid_features.shape[0] > MAX_SAMPLES:\n",
        "        split = train_test_split(\n",
        "            valid_features, valid_y,\n",
        "            train_size=MAX_SAMPLES, random_state=0\n",
        "        )\n",
        "        valid_features = split[0]\n",
        "        valid_y = split[2]\n",
        "    alphas = [0.1, 0.2, 0.5, 1, 2, 5, 10, 20, 50, 100, 200, 500, 1000]\n",
        "    valid_results = []\n",
        "    for alpha in alphas:\n",
        "        lr = Ridge(alpha=alpha).fit(train_features, train_y)\n",
        "        valid_pred = lr.predict(valid_features)\n",
        "        score = np.sqrt(((valid_pred - valid_y) ** 2).mean()) + np.abs(valid_pred - valid_y).mean()\n",
        "        valid_results.append(score)\n",
        "    best_alpha = alphas[np.argmin(valid_results)]\n",
        "\n",
        "    lr = Ridge(alpha=best_alpha)\n",
        "    lr.fit(train_features, train_y)\n",
        "    return lr\n",
        "\n",
        "def cal_metrics(pred, target):\n",
        "    return {\n",
        "        'MSE': ((pred - target) ** 2).mean(),\n",
        "        'MAE': np.abs(pred - target).mean()\n",
        "    }"
      ],
      "metadata": {
        "id": "aw_fXa2wRZxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_forecasting(repr, data, train_slice, valid_slice, test_slice, n_covariate_cols, scaler, padding, pred_lens):\n",
        "    train_repr = repr[:, train_slice]\n",
        "    valid_repr = repr[:, valid_slice]\n",
        "    test_repr = repr[:, test_slice]\n",
        "\n",
        "    train_data = data[:, train_slice, n_covariate_cols:]\n",
        "    valid_data = data[:, valid_slice, n_covariate_cols:]\n",
        "    test_data = data[:, test_slice, n_covariate_cols:]\n",
        "\n",
        "    ours_result = {}\n",
        "    out_log = {}\n",
        "    for pred_len in tqdm(pred_lens, desc=\"forecasting evaluation\"):\n",
        "        train_features, train_labels = generate_pred_samples(train_repr, train_data, pred_len, drop=padding)\n",
        "        valid_features, valid_labels = generate_pred_samples(valid_repr, valid_data, pred_len)\n",
        "        test_features, test_labels = generate_pred_samples(test_repr, test_data, pred_len)\n",
        "\n",
        "        lr = fit_ridge(train_features, train_labels, valid_features, valid_labels)\n",
        "\n",
        "        test_pred = lr.predict(test_features)\n",
        "\n",
        "        ori_shape = test_data.shape[0], -1, pred_len, test_data.shape[2]\n",
        "        test_pred = test_pred.reshape(ori_shape)\n",
        "        test_labels = test_labels.reshape(ori_shape)\n",
        "\n",
        "        test_shape = test_pred.shape\n",
        "        test_shape_swap = (test_shape[3], test_shape[1], test_shape[2], test_shape[0])\n",
        "        if test_data.shape[0] > 1:\n",
        "            test_pred_inv = scaler.inverse_transform(test_pred.swapaxes(0, 3)\n",
        "                .reshape(-1, test_shape[0])).reshape(test_shape_swap).swapaxes(0, 3)\n",
        "            test_labels_inv = scaler.inverse_transform(test_labels.swapaxes(0, 3)\n",
        "                .reshape(-1, test_shape[0])).reshape(test_shape_swap).swapaxes(0, 3)\n",
        "        else:\n",
        "            test_pred_inv = scaler.inverse_transform(test_pred.reshape(-1, test_shape[3])).reshape(test_shape)\n",
        "            test_labels_inv = scaler.inverse_transform(test_labels.reshape(-1, test_shape[3])).reshape(test_shape)\n",
        "\n",
        "        # out_log[pred_len] = {\n",
        "        #     # 'norm': test_pred,\n",
        "        #     # 'raw': test_pred_inv\n",
        "        #     # 'norm_gt': test_labels,\n",
        "        #     # 'raw_gt': test_labels_inv\n",
        "        # }\n",
        "        ours_result[pred_len] = {\n",
        "            'norm': cal_metrics(test_pred, test_labels),\n",
        "            'raw': cal_metrics(test_pred_inv, test_labels_inv)\n",
        "        }\n",
        "        print(ours_result)\n",
        "\n",
        "    eval_res = {\n",
        "        'ours': ours_result\n",
        "    }\n",
        "    return out_log, eval_res"
      ],
      "metadata": {
        "id": "0aJRiW2lOhoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if EVALUATE:\n",
        "    train_slice = datamodule.train_slice\n",
        "    valid_slice = datamodule.valid_slice\n",
        "    test_slice = datamodule.test_slice\n",
        "    data = datamodule.data\n",
        "    n_covariate_cols = datamodule.n_covariate_cols\n",
        "    scaler = datamodule.scaler\n",
        "    padding = PADDING\n",
        "    pred_lens = datamodule.pred_lens\n",
        "    repr=data # REMOVE\n",
        "\n",
        "    out, eval_res = eval_forecasting(repr, data, train_slice, valid_slice, test_slice,\n",
        "                                    n_covariate_cols, scaler, padding, pred_lens)\n",
        "\n",
        "    wandb.log({\"eval_forecasting\": eval_res})\n",
        "    pkl_save(FORECASTING_RESULT + \"/out.pkl\", out)\n",
        "    pkl_save(FORECASTING_RESULT + \"/eval_res.pkl\", eval_res)"
      ],
      "metadata": {
        "id": "NRE-qJPXLXOH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}